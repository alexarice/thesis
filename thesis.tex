\documentclass{cam-thesis}

\usepackage{packages}
\usepackage{macros}
\addbibresource{thesis.bib}

\title{A type-theoretic approach to semistrict higher categories}

%% The full name of the author (e.g.: James Smith):
\author{Alex Rice}

%% College affiliation:
\college{Darwin College}

%% College shield:
\collegeshield{CollegeShields/Darwin}

%% Submission date [optional]:
\submissiondate{TODO}

%% Declaration date:
\date{TODO}

%% PDF meta-info:
\subjectline{Computer Science}
\keywords{category theory, higher category theory, type theory}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Abstract:
%%
\abstract{%
  Abstract to go here...
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Acknowledgements:
%%
\acknowledgements{%
  My acknowledgements ...
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Contents:
%%
\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Title page, abstract, declaration etc.:
%% -    the title page (is automatically omitted in the technical report mode).
\frontmatter{}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Thesis body:
%%
\chapter{Introduction}
Things to go in introduction:
\begin{itemize}
\item Motivation for higher categories
\item Motivation for semistrictness
\item Introduce 3 classes of coherences
\item Ideas of semistrictness
\item Existing 3-dimensional semistrictness results
\item Link to graphical ideas
\item Story behind Catt - HoTT - Brunerei
\item Link to Grothedieck higher cats
\end{itemize}

\chapter{Background}
\label{sec:background}

We begin with an overview of the important concepts required for the rest of the thesis. Throughout, we will assume knowledge of various basic concepts from computer science, as well as a basic knowledge of category theory (including functor categories, presheafs, and (co)limits) and type theory. The following sections introduce a form of globular higher categories and give a definition of the type theory \Catt, close to the original definition.

This section additionally serves as a place to introduce the various syntax and notation which will be used throughout the rest of the thesis.

\section{Higher categories}
\label{sec:higher-categories}

A higher category is a generalisation of the ordinary notion of a category to allow higher dimensional structure. This manifests in the form of allowing arrows or morphisms to have their source or target be another morphism instead of an object. More precisely, higher categories are equipped with the notion of an \(n\)-cell, where an \((n+1)\)-cell has source and target \(n\)-cells, and \(0\)-cells play the role of objects in an ordinary category. There are many differing definitions of higher categories (see \cite{leinster2001survey}), some of which use different shapes of cell. In this thesis, we will study globular higher categories, in particular those defined by the type theory \Catt~\cite{finster2017type}, which are known to be equivalent to a definition of \citeauthor{maltsiniotis2010grothendieck}~\cite{maltsiniotis2010grothendieck} based off an earlier definition by \citeauthor{PursuingStacks}~\cite{PursuingStacks}, which we introduce in \cref{sec:weak}.

The role of objects is played by \(0\)-cells, with \(1\)-cells as the morphisms between these objects. For \(0\)-cells \(x\) and \(y\), a \(1\)-cell \(f\) with source \(x\) and target \(y\) will be drawn as:
\[
  \begin{tikzcd}
    x & y
    \arrow["f", from=1-1, to=1-2]
  \end{tikzcd}
\]
or may be written as \(f: x \to y\). Two cells are \emph{parallel} if they have the same source and target. Between any two parallel \(n\)-cells \(f\) and \(g\), we have a set of \((n+1)\)-cells between them. A \(2\)-cell \(\alpha : f \to g\) may be drawn as:
\[
  \begin{tikzcd}
    x & y
    \arrow[""{name=0, anchor=center, inner sep=0}, "f", curve={height=-12pt}, from=1-1, to=1-2]
    \arrow[""{name=1, anchor=center, inner sep=0}, "g"', curve={height=12pt}, from=1-1, to=1-2]
    \arrow["\alpha", shorten <=3pt, shorten >=3pt, Rightarrow, from=1, to=0]
  \end{tikzcd}
\]
and a \(3\)-cell \(\gamma\) between parallel \(2\)-cells \(\alpha\) and \(\beta\) could be could be drawn as:
\[
  \begin{tikzcd}
    x && y
    \arrow[""{name=0, anchor=center, inner sep=0}, "f", curve={height=-15pt}, from=1-1, to=1-3]
    \arrow[""{name=1, anchor=center, inner sep=0}, "g"', curve={height=15pt}, from=1-1, to=1-3]
    \arrow[""{name=2, anchor=center, inner sep=0}, "\alpha", shift left=4, shorten <=3pt, shorten >=3pt, Rightarrow, from=1, to=0]
    \arrow[""{name=3, anchor=center, inner sep=0}, "\beta"', shift right=4, shorten <=3pt, shorten >=3pt, Rightarrow, from=1, to=0]
    \arrow["\gamma", shorten <=4pt, shorten >=4pt, Rightarrow, nfold=3, from=2, to=3]
  \end{tikzcd}
\]

Just as in ordinary \(1\)-category theory, we expect to be able to compose morphisms. For \(1\)-cells, nothing has changed, given \(1\)-cells \(f: x \to y\) and \(g : y \to z\) we form the composition \(f * g\):
\[
  \begin{tikzcd}
    x & y & z
    \arrow[from=1-1, to=1-2, "f"]
    \arrow[from=1-2, to=1-3, "g"]
  \end{tikzcd}
\]
which has source \(x\) and target \(z\). We pause here to note that composition will be given in ``diagrammatic order'' throughout the whole thesis, which is the opposite of the order of function composition but the same as the order of the arrows if drawn head to tail. This is chosen as it will be common for us to draw higher dimensional arrows in a diagram, and rare for us to consider categories where the higher arrows are given by functions. In an attempt to avoid confusion, we use an asterisk (\(*\)) to represent composition of arrows or cells in a higher category, and will use a circle (\(\circ\)) only for function composition.

In two dimensions, there is no longer a singular composition operation. For \(2\)-cells \(\alpha : f \to g\) and \(\beta : g \to h\), the composite \(\alpha *_1 \beta\) can be formed as before:
% https://q.uiver.app/#q=WzAsMixbMCwwLCJcXGJ1bGxldCJdLFsyLDAsIlxcYnVsbGV0Il0sWzAsMSwiZiIsMCx7ImN1cnZlIjotNH1dLFswLDEsImgiLDIseyJjdXJ2ZSI6NH1dLFswLDEsImciLDFdLFsyLDQsIlxcYWxwaGEiLDAseyJzaG9ydGVuIjp7InNvdXJjZSI6MjAsInRhcmdldCI6MjB9fV0sWzQsMywiXFxiZXRhIiwwLHsic2hvcnRlbiI6eyJzb3VyY2UiOjIwLCJ0YXJnZXQiOjIwfX1dXQ==
\[
  \begin{tikzcd}
    x && y
    \arrow[""{name=0, anchor=center, inner sep=0}, "f"', curve={height=24pt}, from=1-1, to=1-3]
    \arrow[""{name=1, anchor=center, inner sep=0}, "h", curve={height=-24pt}, from=1-1, to=1-3]
    \arrow[""{name=2, anchor=center, inner sep=0}, "g"{description}, from=1-1, to=1-3]
    \arrow["\alpha", shorten <=3pt, shorten >=3pt, Rightarrow, from=0, to=2]
    \arrow["\beta", shorten <=3pt, shorten >=3pt, Rightarrow, from=2, to=1]
  \end{tikzcd}
\]

We refer to this composition as \emph{vertical composition}. We can also compose cells \(\alpha\) and \(\beta\) in the following way:

% https://q.uiver.app/#q=WzAsMyxbMCwwLCJ4Il0sWzEsMCwieSJdLFsyLDAsInoiXSxbMCwxLCIiLDAseyJjdXJ2ZSI6LTN9XSxbMCwxLCIiLDIseyJjdXJ2ZSI6M31dLFsxLDIsIiIsMix7ImN1cnZlIjotM31dLFsxLDIsIiIsMix7ImN1cnZlIjozfV0sWzMsNCwiXFxhbHBoYSIsMCx7InNob3J0ZW4iOnsic291cmNlIjoyMCwidGFyZ2V0IjoyMH19XSxbNSw2LCJcXGJldGEiLDAseyJzaG9ydGVuIjp7InNvdXJjZSI6MjAsInRhcmdldCI6MjB9fV1d
\[
  \begin{tikzcd}
    x & y & z
    \arrow[""{name=0, anchor=center, inner sep=0}, "g", curve={height=-18pt}, from=1-1, to=1-2]
    \arrow[""{name=1, anchor=center, inner sep=0}, "f"', curve={height=18pt}, from=1-1, to=1-2]
    \arrow[""{name=2, anchor=center, inner sep=0}, "i", curve={height=-18pt}, from=1-2, to=1-3]
    \arrow[""{name=3, anchor=center, inner sep=0}, "h"', curve={height=18pt}, from=1-2, to=1-3]
    \arrow["\alpha", shorten <=5pt, shorten >=5pt, Rightarrow, from=1, to=0]
    \arrow["\beta", shorten <=5pt, shorten >=5pt, Rightarrow, from=3, to=2]
  \end{tikzcd}
\]

This composition is called the \emph{horizontal composition}, and is written \(\alpha *_0 \beta\). The subscript refers to the dimension of the shared boundary in the composition, with the \(1\)-cell \(g\) being the shared boundary in the vertical composition example and the \(0\)-cell \(y\) being the shared boundary in the horizontal composition example. The dimension of this shared boundary is the \emph{codimension} of the composition.

This pattern continues with \(3\)-cells, which can be composed at codimension \(0\), \(1\), or \(2\), as below:

% https://q.uiver.app/#q=WzAsNyxbMiwwLCJcXGJ1bGxldCJdLFswLDAsIlxcYnVsbGV0Il0sWzMsMCwiXFxidWxsZXQiXSxbNSwwLCJcXGJ1bGxldCJdLFs2LDAsIlxcYnVsbGV0Il0sWzcsMCwiXFxidWxsZXQiXSxbOCwwLCJcXGJ1bGxldCJdLFsxLDAsIiIsMCx7ImN1cnZlIjotM31dLFsxLDAsIiIsMix7ImN1cnZlIjozfV0sWzIsMywiIiwwLHsiY3VydmUiOi00fV0sWzIsMywiIiwyLHsiY3VydmUiOjR9XSxbMiwzXSxbNCw1LCIiLDAseyJjdXJ2ZSI6LTN9XSxbNCw1LCIiLDIseyJjdXJ2ZSI6M31dLFs1LDYsIiIsMix7ImN1cnZlIjotM31dLFs1LDYsIiIsMix7ImN1cnZlIjozfV0sWzgsNywiIiwyLHsib2Zmc2V0IjotNSwic2hvcnRlbiI6eyJzb3VyY2UiOjIwLCJ0YXJnZXQiOjIwfX1dLFs4LDcsIiIsMCx7Im9mZnNldCI6NSwic2hvcnRlbiI6eyJzb3VyY2UiOjIwLCJ0YXJnZXQiOjIwfX1dLFs4LDcsIiIsMix7InNob3J0ZW4iOnsic291cmNlIjoyMCwidGFyZ2V0IjoyMH19XSxbMTAsMTEsIiIsMix7Im9mZnNldCI6LTQsInNob3J0ZW4iOnsic291cmNlIjoyMCwidGFyZ2V0IjoyMH19XSxbMTAsMTEsIiIsMCx7Im9mZnNldCI6NCwic2hvcnRlbiI6eyJzb3VyY2UiOjIwLCJ0YXJnZXQiOjIwfX1dLFsxMSw5LCIiLDEseyJvZmZzZXQiOi00LCJzaG9ydGVuIjp7InNvdXJjZSI6MjAsInRhcmdldCI6MjB9fV0sWzExLDksIiIsMSx7Im9mZnNldCI6NCwic2hvcnRlbiI6eyJzb3VyY2UiOjIwLCJ0YXJnZXQiOjIwfX1dLFsxMywxMiwiIiwyLHsib2Zmc2V0IjotMywic2hvcnRlbiI6eyJzb3VyY2UiOjIwLCJ0YXJnZXQiOjIwfX1dLFsxMywxMiwiIiwwLHsib2Zmc2V0IjozLCJzaG9ydGVuIjp7InNvdXJjZSI6MjAsInRhcmdldCI6MjB9fV0sWzE1LDE0LCIiLDIseyJvZmZzZXQiOi0zLCJzaG9ydGVuIjp7InNvdXJjZSI6MjAsInRhcmdldCI6MjB9fV0sWzE1LDE0LCIiLDAseyJvZmZzZXQiOjMsInNob3J0ZW4iOnsic291cmNlIjoyMCwidGFyZ2V0IjoyMH19XSxbMTYsMTgsIlxcZ2FtbWEiLDAseyJzaG9ydGVuIjp7InNvdXJjZSI6MjAsInRhcmdldCI6MjB9fV0sWzE4LDE3LCJcXGRlbHRhIiwwLHsic2hvcnRlbiI6eyJzb3VyY2UiOjIwLCJ0YXJnZXQiOjIwfX1dLFsyMSwyMiwiXFxnYW1tYSIsMCx7InNob3J0ZW4iOnsic291cmNlIjoyMCwidGFyZ2V0IjoyMH19XSxbMTksMjAsIlxcZGVsdGEiLDAseyJzaG9ydGVuIjp7InNvdXJjZSI6MjAsInRhcmdldCI6MjB9fV0sWzIzLDI0LCJcXGdhbW1hIiwwLHsic2hvcnRlbiI6eyJzb3VyY2UiOjIwLCJ0YXJnZXQiOjIwfX1dLFsyNSwyNiwiXFxkZWx0YSIsMCx7InNob3J0ZW4iOnsic291cmNlIjoyMCwidGFyZ2V0IjoyMH19XV0=
\[
  \begin{tikzcd}
    \bullet && \bullet & \bullet && \bullet & \bullet & \bullet & \bullet
    \arrow[""{name=0, anchor=center, inner sep=0}, curve={height=-18pt}, from=1-1, to=1-3]
    \arrow[""{name=1, anchor=center, inner sep=0}, curve={height=18pt}, from=1-1, to=1-3]
    \arrow[""{name=2, anchor=center, inner sep=0}, curve={height=-24pt}, from=1-4, to=1-6]
    \arrow[""{name=3, anchor=center, inner sep=0}, curve={height=24pt}, from=1-4, to=1-6]
    \arrow[""{name=4, anchor=center, inner sep=0}, from=1-4, to=1-6]
    \arrow[""{name=5, anchor=center, inner sep=0}, curve={height=-18pt}, from=1-7, to=1-8]
    \arrow[""{name=6, anchor=center, inner sep=0}, curve={height=18pt}, from=1-7, to=1-8]
    \arrow[""{name=7, anchor=center, inner sep=0}, curve={height=-18pt}, from=1-8, to=1-9]
    \arrow[""{name=8, anchor=center, inner sep=0}, curve={height=18pt}, from=1-8, to=1-9]
    \arrow[""{name=9, anchor=center, inner sep=0}, shift left=5, shorten <=5pt, shorten >=5pt, Rightarrow, from=1, to=0]
    \arrow[""{name=10, anchor=center, inner sep=0}, shift right=5, shorten <=5pt, shorten >=5pt, Rightarrow, from=1, to=0]
    \arrow[""{name=11, anchor=center, inner sep=0}, shorten <=5pt, shorten >=5pt, Rightarrow, from=1, to=0]
    \arrow[""{name=12, anchor=center, inner sep=0}, shift left=4, shorten <=3pt, shorten >=3pt, Rightarrow, from=3, to=4]
    \arrow[""{name=13, anchor=center, inner sep=0}, shift right=4, shorten <=3pt, shorten >=3pt, Rightarrow, from=3, to=4]
    \arrow[""{name=14, anchor=center, inner sep=0}, shift left=4, shorten <=3pt, shorten >=3pt, Rightarrow, from=4, to=2]
    \arrow[""{name=15, anchor=center, inner sep=0}, shift right=4, shorten <=3pt, shorten >=3pt, Rightarrow, from=4, to=2]
    \arrow[""{name=16, anchor=center, inner sep=0}, shift left=3, shorten <=5pt, shorten >=5pt, Rightarrow, from=6, to=5]
    \arrow[""{name=17, anchor=center, inner sep=0}, shift right=3, shorten <=5pt, shorten >=5pt, Rightarrow, from=6, to=5]
    \arrow[""{name=18, anchor=center, inner sep=0}, shift left=3, shorten <=5pt, shorten >=5pt, Rightarrow, from=8, to=7]
    \arrow[""{name=19, anchor=center, inner sep=0}, shift right=3, shorten <=5pt, shorten >=5pt, Rightarrow, from=8, to=7]
    \arrow["\gamma", shorten <=2pt, shorten >=2pt, Rightarrow, nfold=3, from=9, to=11]
    \arrow["\delta", shorten <=2pt, shorten >=2pt, Rightarrow, nfold=3, from=11, to=10]
    \arrow["\gamma", shorten <=3pt, shorten >=3pt, Rightarrow, nfold=3, from=14, to=15]
    \arrow["\delta", shorten <=3pt, shorten >=3pt, Rightarrow, nfold=3, from=12, to=13]
    \arrow["\gamma", shorten <=2pt, shorten >=2pt, Rightarrow, nfold=3, from=16, to=17]
    \arrow["\delta", shorten <=2pt, shorten >=2pt, Rightarrow, nfold=3, from=18, to=19]
  \end{tikzcd}
\]

For every \(n\)-cell \(x\), there is an \((n+1)\)-cell \(\id(x) : x \to x\), called the \emph{identity morphism}.

As with 1-categories, \(\infty\)-categories need to satisfy certain equalities, which fall into 3 groups: associativity, unitality, and interchange. The associativity laws are the same as for 1-categories, only now a law is needed for each composition (every dimension and codimension).

Unitality is again similar to the case for 1-categories, except we again need unitality laws for each composition. We note that for lower codimension compositions, an iterated identity is needed. For example given a \(2\)-cell \(\alpha : f \to g\), the appropriate equation for left unitality of horizontal composition is:
\[ \id(\id(x)) *_0 \alpha = \alpha \]
In general for a unit to be cancelled, it must be iterated a number of times equal to the difference between the dimension and codimension of the composition.

Interchange laws do not appear in 1-categories, and specify how compositions of different dimensions interact. The first interchange law states that for suitable \(2\)-cells \(\alpha\), \(\beta\), \(\gamma\), and \(\delta\), that:
\[ (\alpha *_0 \gamma) *_1 (\beta *_0 \delta) = (\alpha *_1 \beta) *_0 ()\]
This can be diagrammatically depicted as:
\newsavebox{\innertop}
\savebox{\innertop}{
  \adjustbox{scale=0.8}{\begin{tikzcd}[ampersand replacement=\&,column sep=small]
    \bullet \& \bullet \& \bullet
    \arrow[""{name=0, anchor=center, inner sep=0}, curve={height=-12pt}, from=1-1, to=1-2]
    \arrow[""{name=1, anchor=center, inner sep=0}, curve={height=12pt}, from=1-1, to=1-2]
    \arrow[""{name=2, anchor=center, inner sep=0}, curve={height=-12pt}, from=1-2, to=1-3]
    \arrow[""{name=3, anchor=center, inner sep=0}, curve={height=12pt}, from=1-2, to=1-3]
    \arrow["\alpha", shorten <=3pt, shorten >=3pt, Rightarrow, from=1, to=0]
    \arrow["\gamma", shorten <=3pt, shorten >=3pt, Rightarrow, from=3, to=2]
  \end{tikzcd}}}
\newsavebox{\innerbot}
\savebox{\innerbot}{
  \adjustbox{scale=0.8}{\begin{tikzcd}[ampersand replacement=\&,column sep=small]
    \bullet \& \bullet \& \bullet
    \arrow[""{name=0, anchor=center, inner sep=0}, curve={height=-12pt}, from=1-1, to=1-2]
    \arrow[""{name=1, anchor=center, inner sep=0}, curve={height=12pt}, from=1-1, to=1-2]
    \arrow[""{name=2, anchor=center, inner sep=0}, curve={height=-12pt}, from=1-2, to=1-3]
    \arrow[""{name=3, anchor=center, inner sep=0}, curve={height=12pt}, from=1-2, to=1-3]
    \arrow["\beta", shorten <=3pt, shorten >=3pt, Rightarrow, from=1, to=0]
    \arrow["\delta", shorten <=3pt, shorten >=3pt, Rightarrow, from=3, to=2]
  \end{tikzcd}}}
\newsavebox{\innerleft}
\savebox{\innerleft}{
  \adjustbox{scale=1}{\begin{tikzcd}[ampersand replacement=\&,column sep=small,cramped]
    \bullet \& \bullet
    \arrow[""{name=0, anchor=center, inner sep=0}, controls=+(80:0.7) and +(100:0.7),, from=1-1, to=1-2]
    \arrow[""{name=1, anchor=center, inner sep=0}, curve={height=0}, from=1-1, to=1-2]
    \arrow[""{name=2, anchor=center, inner sep=0}, controls=+(100:-0.7) and +(80:-0.7),, from=1-1, to=1-2]
    \arrow["\alpha", shorten <=3pt, shorten >=3pt, Rightarrow, from=2, to=1]
    \arrow["\beta", shorten <=3pt, shorten >=3pt, Rightarrow, from=1, to=0]
  \end{tikzcd}}}
\newsavebox{\innerright}
\savebox{\innerright}{
  \adjustbox{scale=1}{\begin{tikzcd}[ampersand replacement=\&,column sep=small,cramped]
    \bullet \& \bullet
    \arrow[""{name=0, anchor=center, inner sep=0}, controls=+(80:0.7) and +(100:0.7), from=1-1, to=1-2]
    \arrow[""{name=1, anchor=center, inner sep=0}, curve={height=0}, from=1-1, to=1-2]
    \arrow[""{name=2, anchor=center, inner sep=0}, controls=+(100:-0.7) and +(80:-0.7),, from=1-1, to=1-2]
    \arrow["\gamma", shorten <=3pt, shorten >=3pt, Rightarrow, from=2, to=1]
    \arrow["\delta", shorten <=3pt, shorten >=3pt, Rightarrow, from=1, to=0]
  \end{tikzcd}}}
\[
  \begin{tikzcd}[column sep=small]
    \bullet &&&&& \bullet & {=} & \bullet &&& \bullet &&& \bullet
    \arrow[""{name=0, anchor=center, inner sep=0}, from=1-1, to=1-6]
    \arrow[""{name=1, anchor=center, inner sep=0}, draw=none, controls=+(90:2) and +(90:2), from=1-1, to=1-6]
    \arrow[""{name=2, anchor=center, inner sep=0}, draw=none, controls=+(90:-2) and +(90:-2), from=1-1, to=1-6]
    \arrow[""{name=4, anchor=center, inner sep=0}, draw=none, controls=+(80:1.5) and +(100:1.5), from=1-8, to=1-11]
    \arrow[""{name=5, anchor=center, inner sep=0}, draw=none, controls=+(100:-1.5) and +(80:-1.5), from=1-8, to=1-11]
    \arrow[""{name=6, anchor=center, inner sep=0}, draw=none, controls=+(80:1.5) and +(100:1.5), from=1-11, to=1-14]
    \arrow[""{name=8, anchor=center, inner sep=0}, draw=none, controls=+(100:-1.5) and +(80:-1.5), from=1-11, to=1-14]
    \arrow["\usebox{\innertop}"{description, inner sep = 0,xshift = -1.2pt}, shorten <=4pt, shorten >=4pt, Rightarrow, from=2, to=0]
    \arrow["\usebox{\innerbot}"{description, inner sep = 0,xshift = -1.2pt}, shorten <=4pt, shorten >=4pt, Rightarrow, from=0, to=1]
    \arrow[""{name=1, anchor=center, inner sep=0}, controls=+(90:2) and +(90:2), from=1-1, to=1-6]
    \arrow[""{name=2, anchor=center, inner sep=0}, controls=+(90:-2) and +(90:-2), from=1-1, to=1-6]
    \arrow["\usebox{\innerleft}"{description, inner sep = 0,xshift = -1.3pt}, shorten <=2pt, shorten >=2pt, Rightarrow, from=5, to=4]
    \arrow["\usebox{\innerright}"{description, inner sep = 0,xshift = -1.3pt}, shorten <=2pt, shorten >=2pt, Rightarrow, from=8, to=6]
    \arrow[controls=+(80:1.5) and +(100:1.5), from=1-8, to=1-11]
    \arrow[controls=+(100:-1.5) and +(80:-1.5), from=1-8, to=1-11]
    \arrow[controls=+(80:1.5) and +(100:1.5), from=1-11, to=1-14]
    \arrow[controls=+(100:-1.5) and +(80:-1.5), from=1-11, to=1-14]
  \end{tikzcd}
\]

There are also interchange laws for the interaction of composition and identities; A composition of two identities is the same as an identity on the composition of the underlying cells.


The \(\infty\)-categories that we study in this thesis will be globular, meaning that their cells form a globular set. A globular set can be seen as natural extension of the data of a category, whose data can be arranged into the following diagram:
% https://q.uiver.app/#q=WzAsMixbMCwwLCJZIl0sWzEsMCwiWCJdLFswLDEsInMiLDAseyJvZmZzZXQiOi0xfV0sWzAsMSwidCIsMix7Im9mZnNldCI6MX1dXQ==
\[
  \begin{tikzcd}
    M & O
    \arrow["s", shift left, from=1-1, to=1-2]
    \arrow["t"', shift right, from=1-1, to=1-2]
  \end{tikzcd}
\]
where \(O\) is a set of objects, \(M\) is a set of all morphisms, and \(s\) and \(t\) are functions assigning each morphism to its source and target object respectively. \(2\)-cells can be added to this diagram in a natural way:

% https://q.uiver.app/#q=WzAsMyxbMSwwLCJDXzEiXSxbMiwwLCJDXzAiXSxbMCwwLCJDXzIiXSxbMCwxLCJzXzAiLDAseyJvZmZzZXQiOi0xfV0sWzAsMSwidF8wIiwyLHsib2Zmc2V0IjoxfV0sWzIsMCwic18xIiwwLHsib2Zmc2V0IjotMX1dLFsyLDAsInRfMSIsMix7Im9mZnNldCI6MX1dXQ==
\[
  \begin{tikzcd}
    {C_2} & {C_1} & {C_0}
    \arrow["{s_0}", shift left, from=1-2, to=1-3]
    \arrow["{t_0}"', shift right, from=1-2, to=1-3]
    \arrow["{s_1}", shift left, from=1-1, to=1-2]
    \arrow["{t_1}"', shift right, from=1-1, to=1-2]
  \end{tikzcd}
\]
In a globular set, the source and target of any cell must be parallel, meaning they share the same source and target. This condition is imposed by \emph{globularity conditions}. Adding these and iterating the process leads to the following definition.

\begin{definition}
  The category of globes \(\mathbf{G}\) has objects given by the natural numbers and morphisms generated from \(\mathbf{s}_n, \mathbf{t}_n : n \to n + 1\) quotiented by the \emph{globularity conditions}:
  \begin{align*}
    \mathbf{s}_{n+1} \circ \mathbf{s}_n &= \mathbf{t}_{n+1} \circ \mathbf{s}_n\\
    \mathbf{s}_{n+1} \circ \mathbf{t}_n &= \mathbf{t}_{n+1} \circ \mathbf{t}_n
  \end{align*}

The category of globular sets \(\mathbf{Glob}\), is the presheaf category \([\mathbf{G}, \mathbf{Set}]\).
 \end{definition}

Unwrapping this definition, a globular set \(G\) consists of sets \(G(n)\) for each \(n \in \mathbb{N}\), with source and target maps \(s_n, t_n : G(n+1) \to G(n)\), forming the following diagram:
\[
  \begin{tikzcd}
    \cdots & {G(3)} & {G(2)} & {G(1)} & {G(0)}
    \arrow["{s_0}", shift left, from=1-4, to=1-5]
    \arrow["{t_0}"', shift right, from=1-4, to=1-5]
    \arrow["{s_1}", shift left, from=1-3, to=1-4]
    \arrow["{t_1}"', shift right, from=1-3, to=1-4]
    \arrow["{t_2}"', shift right, from=1-2, to=1-3]
    \arrow["{s_2}", shift left, from=1-2, to=1-3]
    \arrow[shift right, from=1-1, to=1-2]
    \arrow[shift left, from=1-1, to=1-2]
  \end{tikzcd}
\]
and satisfying the globularity conditions. A morphism of globular sets \(F : G \to H\) is a collection of functions \(G(n) \to H(n)\) which commute with source and target maps.

Given a globular set \(G\), we will call the elements of \(G(n)\) the \(n\)-cells and write \(f : x \to y\) for an \((n+1)\)-cell \(f\) where \(s_n(f) = x\) and \(t_n(f) = y\). We further define the \(n\)-boundary operators \(\delta_n^-\) and \(\delta_n^+\) which take the source or target respectively of a \((n+k)\)-cell \(k\) times, returning an \(n\)-cell.

\begin{example}
  \label{ex:disc}
  The \(n\)-disc \(D^n\) is a finite globular set given by \(Y(n)\), where \(Y\) is the Yoneda functor \(\mathbf{G} \to \mathbf{Glob}\). \(D^n\), has no \(k\)-cells for \(k > n\), a single \(n\)-cell \(d_n\), and two \(m\)-cells \(d_m^-\) and \(d_m^+\) for \(m < n\). Every \((m+1)\)-cell of \(D^n\) has source \(d_m^-\) and target \(d_m^+\). The first few discs are depicted in \cref{fig:discs}. The Yoneda lemma tells us that a map of globular sets \(D^n \to G\) is the same as an \(n\)-cell of \(G\). For an \(n\)-cell \(x\) of \(G\), we let \(\{x\}\) be the unique map \(D^n \to G\) which sends \(d_n\) to \(x\).
\end{example}

\begin{figure}[h]
  \centering
  \begin{tabular}{P{3cm} P{3cm} P{3cm} P{3cm}}
    \(D^0\)&\(D^1\)&\(D^2\)&\(D^3\)\\
    {\begin{tikzcd}
        d_0
      \end{tikzcd}
    }&{\begin{tikzcd}[ampersand replacement=\&]
        d_0^- \& d_0^+
        \arrow[from=1-1, to=1-2, "d_1"]
      \end{tikzcd}
       }&{\begin{tikzcd}[ampersand replacement=\&]
           d_0^- \& d_0^+
           \arrow[""{name=0, anchor=center, inner sep=0}, "d_1^+", curve={height=-18pt}, from=1-1, to=1-2]
           \arrow[""{name=1, anchor=center, inner sep=0}, "d_1^-"', curve={height=18pt}, from=1-1, to=1-2]
           \arrow["d_2", shorten <=3pt, shorten >=3pt, Rightarrow, from=1, to=0]
         \end{tikzcd}
          }&{\begin{tikzcd}[ampersand replacement=\&]
              d_0^- \&\& d_0^+
              \arrow[""{name=0, anchor=center, inner sep=0}, "d_1^+", curve={height=-25pt}, from=1-1, to=1-3]
              \arrow[""{name=1, anchor=center, inner sep=0}, "d_1^-"', curve={height=25pt}, from=1-1, to=1-3]
              \arrow[""{name=2, anchor=center, inner sep=0}, "d_2^-", shift left=12pt,Rightarrow, shorten <=5pt, shorten >=5pt, from=1,to=0]
              \arrow[""{name=3, anchor=center, inner sep=0}, "d_2^+"', shift right=12pt,Rightarrow, shorten <=5pt, shorten >=5pt, from=1,to=0]
              \arrow["d_3", Rightarrow, nfold = 3, shorten <=3pt, shorten >=3pt,from=2,to=3]
            \end{tikzcd}}
  \end{tabular}
  \caption{The first disc globular sets}
  \label{fig:discs}
\end{figure}

\begin{remark}
  Globular sets are not the only natural extension of the data of a 1-category. The form of this data in a definition of a higher category is referred to as the \emph{shape} of the cells. Notable alternatives to globular sets include simplicial sets, opetopic sets, and cubical sets.
\end{remark}\todo{Could put some references in here}

We can now give the definition of a (strict) \(\infty\)-category.

\begin{definition}
  A (strict) \(\infty\)-category is a globular set \(G\) with operations:
  \begin{itemize}
  \item For \(m < n\), a composition \(*_m\) taking \(n\)-cells \(f\) and \(g\) with \(\delta_m^+(f) = \delta_m^-(g)\) and giving an \(n\)-cell \(f *_m g\) with:
    \begin{align*}
      s(f *_m g) &= \begin{cases*}
        s(f)&\text{if \(m = n - 1\)}\\
        s(f) *_m s(g)&\text{otherwise}
      \end{cases*}\\
      t(f *_m g) &= \begin{cases*}
        t(g)&\text{if \(m = n - 1\)}\\
        t(f) *_m t(g)&\text{otherwise}
      \end{cases*}
    \end{align*}
  \item For \(n\)-cell \(x\), an identity \((n+1)\)-cell \(\id(x) : x \to x\).
  \end{itemize}
  and satisfying equalities:
  \begin{itemize}
  \item Associativity: Given \(m < n\) and \(n\)-cells \(f\), \(g\), and \(h\) with \(\delta_m^+(f) = \delta_m^-(g)\) and \(\delta_m^+(g) = \delta_m^-(h)\):
    \[ (f *_m g) *_m h = f *_m (g *_m h) \]
  \item Unitality: Given \(m < n\) and \(n\)-cell \(f\):
    \begin{align*}
      \id^{n-m}(\delta_m^-(f)) *_m f &= f\\
      f *_m \id^{n-m}(\delta_m^+(f)) &= f
    \end{align*}
  \item Composition interchange: If \(o < m < n\) and \(\alpha\), \(\beta\), \(\gamma\), and \(\delta\) be \(n\)-cells with
    \[\delta_m^+(\alpha) = \delta_m^-(\beta)\qquad
      \delta_m^+(\gamma) = \delta_m^-(\delta)\qquad
      \delta_o^+(\alpha) = \delta_o^-(\gamma)\]
    then:
    \[(\alpha *_o \gamma) *_m (\beta *_o \delta) = (\alpha *_m \beta) *_o (\gamma *_m \delta)\]
  \item Identity interchange: Let \(m < n\) and \(f\) and \(g\) be \(n\)-cells with \(\delta_m^+(f) = \delta_m^-(g)\). Then:
    \[\id(f) *_m \id(g) = \id(f *_m g)\]
  \end{itemize}
  A morphism of \(\infty\) categories is a morphism of the underlying globular sets which preserves composition and identities.
\end{definition}

There is a clear forgetful functor from the category of strict infinity categories to the category of globular sets, which has a left adjoint given by taking the free strict infinity category over a globular set.

We end this section with an example of a non-trivial application of the axioms of an infinity category, known as the Eckmann-Hilton argument. The argument show's that any two scalars (morphisms from the identity to the identity) commute.

\begin{proposition}[Eckmann-Hilton]
  \label{prop:eh}
  Let \(x\) be an \(n\)-cell in an \(\infty\)-category and let \(\alpha\) and \(\beta\) be \((n+2)\)-cells with source and target \(\id(x)\). Then \(\alpha *_{n+1} \beta = \beta *_{n+1} \alpha\).
\end{proposition}
\begin{proof}
  The cells \(\alpha\) and \(\beta\) can be manoeuvred around each other as follows:
  \begin{align*}
    &\phantom{{}={}} \alpha *_{n+1} \beta \\
    &= (\alpha *_n i) *_{n+1} (i *_n \beta)&\text{Unitality}\\
    &= (\alpha *_{n+1} i) *_n (i *_{n+1} \beta)&\text{Interchange}\\
    &= \alpha *_n \beta &\text{Unitality}\\
    &= (i *_{n+1} \alpha) *_n (\beta *_{n+1} i)&\text{Unitality}\\
    &= (i *_n \beta) *_{n+1} (\alpha *_n i)&\text{Interchange}\\
    &= \beta *_{n+1} \alpha&\text{Unitality}
  \end{align*}
  Where \(i = \id(\id(x))\).
\end{proof}

We give a more graphical representation of the proof in \cref{fig:eh}. In this proof the \(\alpha\) is moved to the left of \(\beta\), though we equally could have moved it round the right, and the choice made was arbitrary.

\newsavebox{\ehalpha}
\savebox{\ehalpha}{\adjustbox{scale=0.8}{
  \begin{tikzcd}[ampersand replacement=\&,column sep=small,cramped]
    \bullet \& \bullet \& \bullet
    \arrow[""{name=0, anchor=center, inner sep=0}, curve={height=-10pt}, from=1-1, to=1-2]
    \arrow[""{name=1, anchor=center, inner sep=0}, curve={height=10pt}, from=1-1, to=1-2]
    \arrow[""{name=2, anchor=center, inner sep=0}, curve={height=-10pt}, from=1-2, to=1-3]
    \arrow[""{name=3, anchor=center, inner sep=0}, curve={height=10pt}, from=1-2, to=1-3]
    \arrow["\alpha"', color={rgb,255:red,0;green,24;blue,204}, shorten <=3pt, shorten >=3pt, Rightarrow, from=1, to=0]
    \arrow["\id"', shorten <=3pt, shorten >=3pt, Rightarrow, from=3, to=2]
  \end{tikzcd}}}
\newsavebox{\ehbeta}
\savebox{\ehbeta}{\adjustbox{scale=0.8}{
  \begin{tikzcd}[ampersand replacement=\&,column sep=small,cramped]
    \bullet \& \bullet \& \bullet
    \arrow[""{name=0, anchor=center, inner sep=0}, curve={height=-10pt}, from=1-1, to=1-2]
    \arrow[""{name=1, anchor=center, inner sep=0}, curve={height=10pt}, from=1-1, to=1-2]
    \arrow[""{name=2, anchor=center, inner sep=0}, curve={height=-10pt}, from=1-2, to=1-3]
    \arrow[""{name=3, anchor=center, inner sep=0}, curve={height=10pt}, from=1-2, to=1-3]
    \arrow["\id"',  shorten <=3pt, shorten >=3pt, Rightarrow, from=1, to=0]
    \arrow["\beta"', color={rgb,255:red,204;green,0;blue,14}, shorten <=3pt, shorten >=3pt, Rightarrow, from=3, to=2]
  \end{tikzcd}}}
\newsavebox{\ehlefttop}
\savebox{\ehlefttop}{
  \adjustbox{scale=1}{\begin{tikzcd}[ampersand replacement=\&,column sep=small,cramped]
     \bullet \& \bullet
     \arrow[""{name=0, anchor=center, inner sep=0}, controls=+(80:0.7) and +(100:0.7),, from=1-1, to=1-2]
     \arrow[""{name=1, anchor=center, inner sep=0}, curve={height=0}, from=1-1, to=1-2]
     \arrow[""{name=2, anchor=center, inner sep=0}, controls=+(100:-0.7) and +(80:-0.7),, from=1-1, to=1-2]
     \arrow["\alpha", color= blue, shorten <=3pt, shorten >=3pt, Rightarrow, from=2, to=1]
     \arrow["\id", shorten <=3pt, shorten >=3pt, Rightarrow, from=1, to=0]
   \end{tikzcd}}}
\newsavebox{\ehrighttop}
\savebox{\ehrighttop}{
  \adjustbox{scale=1}{\begin{tikzcd}[ampersand replacement=\&,column sep=small,cramped]
    \bullet \& \bullet
    \arrow[""{name=0, anchor=center, inner sep=0}, controls=+(80:0.7) and +(100:0.7), from=1-1, to=1-2]
    \arrow[""{name=1, anchor=center, inner sep=0}, curve={height=0}, from=1-1, to=1-2]
    \arrow[""{name=2, anchor=center, inner sep=0}, controls=+(100:-0.7) and +(80:-0.7),, from=1-1, to=1-2]
    \arrow["\id", shorten <=3pt, shorten >=3pt, Rightarrow, from=2, to=1]
    \arrow["\beta", color=red, shorten <=3pt, shorten >=3pt, Rightarrow, from=1, to=0]
  \end{tikzcd}}}
\newsavebox{\ehleftbot}
\savebox{\ehleftbot}{
  \adjustbox{scale=1}{\begin{tikzcd}[ampersand replacement=\&,column sep=small,cramped]
    \bullet \& \bullet
    \arrow[""{name=0, anchor=center, inner sep=0}, controls=+(80:0.7) and +(100:0.7),, from=1-1, to=1-2]
    \arrow[""{name=1, anchor=center, inner sep=0}, curve={height=0}, from=1-1, to=1-2]
    \arrow[""{name=2, anchor=center, inner sep=0}, controls=+(100:-0.7) and +(80:-0.7),, from=1-1, to=1-2]
    \arrow["\id", shorten <=3pt, shorten >=3pt, Rightarrow, from=2, to=1]
    \arrow["\alpha", color=blue, shorten <=3pt, shorten >=3pt, Rightarrow, from=1, to=0]
  \end{tikzcd}}}
\newsavebox{\ehrightbot}
\savebox{\ehrightbot}{
  \adjustbox{scale=1}{\begin{tikzcd}[ampersand replacement=\&,column sep=small,cramped]
    \bullet \& \bullet
    \arrow[""{name=0, anchor=center, inner sep=0}, controls=+(80:0.7) and +(100:0.7), from=1-1, to=1-2]
    \arrow[""{name=1, anchor=center, inner sep=0}, curve={height=0}, from=1-1, to=1-2]
    \arrow[""{name=2, anchor=center, inner sep=0}, controls=+(100:-0.7) and +(80:-0.7),, from=1-1, to=1-2]
    \arrow["\beta", color=red, shorten <=3pt, shorten >=3pt, Rightarrow, from=2, to=1]
    \arrow["\id", shorten <=3pt, shorten >=3pt, Rightarrow, from=1, to=0]
  \end{tikzcd}}}

\begin{figure}[h]
  \centering

  \[
    \begin{tikzcd}[ampersand replacement=\&,column sep=small]
      \bullet \&\& \bullet \& = \& \bullet \&\&\&\&\& \bullet \& = \& \bullet \&\&\& \bullet \&\&\& \bullet \\
      \\
      \&\&\&\&\&\&\&\&\&\&\&\&\&\& = \\
      \\
      \bullet \&\& \bullet \& = \& \bullet \&\&\&\&\& \bullet \& = \& \bullet \&\&\& \bullet \&\&\& \bullet
      \arrow[""{name=0, anchor=center, inner sep=0}, "\id", curve={height=-24pt}, from=1-1, to=1-3]
      \arrow[""{name=1, anchor=center, inner sep=0}, "\id"', curve={height=24pt}, from=1-1, to=1-3]
      \arrow[""{name=2, anchor=center, inner sep=0}, "\id"{description}, from=1-1, to=1-3]
      \arrow[""{name=3, anchor=center, inner sep=0}, draw=none, controls=+(90:1.8) and +(90:1.8), from=1-5, to=1-10]
      \arrow[""{name=4, anchor=center, inner sep=0}, draw=none, controls=+(90:-1.8) and +(90:-1.8), from=1-5, to=1-10]
      \arrow[""{name=5, anchor=center, inner sep=0}, from=1-5, to=1-10]
      \arrow[""{name=6, anchor=center, inner sep=0}, draw=none, controls=+(90:1.8) and +(90:1.8), from=5-5, to=5-10]
      \arrow[""{name=7, anchor=center, inner sep=0}, draw=none, controls=+(90:-1.8) and +(90:-1.8), from=5-5, to=5-10]
      \arrow[""{name=8, anchor=center, inner sep=0}, from=5-5, to=5-10]
      \arrow[""{name=9, anchor=center, inner sep=0}, "\id", curve={height=-24pt}, from=5-1, to=5-3]
      \arrow[""{name=10, anchor=center, inner sep=0}, "\id"', curve={height=24pt}, from=5-1, to=5-3]
      \arrow[""{name=11, anchor=center, inner sep=0}, "\id"{description}, from=5-1, to=5-3]
      \arrow[""{name=12, anchor=center, inner sep=0}, draw=none, controls=+(80:1.5) and +(100:1.5), from=1-12, to=1-15]
      \arrow[""{name=13, anchor=center, inner sep=0}, draw=none, controls=+(100:-1.5) and +(80:-1.5), from=1-12, to=1-15]
      \arrow[""{name=14, anchor=center, inner sep=0}, draw=none, controls=+(80:1.5) and +(100:1.5), from=1-15, to=1-18]
      \arrow[""{name=15, anchor=center, inner sep=0}, draw=none, controls=+(100:-1.5) and +(80:-1.5), from=1-15, to=1-18]
      \arrow[""{name=16, anchor=center, inner sep=0}, draw=none, controls=+(80:1.5) and +(100:1.5), from=5-12, to=5-15]
      \arrow[""{name=17, anchor=center, inner sep=0}, draw=none, controls=+(100:-1.5) and +(80:-1.5), from=5-12, to=5-15]
      \arrow[""{name=18, anchor=center, inner sep=0}, draw=none, controls=+(80:1.5) and +(100:1.5), from=5-15, to=5-18]
      \arrow[""{name=19, anchor=center, inner sep=0}, draw=none, controls=+(100:-1.5) and +(80:-1.5), from=5-15, to=5-18]
      \arrow["\alpha"', color={rgb,255:red,0;green,24;blue,204}, shorten <=3pt, shorten >=5pt, Rightarrow, from=1, to=2]
      \arrow["\beta"', color={rgb,255:red,204;green,0;blue,14}, shorten <=5pt, shorten >=3pt, Rightarrow, from=2, to=0]
      \arrow["\beta"', color={rgb,255:red,204;green,0;blue,14}, shorten <=3pt, shorten >=5pt, Rightarrow, from=10, to=11]
      \arrow["\alpha"', color={rgb,255:red,0;green,24;blue,204}, shorten <=5pt, shorten >=3pt, Rightarrow, from=11, to=9]
      \arrow["\usebox{\ehalpha}"{description,inner sep = 0,xshift = -1.2pt}, shorten <=3pt, shorten >=3pt, Rightarrow, from=4, to=5]
      \arrow["\usebox{\ehbeta}"{description,inner sep = 0,xshift = -1.2pt}, shorten <=3pt, shorten >=3pt, Rightarrow, from=5, to=3]
      \arrow["\usebox{\ehbeta}"{description,inner sep = 0,xshift = -1.2pt}, shorten <=3pt, shorten >=3pt, Rightarrow, from=7, to=8]
      \arrow["\usebox{\ehalpha}"{description,inner sep = 0,xshift = -1.2pt}, shorten <=3pt, shorten >=3pt, Rightarrow, from=8, to=6]
      \arrow["\usebox{\ehlefttop}"{description,inner sep = 0,xshift = -1.3pt, yshift = 0.2pt}, shorten <=3pt, shorten >=3pt, Rightarrow, from=13, to=12]
      \arrow["\usebox{\ehrighttop}"{description,inner sep = 0,xshift = -1.3pt,yshift = 0.2pt}, shorten <=3pt, shorten >=3pt, Rightarrow, from=15, to=14]
      \arrow["\usebox{\ehleftbot}"{description,inner sep = 0,xshift = -1.3pt}, shorten <=3pt, shorten >=3pt, Rightarrow, from=17, to=16]
      \arrow["\usebox{\ehrightbot}"{description,inner sep = 0,xshift = -1.3pt}, shorten <=3pt, shorten >=3pt, Rightarrow, from=19, to=18]
      \arrow[controls=+(90:1.8) and +(90:1.8), from=1-5, to=1-10]
      \arrow[controls=+(90:-1.8) and +(90:-1.8), from=1-5, to=1-10]
      \arrow[controls=+(90:1.8) and +(90:1.8), from=5-5, to=5-10]
      \arrow[controls=+(90:-1.8) and +(90:-1.8), from=5-5, to=5-10]
      \arrow[controls=+(80:1.5) and +(100:1.5), from=1-12, to=1-15]
      \arrow[controls=+(100:-1.5) and +(80:-1.5), from=1-12, to=1-15]
      \arrow[controls=+(80:1.5) and +(100:1.5), from=1-15, to=1-18]
      \arrow[controls=+(100:-1.5) and +(80:-1.5), from=1-15, to=1-18]
      \arrow[controls=+(80:1.5) and +(100:1.5), from=5-12, to=5-15]
      \arrow[controls=+(100:-1.5) and +(80:-1.5), from=5-12, to=5-15]
      \arrow[controls=+(80:1.5) and +(100:1.5), from=5-15, to=5-18]
      \arrow[controls=+(100:-1.5) and +(80:-1.5), from=5-15, to=5-18]
    \end{tikzcd}
  \]
  \caption{The Eckmann-Hilton argument}
  \label{fig:eh}
\end{figure}

\subsection{Pasting diagrams}
\label{sec:pasting-diagrams}

The definition of \(\infty\)-categories given in the previous section is close in spirit to the the ordinary definitions of 1-categories and clearly demonstrates the different families of axioms present. However, we will see in \cref{sec:weak}, that these sort of definitions do not scale well to our eventual setting of weak higher categories.

There is a special class of (finite) globular sets known as \emph{pasting diagrams} (sometimes known as pasting schemes). The elements of the free strict \(\infty\)-category on a globular set \(G\) can instead be represented by a pasting diagram and a map from this pasting diagram into \(G\). To do this, it must be possible to obtain a canonical composite from each pasting diagram.

Informally, we can define a \(n\)-dimensional pasting diagram to be a finite globular set which admits a unique full composite of dimension \(n\), where a full composite of a globular set \(G\) is an element of the free \(\infty\)-category over \(G\) which uses all the maximal elements. This functions as the primary intuition on the role of pasting diagrams.

Pasting diagrams were used directly by \citeauthor{batanin1998monoidal}~\cite{batanin1998monoidal} to give a defintion of weak \(\infty\)-categories, and will be pivotal in \cref{sec:weak} to define the variety of higher categories that \Catt is based on. A more indepth discussion of pasting diagrams, representations of free strict \(\infty\)-categories using them, and their use in the definition of weak higher categories can be found in \citetitle{leinster2004higher}~\cite{leinster2004higher}.

Before giving a more formal definition of pasting diagrams, we explore some examples and non-examples. In contrast to \citeauthor{leinster2004higher}, we consider pasting diagrams as a full subcategory of globular sets, rather than a separate category with a function sending each pasting diagram to a globular set.

The disc contexts introduced in \cref{ex:disc} are all examples of pasting diagrams. The unique ``composite'' of these globular sets is just given by their maximal element, noting that we allow a singular cell in our informal definition of composite. The uniqueness of this is trivial as the only possible operations we could apply are compositions with units, which gives the same cell under the laws of an \(\infty\)-category.

The diagrams used to graphically represent our composition operations (of which we recall three below) are also pasting diagrams.

\[
  \begin{tikzcd}
    x & y & z
    \arrow["f", from=1-1, to=1-2]
    \arrow["g", from=1-2, to=1-3]
  \end{tikzcd}
  \qquad
  \begin{tikzcd}
    x && y
    \arrow[""{name=0, anchor=center, inner sep=0}, "f"', curve={height=24pt}, from=1-1, to=1-3]
    \arrow[""{name=1, anchor=center, inner sep=0}, "h", curve={height=-24pt}, from=1-1, to=1-3]
    \arrow[""{name=2, anchor=center, inner sep=0}, "g"{description}, from=1-1, to=1-3]
    \arrow["\alpha", shorten <=3pt, shorten >=3pt, Rightarrow, from=0, to=2]
    \arrow["\beta", shorten <=3pt, shorten >=3pt, Rightarrow, from=2, to=1]
  \end{tikzcd}
  \qquad
    \begin{tikzcd}
    x & y & z
    \arrow[""{name=0, anchor=center, inner sep=0}, "g", curve={height=-18pt}, from=1-1, to=1-2]
    \arrow[""{name=1, anchor=center, inner sep=0}, "f"', curve={height=18pt}, from=1-1, to=1-2]
    \arrow[""{name=2, anchor=center, inner sep=0}, "i", curve={height=-18pt}, from=1-2, to=1-3]
    \arrow[""{name=3, anchor=center, inner sep=0}, "h"', curve={height=18pt}, from=1-2, to=1-3]
    \arrow["\alpha", shorten <=5pt, shorten >=5pt, Rightarrow, from=1, to=0]
    \arrow["\beta", shorten <=5pt, shorten >=5pt, Rightarrow, from=3, to=2]
  \end{tikzcd}
\]

The composite of these diagrams is just the composite of the two maximal cells with the appropriate codimension.

We can also consider composites which are not binary composites of two cells of equal dimension. For example the following globular set is a pasting diagram:

\[
  \begin{tikzcd}
    x & y & z
    \arrow[""{name=0, anchor=center, inner sep=0}, "g", curve={height=-18pt}, from=1-1, to=1-2]
    \arrow[""{name=1, anchor=center, inner sep=0}, "f"', curve={height=18pt}, from=1-1, to=1-2]
    \arrow["h", from=1-2, to=1-3]
    \arrow["\alpha", shorten <=5pt, shorten >=5pt, Rightarrow, from=1, to=0]
  \end{tikzcd}
\]
with a composite given by \(\alpha *_0 \id(h)\). This operation is fairly common (in fact we have already seen it in \cref{prop:eh}) and is known as \emph{whiskering}. In this case we would say that the composite is given by the right whiskering of \(\alpha\) with \(h\).

The 1-dimensional pasting diagrams are all given by chains of 1-cells of the form:
\[x_0 \overset{f_0}\to x_1 \overset{f_1}\to x_2 \overset{f_2}\to \cdots \overset{f_n}\to x_{n+1}\]
There are multiple ways to form a composite over these diagrams by repeated binary composition, however these all have the same result due to associativity.

Lastly we look at the diagram, where all the \(0\)-cells and \(1\)-cells are assumed to be distinct:

\[
  \begin{tikzcd}[column sep = large]
    \bullet & \bullet & \bullet
    \arrow[""{name=0, anchor=center, inner sep=0}, curve={height=-30pt}, from=1-1, to=1-2]
    \arrow[""{name=1, anchor=center, inner sep=0}, curve={height=30pt}, from=1-1, to=1-2]
    \arrow[""{name=2, anchor=center, inner sep=0}, from=1-1, to=1-2]
    \arrow[""{name=3, anchor=center, inner sep=0}, curve={height=-30pt}, from=1-2, to=1-3]
    \arrow[""{name=4, anchor=center, inner sep=0}, curve={height=30pt}, from=1-2, to=1-3]
    \arrow[""{name=5, anchor=center, inner sep=0}, from=1-2, to=1-3]
    \arrow["\alpha", shorten <=4pt, shorten >=4pt, Rightarrow, from=1, to=2]
    \arrow["\beta", shorten <=4pt, shorten >=4pt, Rightarrow, from=2, to=0]
    \arrow["\gamma", shorten <=4pt, shorten >=4pt, Rightarrow, from=4, to=5]
    \arrow["\delta", shorten <=4pt, shorten >=4pt, Rightarrow, from=5, to=3]
  \end{tikzcd}
\]

We get a composite given by \((\alpha *_1 \beta) *_0 (\gamma *_1 \delta)\). The uniqueness of this composite is due to the interchange law.

Non-examples of pasting diagrams roughly fall into two groups: those that do not admit a composite, and those that admit many distinct composites. The following three globular sets fail to admit a composite (the last is drawn in a box to emphasise that \(z\) is part of the same globular set as \(x\), \(y\), \(f\), \(g\), and \(\alpha\)):

\[
  \begin{tikzcd}[column sep=large, row sep = small]
    & y \\
    x \\
    & z
    \arrow["f", pos=0.6, from=2-1, to=1-2]
    \arrow["g"', pos=0.6, from=2-1, to=3-2]
  \end{tikzcd}
  \qquad
  \begin{tikzcd}[column sep=large]
    x & y
    \arrow["f", curve={height=-12pt}, from=1-1, to=1-2]
    \arrow["g"', curve={height=12pt}, from=1-1, to=1-2]
  \end{tikzcd}
  \qquad
  \fbox{\begin{tikzcd}[column sep=scriptsize, ampersand replacement = \&]
    x \&\& y \& z
    \arrow[""{name=0, anchor=center, inner sep=0}, "f", curve={height=-18pt}, from=1-1, to=1-3]
    \arrow[""{name=1, anchor=center, inner sep=0}, "g"', curve={height=18pt}, from=1-1, to=1-3]
    \arrow["\alpha", shorten <=5pt, shorten >=5pt, Rightarrow, from=1, to=0]
  \end{tikzcd}}
\]
The globular set with a single \(0\)-cell \(x\), and a single \(1\)-cell \(f : x \to x\) has too many composites: \(f\) and \(f *_0 f\) need not be equal in an infinity category.

To describe the free \(\infty\)-category in terms of pasting diagrams we need to be able to extract a composite from a pasting diagram, and construct a pasting diagram from an arbitrary composite. Each pasting diagram having a unique composite solves the former issue.

To be able to construct a pasting diagram from a composite, we wish to equip our set of pasting diagrams itself with the structure of an \(\infty\)-category. We therefore need our pasting diagrams to have a notion of boundary and a notion of composition. A natural candidate for composition is given by colimits, as \(\mathbf{Glob}\) has all colimits due to being a presheaf category, and so it is sufficient for our class of pasting diagrams to be closed under these specific colimits. In fact, it is sufficient to contain a class of colimits known as \emph{globular sums}.

\begin{definition}
  A globular category is a category \(\mathcal{C}\), equipped with a disc functor \(D : \mathbf{G} \to \mathcal{C}\), specifying certain objects as discs in the category. A \emph{globular sum} is a colimit of a diagram of the form:
  \[
    \begin{tikzcd}[column sep = tiny, row sep = tiny]
      {D(i_0)} && {D(i_1)} && {D(i_2)} && {D(i_n)} && {D(i_{n+1})} \\
      &&&&& \cdots \\
      & {D(j_0)} && {D(j_1)} &&&& {D(j_n)}
      \arrow["{f_0}", from=3-2, to=1-1]
      \arrow["{g_0}"', from=3-2, to=1-3]
      \arrow["{f_n}", from=3-8, to=1-7]
      \arrow["{g_n}"', from=3-8, to=1-9]
      \arrow["{f_1}", from=3-4, to=1-3]
      \arrow["{g_1}"', from=3-4, to=1-5]
    \end{tikzcd}
  \]
  Where all morphisms \(f_i\) are a composite of source maps (\(D(\mathbf{s}_n)\) for some \(n\)) and the morphisms \(g_i\) are a composite of target maps (\(D(\mathbf{t}_n)\) for some \(n\)). Given that the maps \(f_i\) and \(g_i\) are uniquely determined, we may write such a globular sum as:

  \[ D(i_0) \amalg_{D(j_0)} D(i_1) \amalg_{D(j_1)} D(i_2) \cdots D(i_n) \amalg_{D(j_n)} D(i_{n+ 1})\]

  A \emph{globular extension} is a globular category where all globular sums exist, and a morphism of globular extensions is a functor of the underlying categories commuting with the disc functors and preserving globular sums.
\end{definition}

We can finally give our first definition of a pasting diagram.

\begin{definition}
  The category \(\mathbf{Glob}\) is a globular category with functor \(\mathbf{G} \to \mathbf{Glob}\) given by the Yoneda embedding. The category of \emph{pasting diagrams}, \(\mathbf{Pd}\), is the full subcategory containing the globular sets which are globular sums.
  The boundary of an \((n+1)\)-dimensional pasting diagram is given by replacing each instance of \(D^{n+1}\) by \(D^n\) in its globular sum representation. There are two canonical maps including the boundary into the original pasting diagram, whose images give the source and target of the pasting diagram.
\end{definition}

The category of pasting diagrams clearly forms a globular category, with the functor \(\mathbf{G} \to \mathbf{Pd}\) sending \(n\) to \(D^n\). It is a globular extension and is in fact the universal globular extension; it is initial in the category of globular extensions~\cite{Ara}.

We finish this section with one larger example.

\begin{example}
  The following depicts a \(2\)-dimensional pasting diagram.
  \[
    \begin{tikzcd}
      x & y & z & w
      \arrow[""{name=0, anchor=center, inner sep=0}, "g", curve={height=-18pt}, from=1-1, to=1-2]
      \arrow[""{name=1, anchor=center, inner sep=0}, "f"', curve={height=18pt}, from=1-1, to=1-2]
      \arrow["h"', from=1-2, to=1-3]
      \arrow[""{name=2, anchor=center, inner sep=0}, "k", curve={height=-24pt}, from=1-3, to=1-4]
      \arrow[""{name=3, anchor=center, inner sep=0}, "i"', curve={height=24pt}, from=1-3, to=1-4]
      \arrow[""{name=4, anchor=center, inner sep=0}, "j"{description}, from=1-3, to=1-4]
      \arrow["\alpha", shorten <=5pt, shorten >=5pt, Rightarrow, from=1, to=0]
      \arrow["\beta", shorten <=3pt, shorten >=3pt, Rightarrow, from=3, to=4]
      \arrow["\gamma", shorten <=3pt, shorten >=3pt, Rightarrow, from=4, to=2]
    \end{tikzcd}
  \]
  which has the following globular sum decomposition:
  % https://q.uiver.app/#q=WzAsMTMsWzAsMCwieCJdLFsyLDAsInkiXSxbOCwwLCJ6Il0sWzEwLDAsInciXSxbMywxLCJ5Il0sWzQsMCwieSJdLFs2LDAsInoiXSxbNywxLCJ6Il0sWzksMF0sWzEwLDEsInoiXSxbMTIsMSwidyJdLFsxMiwwLCJ6Il0sWzE0LDAsInciXSxbMCwxLCJnIiwwLHsiY3VydmUiOi0zfV0sWzAsMSwiZiIsMix7ImN1cnZlIjozfV0sWzIsMywiaSIsMix7ImN1cnZlIjo0fV0sWzIsMywiaiIsMV0sWzUsNiwiaCIsMl0sWzQsMSwiIiwyLHsic3R5bGUiOnsiYm9keSI6eyJuYW1lIjoiZGFzaGVkIn19fV0sWzQsNSwiIiwxLHsic3R5bGUiOnsiYm9keSI6eyJuYW1lIjoiZGFzaGVkIn19fV0sWzksMTAsImoiLDFdLFsxMSwxMiwiaiIsMV0sWzExLDEyLCJrIiwxLHsiY3VydmUiOi00fV0sWzcsNiwiIiwwLHsic3R5bGUiOnsiYm9keSI6eyJuYW1lIjoiZGFzaGVkIn19fV0sWzcsMiwiIiwwLHsic3R5bGUiOnsiYm9keSI6eyJuYW1lIjoiZGFzaGVkIn19fV0sWzE0LDEzLCJcXGFscGhhIiwwLHsic2hvcnRlbiI6eyJzb3VyY2UiOjIwLCJ0YXJnZXQiOjIwfX1dLFsxNSwxNiwiXFxiZXRhIiwwLHsic2hvcnRlbiI6eyJzb3VyY2UiOjIwLCJ0YXJnZXQiOjIwfX1dLFsyMSwyMiwiXFxnYW1tYSIsMCx7InNob3J0ZW4iOnsic291cmNlIjoyMCwidGFyZ2V0IjoyMH19XSxbMjAsMywiIiwxLHsic2hvcnRlbiI6eyJzb3VyY2UiOjIwfSwibGV2ZWwiOjEsInN0eWxlIjp7ImJvZHkiOnsibmFtZSI6ImRhc2hlZCJ9fX1dLFsyMCwxMSwiIiwxLHsic2hvcnRlbiI6eyJzb3VyY2UiOjIwfSwibGV2ZWwiOjEsInN0eWxlIjp7ImJvZHkiOnsibmFtZSI6ImRhc2hlZCJ9fX1dXQ==
  \[
    \begin{tikzcd}[column sep=small, row sep = small]
      x && y && y && z && z & {} & w && z && w \\
      &&& y &&&& z &&& z && w
      \arrow[""{name=0, anchor=center, inner sep=0}, "g", curve={height=-18pt}, from=1-1, to=1-3]
      \arrow[""{name=1, anchor=center, inner sep=0}, "f"', curve={height=18pt}, from=1-1, to=1-3]
      \arrow[""{name=2, anchor=center, inner sep=0}, "i"', curve={height=24pt}, from=1-9, to=1-11]
      \arrow[""{name=3, anchor=center, inner sep=0}, "j"{description}, from=1-9, to=1-11]
      \arrow["h"', from=1-5, to=1-7]
      \arrow[dashed, from=2-4, to=1-3]
      \arrow[dashed, from=2-4, to=1-5]
      \arrow[""{name=4, anchor=center, inner sep=0}, "j"{description}, from=2-11, to=2-13]
      \arrow[""{name=5, anchor=center, inner sep=0}, "j"{description}, from=1-13, to=1-15]
      \arrow[""{name=6, anchor=center, inner sep=0}, "k"{description}, curve={height=-24pt}, from=1-13, to=1-15]
      \arrow[dashed, from=2-8, to=1-7]
      \arrow[dashed, from=2-8, to=1-9]
      \arrow["\alpha", shorten <=5pt, shorten >=5pt, Rightarrow, from=1, to=0]
      \arrow["\beta", shorten <=3pt, shorten >=3pt, Rightarrow, from=2, to=3]
      \arrow["\gamma", shorten <=3pt, shorten >=3pt, Rightarrow, from=5, to=6]
      \arrow[shorten <=6pt, dashed, from=4, to=1-11]
      \arrow[shorten <=6pt, dashed, from=4, to=1-13]
    \end{tikzcd}
  \]
  The source and target of the diagram are given by:
  \[
    \begin{tikzcd}
      x & y & z & w
      \arrow["g", curve={height=-18pt}, from=1-1, to=1-2]
      \arrow["h", from=1-2, to=1-3]
      \arrow["k", curve={height=-24pt}, from=1-3, to=1-4]
    \end{tikzcd}
    \qquad\text{and}\qquad
    \begin{tikzcd}
      x & y & z & w
      \arrow["f"', curve={height=18pt}, from=1-1, to=1-2]
      \arrow["h", from=1-2, to=1-3]
      \arrow["i"', curve={height=24pt}, from=1-3, to=1-4]
    \end{tikzcd}
  \]
  which are isomorphic pasting diagrams.
\end{example}

\subsection{Weak higher categories}
\label{sec:weak}

The \(\infty\)-categories we have defined so far have all been strict \(\infty\)-categories, meaning that the laws are required to hold up to equality. In ordinary \(1\)-category theory, isomorphism is usually preferred over equality for comparing objects. Similarly, when we have access to higher dimensional arrows, it follows that that we can also consider isomorphisms between morphisms, and therefore consider laws such as associativity up to isomorphism instead of equality.

Topological spaces provide one of the primary examples for where it is useful to consider weak laws. Given a topological space \(X\), we can define a globular set of paths and homotopies. Let the \(0\)-cells be given by points \(x\) of the topological space, let morphisms from \(x\) to \(y\) be given as paths \(I \to X\) (where \(I\) is the topological interval \([0,1]\)) which send \(0\) to \(x\) and \(1\) to \(y\), and let higher cells be given by homotopies. The natural composition of two paths \(p\) and \(q\) is the following path:
\[
  (p * q)(i) =
  \begin{cases*}
    p(2i)&when \(i < 0.5\)\\
    q(2i-1)&when \(i \geq 0.5\)
  \end{cases*}
\]
which effectively lines up the paths end to end. Given \(3\) paths \(p\), \(q\), and \(r\), the compositions \((p * q) * r\) and \(p * (q * r)\) are not identical but are equal up to homotopy, meaning the two compositions are isomorphic. Therefore in this case the composition \(p * q\) does not form a strict \(\infty\)-category structure, but rather a weak structure.

\paragraph{Weak 2-categories} We start our exploration of weak higher categories by considering the lower dimension case of bicategories (weak \(2\)-categories). Here, interchange must still be given by a strict equality, as there are no non-trivial \(3\)-cells in a \(2\)-category. However, associativity and unitality can be given by isomorphisms known as associators and unitors:
\begin{align*}
  \alpha_{f,g,h} &: (f *_0 g) *_0 h \to f *_0 (g *_0 h)\\
  \lambda_f &: \id(x) *_0 f \to f\\
  \rho_f &: f *_0 \id(y) \to f
\end{align*}
for \(f : x \to y\), \(g : y \to z\), and \(h : z \to w\).

\begin{example}
  \label{ex:spans}
  All strict 2-categories are also bicategories. The bicategory of spans is an example of a bicategory which is not strict. Starting with a category \(\mathcal{C}\) equipped with chosen pullbacks, we define the bicategory of spans over \(\mathcal{C}\) to be:
  \begin{itemize}
  \item Objects are the same as \(\mathcal{C}\)
  \item Morphisms \(A\) to \(B\) are spans \(A \leftarrow C \to B\).
  \item A 2-morphism from \(A \leftarrow C \to B\) to \(A \leftarrow C' \to B\) is a morphism \(C \to C'\) such that the following diagram commutes:
    \[
      \begin{tikzcd}[row sep = small]
	& C \\
	A && B \\
	& {C'}
	\arrow[from=1-2, to=3-2]
	\arrow[from=3-2, to=2-1]
	\arrow[from=1-2, to=2-1]
	\arrow[from=1-2, to=2-3]
	\arrow[from=3-2, to=2-3]
      \end{tikzcd}
    \]
  \item Compositions and identities of 2-morphisms is given by composition and identities of the underlying morphisms in \(\mathcal{C}\).
  \item The identity on an object \(A\) is the span \(A \leftarrow A \to A\).
  \item Given spans \(A \leftarrow D \to B\) and \(B \leftarrow E \to C\), their composite is given by the pullback:
    \[
      \begin{tikzcd}[row sep=small]
	&& {D \times_B E} \\
	& D && E \\
	A && B && C
	\arrow[from=2-2, to=3-1]
	\arrow[from=2-2, to=3-3]
	\arrow[from=2-4, to=3-3]
	\arrow[from=2-4, to=3-5]
	\arrow[from=1-3, to=2-2]
	\arrow[from=1-3, to=2-4]
	\arrow["\lrcorner"{anchor=center, pos=0.125, rotate=-45}, draw=none, from=1-3, to=3-3]
      \end{tikzcd}
    \]
  \item Associators and unitors are given by the universal property of the pullback.
  \end{itemize}
\end{example}

In general, there could be many possible isomorphisms between \((f * g) * h\) and \(f * (g * h)\), and we require that the chosen morphisms satisfy certain compatibility properties. The first is that each of the associator, left unitor, and right unitor should be a natural isomorphism. The second is a property known as \emph{coherence}, saying that any two parallel morphisms built purely from naturality moves, associators, and unitors must be equal.

For bicategories it is sufficient to give two coherence laws: the triangle equality and pentagon equality. The triangle equality identifies two ways of cancelling the identity in the composite \(f * \id * g\), giving a compatibility between the left and right unitors. It is given by the following commutative diagram:

% https://q.uiver.app/#q=WzAsMyxbMCwwLCIoZiBcXHN0YXIgXFxpZCkgXFxzdGFyIGciXSxbMiwwLCJmIFxcc3RhciAoXFxpZCBcXHN0YXIgZykiXSxbMSwxLCJmIFxcc3RhciBnIl0sWzAsMSwiXFxhbHBoYV97ZixcXGlkLGd9Il0sWzAsMiwiXFxyaG9fZiBcXHN0YXJfMCBcXGlkKGcpIiwyXSxbMSwyLCJcXGlkKGYpXFxzdGFyXzBcXGxhbWJkYV9nIl1d
\[
  \begin{tikzcd}
    {(f * \id) * g} && {f * (\id * g)} \\
    & {f * g}
    \arrow["{\alpha_{f,\id,g}}", from=1-1, to=1-3]
    \arrow["{\rho_f *_0 \id(g)}"', from=1-1, to=2-2]
    \arrow["{\id(f)*_0\lambda_g}", from=1-3, to=2-2]
  \end{tikzcd}
\]

The pentagon equation identifies two ways of associating \(((f * g) * h) * k\) to \(f * (g * (h * k))\). It is given by the diagram below:
% https://q.uiver.app/#q=WzAsNSxbMSwzLCIoZiBcXHN0YXIgKGcgXFxzdGFyIGgpKSBcXHN0YXIgayJdLFswLDEsIigoZiBcXHN0YXIgZykgXFxzdGFyIGgpIFxcc3RhciBrIl0sWzIsMCwiKGYgXFxzdGFyIGcpIFxcc3RhciAoaCBcXHN0YXIgaykiXSxbNCwxLCJmIFxcc3RhciAoZyBcXHN0YXIgKGggXFxzdGFyIGspKSJdLFszLDMsImYgXFxzdGFyICgoZyBcXHN0YXIgaCkgXFxzdGFyIGspIl0sWzEsMiwiXFxhbHBoYV97ZiBcXHN0YXIgZyxoLGt9Il0sWzIsMywiXFxhbHBoYV97ZixnLGhcXHN0YXIga30iXSxbMSwwLCJcXGFscGhhX3tmLGcsaH0gXFxzdGFyXzAgXFxpZChrKSIsMl0sWzAsNCwiXFxhbHBoYV97ZixnXFxzdGFyIGgsa30iLDJdLFs0LDMsIlxcaWQoZilcXHN0YXJfMCBcXGFscGhhX3tnLGgsa30iLDJdXQ==
\[
  \begin{tikzcd}[column sep = -1.5em]
    && {(f * g) * (h * k)} \\
    {((f * g) * h) * k} &&&& {f * (g * (h * k))} \\
    \\
    & {(f * (g * h)) * k} && {f * ((g * h) * k)}
    \arrow["{\alpha_{f * g,h,k}}", from=2-1, to=1-3]
    \arrow["{\alpha_{f,g,h* k}}", from=1-3, to=2-5]
    \arrow["{\alpha_{f,g,h} *_0 \id(k)}"', from=2-1, to=4-2]
    \arrow["{\alpha_{f,g* h,k}}"', from=4-2, to=4-4]
    \arrow["{\id(f)*_0 \alpha_{g,h,k}}"', from=4-4, to=2-5]
  \end{tikzcd}
\]

Surprisingly, these two equations are enough to give full coherence. For the example of spans from \cref{ex:spans}, these two equations follow from the uniqueness of the universal morphism.

\paragraph{Weak \(\infty\)-categories} To move from weak \(2\)-categories to weak \(3\)-categories, new coherence cells for interchangers are added to replace the interchanger equalities, and new equalities must be added to specify the interaction between the interchangers and other coherence morphisms. Furthermore, the triangle and pentagon equation from \(2\)-categories will become an isomorphisms in a weak \(3\)-category, causing more coherence equations to be added.

As we move up in dimension, the number of coherence morphisms and equalities required increases exponentially. Whereas a bicategory has 11 operations (1-identity, 2-identity, 1-composition, vertical composition, horizontal composition, left unitor (and inverse), right unitor (and inverse), and associator (and inverse)), where as a fully weak tricategory already has around 51 operations~\cite{gurski2006algebraic}\footnote{The number here is obtained by unwrapping various subdefinitions and should be treated as approximate.}. Comparisons between the size of partially weak definitions can be found in \cite{bar2017data}.

Because of this complexity, we look for more uniform ways to represent the operations and axioms of an \(\infty\)-category. In this thesis, we will work with the type theory \Catt, which is based on a definition of \(\infty\)-categories due to \citeauthor{maltsiniotis2010grothendieck}~\cite{maltsiniotis2010grothendieck}, which is itself based on a definition of \(\infty\)-groupoid by \citeauthor{PursuingStacks}~\cite{PursuingStacks}. We will sketch the ideas behind these definitions here, and give a definition of \Catt in \cref{sec:type-theory-catt}.

The key insight behind Grothendieck's definition is that pasting diagrams should be weakly contractible, instead of containing a unique composite. Whereas in a strict \(\infty\)-category, each pasting diagram effectively has 1 composite, in a weak \(\infty\)-category there can be many operations over a pasting diagram.

These operations are assembled into a globular extension called a \emph{coherator}. A weak \(\infty\)-groupoid is then a presheaf on this coherator for which the opposite functor preserves globular sums (alternatively, the dual notion of globular product could be defined, and such a presheaf could be asked to preserve globular products). The objects of a coherator are given by pasting diagrams, with \(D^n\) being sent to the \(n\)-cells of the category and other pasting diagrams being sent to composable sets of cells (as determined by the preservation of globular sums).

Operations over a pasting diagram \(P\) in the coherator are given by morphisms \(D^n \to P\). When we take a presheaf over this, we obtain a function that takes an \(P\)-shaped collection of cells to a single \(n\)-cell. Operations can be precomposed with source and target maps \(D^{n-1} \to D^n\) to get the source and target of an operation. To build the coherator, we start by taking the category of pasting diagrams. The ``operations'' of this category consist solely of the inclusions of discs into pasting diagrams, and correspond to picking a single element from the pasting diagram. Other operations are then built using the following guiding principle.

\begin{principle-groupoid}
  Let \(f\) and \(g\) be two parallel operations over a pasting diagram \(P\). Then there is an operation \(h\) over \(P\) with source \(f\) and target \(g\).
\end{principle-groupoid}

We define a pair of operations \(f,g : D^n \to X\) to be \emph{parallel} if \(n = 0\) or \(n > 0\) and \(f \circ \mathbf{s}_{n-1} = g \circ \mathbf{s}_{n-1}\) and \(f \circ \mathbf{t}_{n-1} = g \circ \mathbf{t}_{n-1}\). A \emph{lift} for such a pair of parallel operations is an operation \(h : D^{n+1} \to X\) such that \(h \circ \mathbf{s}_{n} = f\) and \(h \circ \mathbf{t}_n = g\). Closing under the principle then amounts to inductively adding lifts for all parallel operations, while ensuring that the category remains a globular extension.

We start with some basic operations: Consider the pasting diagram \(A\):

\[
  \begin{tikzcd}
    x & y & z
    \arrow["a", from=1-1, to=1-2]
    \arrow["b", from=1-2, to=1-3]
  \end{tikzcd}
\]

where \(A = D^1 \amalg D^1\). Our rule now tells us that since \(x\) and \(z\) are elements of \(A\), that there should be an operation returning a cell with source \(x\) and target \(z\), namely the composition of \(a\) and \(b\). In the language of coherators, there are operations \(f, g : D^0 \to A\), where \(f\) includes into the source of the first disc of \(A\), and \(g\) includes into the target of the second disc of \(A\). These are trivially parallel, and so there exists a lift \(h : D^1 \to A\), giving 1-composition. Similarly, if we take the pasting diagram with a single \(0\)-cell \(x\) and no other cells, then applying our rule with \(f,g\) both being the operation returning the element \(x\) produces an operation with source and target \(x\), the identity on \(x\).

We can generate more complicated operations with this principle, consider pasting diagram \(B\):
\[
  \begin{tikzcd}
    x & y & z & w
    \arrow["f", from=1-1, to=1-2]
    \arrow["g", from=1-2, to=1-3]
    \arrow["h", from=1-3, to=1-4]
  \end{tikzcd}
\]
We already know the coherator contains 1-composition, and using composition and the universal property of globular sums, we can generate operations realising the compound composites \((f * g) * h\) and \(f * (g * h)\). The principle then gives us an operation returning the \(2\)-cell \((f * g) * h \to f * (g * h)\), which is of course our associator. This one principle allows us to generate all the structure we need, as well as structure that is arguably unnecessary, such as ternary compositions that did not appear in the definition of bicategory.

Unfortunately, as we have already mentioned, Grothendieck's definition is for \(\infty\)-groupoids, where everything is invertible, instead of \(\infty\)-categories in full generality, as we want to study in this thesis. This can be seen by taking the pasting diagram \(C\):
\[
  \begin{tikzcd}
    x & y
    \arrow["f", from=1-1, to=1-2]
  \end{tikzcd}
\]
and applying the rule with \(f\) returning \(y\) and \(g\) returning \(x\), giving an operation that returns a \(1\)-cell \(f^{-1} : y \to x\), the inverse of \(f\). The rule as we have stated it is too powerful.

Maltsiniotis' definition provides a solution to this problem by giving a more refined version of the principle. Whereas Grothendieck's definition treats all operations as coherences, Maltsiniotis' definition splits operations into two classes: compositions and equivalences. Both classes are obtained by restricting the classes of parallel operations that admit lifts.

We begin by defining what it means for an operation to be algebraic:
\begin{definition}
  Let \(\mathcal{C}\) be a globular extension for which the canonical functor \(P : \mathbf{Pd} \to \mathcal{C}\) is faithful and the identity on objects. Then an operation \(f : D^n \to X\) in \(\mathcal{C}\) is \emph{algebraic} if whenever \(f = P(g) \circ f'\), \(g = \id\).
\end{definition}
Intuitively, an operation is algebraic when it does not factor through any proper inclusion. Algebraicity is equivalent to requiring that an operation makes use of all the (locally maximal) elements of the pasting diagram.

Equivalences contain the various invertible laws of our \(\infty\)-categories such as associators, unitors, identities, and interchangers. For two operations \(f,g : D^n \to X\) to admit a lift under the rule for equivalences, they must both be algebraic. This gives the following rule:

\begin{principle-category}[Equivalences]
  Let \(f\) and \(g\) be two parallel operations over a pasting diagram \(P\). If both \(f\) and \(g\) use all locally maximal variables of \(f\), then there is an operation over \(P\) with source \(f\) and target \(g\).
\end{principle-category}

Clearly any operations generated by this principle are invertible, as the extra condition imposed is symmetric. For compositions we introduce the following asymmetric principle, recalling that pasting diagrams are equipped with source and target inclusions, and letting \(\partial^-(P)\) and \(\partial^+(P)\) be the images of these inclusions:

\begin{principle-category}[Composites]
  Let \(f\) and \(g\) are parallel operations over a (non-singleton) pasting diagram \(P\) such that \(f\) uses all locally maximal cells of \(\partial^-(P)\) and no cells outside of \(\partial^-(P)\) and \(g\) uses all locally maximal cells of \(\partial^+(P)\) and no cells outside of \(\partial^+(P)\). Then there is an operation over \(P\) with source \(f\) and target \(g\).
\end{principle-category}

The condition required to form a composite can be expressed by the operation \(f : D^n \to P\) factoring into an algebraic map composed with the source inclusion into \(P\), and similar for \(g\) with the target inclusion. It can be easily checked that the inverse operation given above does not satisfy the criteria for being an equivalence or composite.

As with Grothendieck's definition, a coherator can be made by closing the globular extension of pasting diagrams under these restricted principles, and then weak \(\infty\)-categories can be defined to be presheaves on this coherator such that the opposite functor preserves globular sums.

\begin{remark}
  We have claimed that a coherator can be formed by closing under adding lifts to parallel operations, though this is not precise and there are actually multiple ways of performing this closure that lead to different coherators. For example, one could add the lift for 1-composition twice, to get two distinct 1-composition operations, as long as one also added a lift between these now parallel operations. Grothendieck gives a general schema for producing coherators, and conjectures that any two coherators give rise to equivalent models of \(\infty\)-categories.
\end{remark}

We now turn our attention back to the proof of Eckmann-Hilton from \cref{fig:eh}. Given a \(0\)-cell \(x\) and two scalars \(\alpha, \beta : \id(x) \to \id(x)\), we expect the Eckmann-Hilton argument to give us an isomorphism in a weak higher category, rather than the equality obtained in the strict case. In fact we immediately see that equalities 2, 3, and 4 in the proof can be immediately replaced by isomorphisms (interchangers and unitors).

The first and last equalities however are more problematic, although at first we may believe that there should exist some horizontal unitor isomorphism, upon closer inspection the two compositions do not even have the same boundary and so are not parallel. The composition \(\alpha *_1 \beta\) has source and target \(\id(x)\), whereas the source of \(\alpha *_0 \id(\id(x))\) is \(\id(x) *_0 \id(x)\).

To recover the proof in a weak setting, the intermediate composites must be composed with unitors so that they all have source and target \(\id(x)\). To give equivalences for the first and last step, these unitors must be moved around with naturality moves, and at a critical point the isomorphism \(\lambda_{\id(x)} \simeq \rho_{\id(x)}\) is required. Multiple full proofs of Eckmann-Hilton will be given in \cref{sec:rehydration}. The proof of Eckmann-Hilton is vastly simpler in strict case, mainly due to the presence of the equation \(\id(x) *_0 \id(x) = \id(x)\).
%  It is natural to ask whether it is necessary to work with weak higher categories at all, given the extra complexity.

% For bicategories, it turns out that the answer is no. Every bicategory is biequivalent to a strict 2-category~\cite[Theorem 1.4]{gordon1995coherence}, meaning that to prove any equation holds in a bicategory, it suffices to prove that the same equation holds in a strict 2-category. This allows the more general notion of bicategory to be used without incurring extra proof burden.

% For more than 2-dimensions, this full strictification is no longer possible.\todo{This should all likely go in the introduction}

\subsection{Computads}
\label{sec:computads}

A free group is generated by a set, and a free category is generated by a directed graph, and so it is a natural question what the generating data for a free higher category is. We have already seen that a free higher category can be generated by a globular set, but free \(\infty\)-categories can also be generated by data that does not form a globular set.

Consider the minimum data needed to to state the Eckmann-Hilton principle~(\cref{prop:eh}). We require a single \(0\)-cell \(x\), and two \(2\)-cells \(\alpha, \beta : \id(x) \to \id(x)\). This data does not form a globular set as, for example, the source of the \(2\)-cell \(\alpha\) is not in the generating data, but is rather an operation applied to the data. We could try to remedy this by adding a new \(1\)-cell \(f\) to the data to represent \(\id(x)\), but then the connection between \(\id(x)\) and \(f\) would be lost and \(f\) and \(\id(x)\) would be distinct in any free \(\infty\)-category generated on this data.

The correct generating data for an \(\infty\)-category is a \emph{computad}. A version for 2-categories was introduced by \citeauthor{street1976limits}~\cite{street1976limits}, which allows a generating \(2\)-cell to have a composite or identity as its source or target. These were extended to strict \(\infty\)-categories by \citeauthor{burroni1993higher}~\cite{burroni1993higher} and weak \(\infty\)-categories by
\citeauthor{batanin1998computads}~\cite{batanin1998computads}, which allow the source and target of an \(n\)-cell to be any \((n-1)\)-cell of the free \(\infty\)-category generated by the lower dimensional data.

A modern approach to computads for weak \(\infty\)-categories is given by \citeauthor{dean2022computads}~\cite{dean2022computads}, which avoids much of the complexity of globular operads, relying only on (mutual) structural induction. This definition of a computad is much closer in style (and is inspired by) the type theory \Catt which we review in \cref{sec:type-theory-catt}.

\section{The type theory \Catt}
\label{sec:type-theory-catt}

In this section we give an overview of the dependent type theory \Catt~\cite{finster2017type}. \Catt serves as a definition of weak \(\infty\)-categories, by defining a weak \(\infty\)-category to be a model of the type theory (e.g. using categories with families~\cite{MR1474535}). In \cref{cha:gener-pres-catt}, we give a more general and comprehensive presentation of \Catt, allowing the addition of equality relations to the type theory, preempting \cref{cha:cattstrict}. In contrast this section presents the version of \Catt closer to the one found in the literature, and compares its various constructions to the ideas introduced in \cref{sec:weak}.

\subsection{Syntax of \Catt}
\label{sec:syntax-catt}

\Catt has 4 classes of syntax: contexts, terms, types, and substitutions.
\begin{itemize}
\item Contexts contain a list of variables with an associated type. We can consider contexts as finite computads, the generating data for a weak \(\infty\)-category (see \cref{sec:computads}). It is alternatively valid to consider contexts in \Catt as finitely generated \(\infty\)-categories. The set of contexts contains all globular sets (and hence all pasting diagrams).
\item Terms over a context \(\Gamma\) correspond to the operations from \cref{sec:weak}. Terms can either be a variable, which corresponds to the operations which pick a single cell out of a globular set, or those generated by the unique constructor \(\mathsf{coh}\), which correspond to the operations generated by lifting. A term over a context \(\Gamma\) can also be seen as a element of the free \(\infty\)-category generated from \(\Gamma\).
\item Types over a context \(\Gamma\) consist of a collection of terms over the same context, and contain the boundary information for a term. Types either take the form of the constructor \(*\), the type of \(0\)-cells (which have no boundary data), or an arrow type \(\arr s A t\), where \(s\) and \(t\) are terms giving the source and target of the boundary and the type \(A\) gives lower dimensional boundary information\footnote{This can be viewed as a directed version of the equality type \(s =_A t\) from Martin-L\"of type theory}.
\item Substitutions from a context \(\Gamma\) to a context \(\Delta\) are a mapping from variables of \(\Gamma\) to terms of \(\Delta\). These play the role of functors between the \(\infty\)-categories generated by \(\Gamma\) and \(\Delta\) and are also syntactically crucial for forming compound composites in the theory.
\end{itemize}

\begin{figure}[h]
  \centering
    \begin{tabular}{Sc Sc}
    {
    \begin{prooftree}
      \hypo{\phantom{\Term}} \infer1{\emptyset : \Ctx}
    \end{prooftree}
    }
    &
      {
      \begin{prooftree}
        \hypo{\Gamma : \Ctx} \hypo{A : \Type_\Gamma}
        \infer2{\Gamma, (x : A) : \Ctx}
      \end{prooftree}}
    \\
    {
    \begin{prooftree}
      \hypo{\phantom{\Term}} \infer1{\langle \rangle : \emptyset \to \Gamma}
    \end{prooftree}
    }
    & {
      \begin{prooftree}
        \hypo{\sigma : \Delta \to \Gamma} \hypo{t : \Term_\Gamma} \hypo{A : \Type_\Delta}
        \infer3{\langle \sigma , t \rangle : \Delta, (x : A) \to \Gamma}
      \end{prooftree}
      }
    \\
    {
    \begin{prooftree}
      \hypo{\phantom{\Type}} \infer1{\star : \Type_\Gamma}
    \end{prooftree}
    }
    & {
      \begin{prooftree}
        \hypo{A : \Type_\Gamma} \hypo{s : \Term_\Gamma} \hypo{t : \Term_\Gamma}
        \infer3{\arr s A t : \Type_\Gamma}
      \end{prooftree}
      }
    \\
    {
    \begin{prooftree}
      \hypo{x \in \Var(\Gamma)\vphantom{\Type}} \infer1{x : \Term_\Gamma}
    \end{prooftree}
    }
    & {
      \begin{prooftree}
        \hypo{\Delta : \Ctx} \hypo{A : \Type_\Delta} \hypo{\sigma : \Delta \to \Gamma}
        \infer3{\Coh \Delta A \sigma : \Term_\Gamma}
      \end{prooftree}
      }

    \end{tabular}

    \vspace{-5pt}
  \caption{Syntax constructions in \Catt.}
  \label{fig:syntax}
\end{figure}

The rules for constructing each piece of syntax are given in \cref{fig:syntax}. To simplify the notation, we may avoid writing substitutions in a fully nested fashion, writing \(\langle \sigma , s , t \rangle\) instead of \(\langle \langle \sigma, s \rangle, t \rangle\), or \(\langle s \rangle\) instead of \(\langle \langle \rangle, s \rangle\). We may also omit the subscript in the arrow type. As opposed to the original paper on \Catt, we fibre terms, types, and substitutions over contexts, allowing us to avoid any problems with substitution only extending to a partial operation on terms. We write \(\Ctx\) for the set of contexts, \(\Term_\Gamma\) for the set of terms in a context \(\Gamma\), \(\Type_\Gamma\) for the set of types in a context \(\Gamma\), and write \(\sigma : \Delta \to \Gamma\) when \(\sigma\) is a substitution taking variables of \(\Delta\) to terms of \(\Gamma\). In the literature, substitutions are often written as going in the opposite direction. We emphasise here that the direction of our substitution morphisms agrees with the direction of the function from variables to terms, the direction of the induced functor between the \(\infty\)-categories freely generated from the domain and codomain contexts, and the direction of arrows in a Grothendieck coherator.

We write \(\equiv\) for \emph{syntactic equality}, up to renaming of variables and \(\alpha\)-equivalence. The various pieces of syntax will be considered as equal up to this relation, which can be achieved by using a de Bruijn index representation of the syntax as we present in \cref{cha:gener-pres-catt} for the formalisation. However, we continue to use named variables in the prose of the thesis to aid readability, assuming that all variables in a context are always distinct. We contrast this with the equality symbol, \(=\), which will represent the equality derived from extra equality rules we have placed on \Catt in \cref{sec:catt-with-equality}, and will be referred to as \emph{definitional equality}.

The action of a substitution \(\sigma : \Delta \to \Gamma\) can be extended from variables to all terms \(t \in \Term_\Delta\), types \(A \in \Type_\Delta\), and substitutions \(\tau : \Theta \to \Delta\) by mutual recursion:
\begin{align*}
  x \sub \sigma &= t&\text{if }(x \mapsto t) \in \sigma\\
  \Coh \Theta A \tau \sub \sigma &= \Coh \Theta A {\tau \bullet \sigma}\\
  \star \sub \sigma &= \star\\
  \arr s A t \sub \sigma &= \arr {s \sub \sigma} {A \sub \sigma} {t \sub \sigma}\\
  \langle \rangle \bullet \sigma &= \langle \rangle\\
  \langle \tau , t \rangle \bullet \sigma &= \langle \tau \bullet \sigma , t \sub \sigma \rangle
\end{align*}

For every context \(\Gamma\), there is an identity substitution \(\id_\Gamma\), which sends every variable to itself, which along with composition of substitutions above gives a category of contexts and substitutions.

The coherence constructor \(\Coh \Delta A \sigma\) allows us to construct lifts between parallel operations over pasting diagrams. The context \(\Delta\) plays the role of the pasting diagram. The type \(A\) will always be of the form \(\arr s B t\), and the terms \(s\) and \(t\) play the role of the parallel operation (with the type \(\arr s B t\) being well typed ensuring that \(s\) and \(t\) are parallel). The substitution \(\sigma : \Delta \to \Gamma\) holds the data of a set of arguments to the coherence, allowing compound composites/operations to be formed and taking the role of composition of morphisms in the coherator.

We next define the free variables of each piece of syntax. These will be used to encode the condition of an operation being algebraic from the theory of non-invertible coherators. Let \(\Var(\Gamma)\) denote the variables of \(\Gamma\). For a term \(t \in \Term_\Gamma\), a type \(A \in \Type_\Gamma\) and a substitution \(\sigma : \Delta \to \Gamma\) we define their free variables \(\FV(t), \FV(A), \FV(\sigma) \subseteq \Var(\Gamma)\) by mutual recursion.
\begin{align*}
  \FV(x) &= \{x\} &\text{if \(x\) is a variable}\\
  \FV(\Coh \Delta A \sigma) &= \FV(\sigma)\\
  \FV(\star) &= \{\}\\
  \FV(\arr s A t) &= \FV(s) \cup \FV(A) \cup \FV(t)\\
  \FV(\langle \rangle) &= \{\}\\
  \FV(\langle \sigma , t \rangle) &= \FV(\sigma) \cup \FV(t)
\end{align*}

The free variables of a term is often the wrong notion to use for testing algebraicity. For example in the context \(D^1\), the term \(d_1\) has free variables \(\{d_1\}\), whereas the unary composite of \(d_1\), \(\Coh {D_1} {\arr {d_0^-} \star {d_0^+}} {\id_{D^1}}\), has free variables \(\{d_0^-,d_0^+,d_1\}\). To remedy this, the original paper considers \(\FV(t) \cup \FV(A)\), for a term \(t\) of type \(A\). In this thesis we instead define the support of each piece of syntax, a purely syntactic construction.

\begin{definition}
  Fix a context \(\Gamma\). The subset \(V \subseteq \Var(\Gamma)\) is \emph{downwards closed} if for all \((x : A) \in \Gamma\) we have:
  \[x \in V \implies \FV(A) \subseteq V\]
  The downwards closure of a set \(V\) in a context \(\Gamma\), \(\DC_\Gamma(V)\) can be defined by induction on the context:
  \begin{align*}
    \DC_\emptyset(\emptyset) &= \emptyset\\
    \DC_{\Gamma, x : A}(V) &=
                               \begin{cases*}
                                 \DC_\Gamma(V)&if \(x \not\in V\)\\
                                 \{x\} \cup \DC_\Gamma(V \cup \FV(A))&if \(x \in V\)\\
                               \end{cases*}
  \end{align*}
  The support of a term, type, or substitution is then defined as the downwards closure of its free variables:
  \[ \Supp(t) = \DC_\Gamma(\FV(t))\qquad \Supp(A) = \DC_\Gamma(\FV(A))\qquad \Supp(\sigma) = \DC_\Gamma(\FV(\sigma)) \]
  for terms \(t \in \Term_\Gamma\), types \(A \in \Type_\Gamma\), and substitutions \(\sigma : \Delta \to \Gamma\).
\end{definition}

We will see later (\cref{item:supp-tm-char-2}) that for well-formed terms \(t\) of typed \(A\) that the support of \(t\) is equal to \(\FV(t) \cup \FV(A)\) and that \(\Supp(A) = \FV(A)\) for well-formed types. Modifying \Catt to use support therefore does not change the theory.

We lastly define the \emph{dimension} of types, contexts, and terms. For types this is defined recursively:
\[ \dim(\star) = 0 \qquad \dim(\arr s A t) = 1 + \dim(A) \]
For contexts we define \(\dim(\Gamma)\) to be the maximum of the dimension of each type in \(\Gamma\). For coherences \(\Coh \Gamma A \sigma\), the dimension is given by \(\dim(A)\), and for variables the dimension is given by the dimension of the associatiated type in the context.

\subsection{Ps-contexts}
\label{sec:ps-contexts}

We need to be able to describe pasting diagrams within the theory \Catt. As contexts model globular sets it is natural to treat pasting diagrams as a subset of contexts and will build pasting diagrams by iteratively attaching discs to a context. This is done by introducing the judgements:

\[ \Delta \vdash_{\mathsf{ps}} x : A \qquad \text{and}\qquad \Delta \vdash_{\mathsf{ps}} \]

If the first judgement holds, then \(\Delta\) is a pasting diagram for which a disc can be attached to the variable \(x\), called a \emph{dangling variable}, which has type \(A\). The contexts \(\Delta\) for which the second judgement holds are fully formed pasting diagrams, which we call \emph{Ps-contexts} (short for pasting scheme contexts). The rules for these judgements are given in \cref{fig:ps-context}.

We note that these rules do not just specify which globular sets are pasting diagrams, but they also specify an ordering on the elements of the pasting diagram, ensuring that there is a unique Ps-context for each pasting diagram. For example, the following judgement holds:
\begin{equation}
  \label[judgement]{judg:ps}
  (x : \star), (y : \star), (f : \arr x \star y), (z: \star), (g : \arr y \star z) \vdash_{\mathsf{ps}}
\end{equation}
However, the context:
\[(y : \star), (z : \star), (g : \arr y \star z), (x : \star), (f : \arr x \star y)\]
represents the same globular set but is not a Ps-context.

\begin{figure}[h]
  \centering
  \begin{mathpar}
    \inferrule{ }{(x : \star) \vdash_{\mathsf{ps}} x : \star} {(\textsc{pss})}
    \and
    \inferrule{\Gamma \vdash_{\mathsf{ps}} x : A}{\Gamma, (y : A), (f : \arr x A y)} {(\textsc{pse})}
    \and
    \inferrule{\Gamma \vdash_{\mathsf{ps}} x : \arr s A t}{\Gamma \vdash_{\mathsf{ps}} t : A} {(\textsc{psd})}
    \and
    \inferrule{\Gamma \vdash_{\mathsf{ps}} x : \star}{\Gamma \vdash_{\mathsf{ps}}} {(\textsc{ps})}
  \end{mathpar}
  \caption{Rules for Ps-contexts}
  \label{fig:ps-context}
\end{figure}

\begin{example}
  \Cref{judg:ps} is given by the following derivation:
  \[\begin{prooftree}
    \hypo{ }
    \infer1[(\textsc{pss})]{(x : \star) \vdash_{\mathsf{ps}} x : \star}
    \infer1[(\textsc{pse})]{(x : \star), (y : \star), (f : \arr x \star y) \vdash_{\mathsf{ps}} f : \arr x \star y}
    \infer1[(\textsc{psd})]{(x : \star), (y : \star), (f : \arr x \star y) \vdash_{\mathsf{ps}} y : \star}
    \infer1[(\textsc{pse})]{(x : \star), (y : \star), (f : \arr x \star y), (z : \star), (g : \arr y \star z) \vdash_{\mathsf{ps}} g : \arr x \star y}
    \infer1[(\textsc{psd})]{(x : \star), (y : \star), (f : \arr x \star y), (z : \star), (g : \arr y \star z) \vdash_{\mathsf{ps}} z : \star}
    \infer1[(\textsc{ps})]{(x : \star), (y : \star), (f : \arr x \star y), (z : \star), (g : \arr y \star z) \vdash_{\mathsf{ps}}}
  \end{prooftree}\]

The applications of (\textsc{pse}) allow new variables to be added to the context, by adding a fresh variable, and attaching a variable from the dangling variable to the new fresh variable. The rule (\textsc{psd}) encodes that if we can attach a variable to \(f : x \to y\), then we can also attach a variable to \(y\). Finally, the rule (\textsc{ps}) forces as many (\textsc{psd}) rules to be applied as possible before completing the derivation, ensuring that derivations of Ps-contexts are unique.
\end{example}

We now state the following theorem, which follows immediately from \cite[Theorem~53]{benjamin2021globular}.

\begin{theorem}
  The set of Ps-contexts is in bijection with the set of pasting diagrams.
\end{theorem}

In order to use Ps-contexts as our notion of pasting diagram, we need to be able to identify the source and target variables of each Ps-context. This will be done by specifying the dimension \(i\) source and target of each pasting context.

More precisely, for each Ps-context \(\Gamma\) and \(i \in \mathbb{N}\), we define a Ps-context \(\bound i \Gamma\) and subcontext inclusions:
\[ \incbd i - \Gamma : \bound i \Gamma \to \Gamma \qquad \text{and}\qquad \incbd i + \Gamma : \bound i \Gamma \to \Gamma\]
Intuitively, the context \(\bound i \Gamma\) can be constructed by removing any variables of dimension greater than \(i\) from \(\Gamma\), and quotienting the dimension \(i\) variables by the (symmetric transitive closure of the) relation \(x \sim y\) if there exists an \(f : x \to y\). The inclusions then send this quotiented variable to the variable appearing first in the equivalence class for the source inclusion, and the variable appearing last in the class for the target inclusion.

These contexts and substitutions can be defined by recursion on the context \(\Gamma\):
\begin{align*}
  \bound i {(x : \star)} &= {(x : \star)}\\
  \bound i {\Gamma, (y : A), (f : \arr x A y)} &=
                                                  \begin{cases*}
                                                    \bound i \Gamma&if \(i \leq \dim(A)\)\\
                                                    \bound i \Gamma, (y : A), (f : \arr x A y)&otherwise
                                                  \end{cases*}\\
  \incbd i \epsilon {(x : \star)} &= \langle x \rangle\\
  \incbd i \epsilon {\Gamma, (y : A) , (f : \arr x A y)} &=
                                                           \begin{cases*}
                                                             \mathrlap{\incbd i \epsilon \Gamma}{\phantom{\bound i \Gamma, (y : A), (f : \arr x A y)}}&if \(i < \dim(A)\)\\
                                                             \incbd i - \Gamma&if \(i = \dim(A)\) and \(\epsilon = -\)\\
                                                             \replace(\incbd i + \Gamma, y)&if \(i = \dim(A)\) and \(\epsilon = +\)\\
                                                             \langle \incbd i \epsilon \Gamma, y, f \rangle &otherwise
                                                           \end{cases*}
\end{align*}
where \(\epsilon \in \{-,+\}\) and \(\replace(\langle \sigma, s \rangle, t) = \langle \sigma, t \rangle\). As it will be common to take the boundary of \(\Gamma\) at the dimension below the dimension of \(\Gamma\) itself, we write
\[\incbd {} \epsilon \Gamma = \incbd {\dim(\Gamma) - 1} \epsilon \Gamma\]
when \(\dim(\Gamma)\) is not zero.

In the original \Catt paper, these inclusion substitutions are not given and instead the source and target variables are given directly as subcontexts. It can be easily checked that the free variables of the inclusions are equal to the subcontexts, and that the free variable sets of these inclusions are downwards closed. It is known, e.g. from \cite[Lemma~55]{benjamin2021globular}, that these constructions agree with the constructions of the source and target pasting diagrams in \cref{sec:pasting-diagrams}.

\subsection{Typing for \Catt}
\label{sec:typing-catt}

We now have all the prerequisites in place to state the typing rules for \Catt. These take the form of 4 judgements (not including the judgements for Ps-contexts introduced in \cref{sec:ps-contexts}):
\begin{alignat*}{2}
  &\Gamma \vdash&\qquad&\text{\(\Gamma \in \Ctx\) is a well-formed context.}\\
  &\Gamma \vdash A&&\text{\(A \in \Type_\Gamma\) is a well-formed type in context \(\Gamma\).}\\
  &\Gamma \vdash t : A &&\text{\(t \in \Term_\Gamma\) is a well-formed term of type \(A \in \Type_\Gamma\).}\\
  &\Gamma \vdash \sigma : \Delta &&\text{\(\sigma : \Delta \to \Gamma\) is a well-formed substitution.}
\end{alignat*}

The typing rules for these judgements are then given in \cref{fig:catt-typing}. As most of these are standard we draw attention to a couple of the key rules. The rule for arrow types ensures that both the source and target of the arrow themselves have the same type, namely the one given in the subscript of the arrow. This effectively ensures the globular nature of the type theory, as given a term \(f : \arr s {\arr x A y} t\), both the source of the source and source of the target are \(x\), and both the target of the source and target of the target are \(y\).

\begin{figure}[h]
  \centering
  \begin{mathpar}
    \inferrule{ }{\emptyset \vdash}
    \and
    \inferrule{\Gamma \vdash\\ \Gamma \vdash A}{\Gamma, (x : A) \vdash}
    \and
    \inferrule{ }{\Gamma \vdash \star}
    \and
    \inferrule{\Gamma \vdash s : A \\ \Gamma \vdash A \\ \Gamma \vdash t : A}{\Gamma \vdash \arr s A t}
    \\
    \inferrule{ }{\Gamma \vdash \langle\rangle : \emptyset}
    \and
    \inferrule{\Gamma \vdash \sigma : \Delta\\ \Gamma \vdash t : A\sub\sigma}{\Gamma \vdash \langle \sigma , t \rangle : \Delta, (x : A)}
    \and
    \inferrule{(x : A) \in \Gamma}{\Gamma \vdash x : A}
    \and
    \inferrule{\Delta \vdash_{\mathsf{ps}}\\ \Delta \vdash \arr s A t \\ \Gamma \vdash \sigma : \Delta\\\dim(\Delta) \neq 0\\\supp(s) = \supp(\incbd {} - \Delta)\\\supp(t) = \supp(\incbd {} + \Delta)}{\Gamma \vdash \Coh \Delta {\arr s A t} \sigma : \arr {s \sub \sigma} {A \sub \sigma} {t \sub \sigma}}
    \and
    \inferrule{\Delta \vdash_{\mathsf{ps}}\\ \Delta \vdash \arr s A t \\ \Gamma \vdash \sigma : \Delta\\\supp(s) = \supp(t) = \Var(\Delta)}{\Gamma \vdash \Coh \Delta {\arr s A t} \sigma : \arr {s \sub \sigma} {A \sub \sigma} {t \sub \sigma}}
  \end{mathpar}
  \caption{Typing rules for \Catt}
  \label{fig:catt-typing}
\end{figure}

There are two rules given for typing coherence, corresponding to the two guiding principles for categories from \cref{sec:weak}. The first rule allows composites to be typed and the second allows equivalences to be typed. In both, the Ps-context \(\Delta\) corresponds to the pasting diagram \(P\), the terms \(s\) and \(t\) correspond to the operations \(f\) and \(g\) over \(P\) (with the judgement \(\Delta \vdash \arr s A t\) enforcing that they are parallel), and the conditions involving support give the remaining side conditions.

By a straightforward mutual induction we can prove that application of substitution to terms, types, and other substitutions preserves typing. Therefore, the \emph{syntactic category} of \Catt can be formed, which contains well-formed contexts as objects and well-formed substitutions between these contexts as morphisms, which by abuse of notation we also call \Catt. There is a full subcategory \(\Catt^{\mathsf{ps}}\), which only contains the contexts which are Ps-contexts.

\begin{theorem}
  The category \(\Catt^{\mathsf{ps}}\) is a coherator for \(\infty\)-categories.
\end{theorem}
\begin{proof}
  Follows from \cite[Theorem~73]{benjamin2021globular}, noting that the opposite convention for substitution is used in that paper.
\end{proof}

Thus, we immediately get that a presheaf over \(\Catt^{\mathsf{ps}}\) which preserves globular products is an \(\infty\)-category (using the Maltsiniotis definition). Further, presheafs of this form are equivalent to type-theoretic models of \Catt by \cite[Theorem~88]{benjamin2021globular}, meaning type-theoretic models of \Catt are \(\infty\)-categories.

\subsection{Basic constructions}
\label{sec:basic-constructions}

We now introduce some examples of basic categorical operations in order to give some early examples. Suppose we have terms \(a : \arr s \star t\) and \(b : \arr t \star u\) in some context \(\Gamma\). Then the Ps-context
\[ \Delta = (x : \star), (y : \star), (f : \arr x \star y), (z : \star), (g : \arr y \star z) \]
from \cref{judg:ps} can be used to form the 1-composite:
\[ a *_0 b = \Coh \Delta {\arr x \star z} {\langle s, t, a, u, b \rangle}\]
It is often not necessary to give all the terms in a substitution, especially when the substitution is from a pasting diagram (or more generally a globular set). In these cases it is sufficient to give terms for the \emph{locally maximal} variables of the context, those that do not appear as the source or target of another variable. For \(\Delta\), the locally maximal variables are \(f\) and \(g\), and so it suffices to give the substitution above as \(\langle a , b \rangle\), with the rest of the terms being inferable.

The disc contexts \(D^n\) can be formed in \Catt as the analogue of the disc globular sets given in \cref{ex:disc} and satisfy the property that a substitution from a disc context \(D^n\) contains the same data as a term and \(n\)-dimensional type. Given a term \(t\) of type \(A\) in context \(\Gamma\), we write this substitution \(\{A,t\} : D^{\dim(A)} \to \Gamma\). All disc contexts are Ps-contexts.

Using these, the identity can be formed on a term \(t\) of type \(A\) in \(\Gamma\):
\[\id(A,t) = \Coh {D^n} {\arr {d_n} {} {d_n}} {\{A, t\}}\]
where \(\dim(A) = n\), which is typed using the rule for equivalences. The structure of this term changes for different values of \(n\), and we will relate these different terms in \cref{sec:suspension}. As before, the non-locally maximal elements of a substitution
can be inferred, and so we may write \(\id(t)\) or \(\{t\}\) when the type \(A\) is inferable\footnote{In \Catt, all types are inferable, though later it may be necessary to specify the exact type we are using up to syntactic equality.}.

\paragraph{Standard coherences}
The composite and identity above form part of a more general collection of coherences, which we call \emph{standard coherences}.

\begin{definition}
  Given a pasting diagram \(\Delta\), we mutually define for all \(n\) the \emph{standard coherence} \(\stdcoh\Delta n\), the \emph{standard term} \(\stdtm \Delta n\), and the \emph{standard type} \(\stdty \Delta n\):
  \begin{alignat*}{2}
    &\stdcoh \Delta n &&= \Coh \Delta {\stdty \Delta n} {\id_\Delta}\\
    &\stdtm \Delta n &&=
                           \begin{cases}
                             d^n &\text{when \(\Delta\) is the disc \(D^n\)}\\
                             \stdcoh \Delta n &\text{otherwise}
                           \end{cases}\\
    &\stdty \Delta 0 &&= \star\\
    &\stdty \Delta {n+1} &&= \arr {\stdtm {\bound n \Delta} n \sub {\incbd n - \Delta}} {\stdty \Delta n} {\stdtm {\bound n \Delta} n \sub {\incbd n + \Delta}}
  \end{alignat*}
  The standard type takes the standard term over each boundary of \(\Delta\), includes these all back into \(\Delta\) and assembles them into a type. When \(n = \dim(\Delta)\) we will refer to the standard coherence as the \emph{standard composite}.
\end{definition}

Intuitively, the standard coherence \(\stdcoh \Delta n\) is the canonical composite in dimension \(n\) of the pasting diagram \(\Delta\). To give this a type is needed to form the coherence, for which the standard type \(\stdty \Delta n\) is used. The standard term \(\stdtm \Delta n\) is used as a variant of the standard coherence which special cases disc contexts. This avoids the standard type containing unary composites and allows standard composites (of non disc-contexts) to be normal forms of the reduction schemes that will be described in \cref{cha:cattstrict}.

It is immediate that the composite \(a *_0 b\) is given by \(\stdcoh \Delta 1\sub{\langle a , b \rangle}\) and the identity on a term \(t\) of dimension \(n\) is given by \(\stdcoh {D^n} {n+1}\sub{\{t\}}\). This construction can be used to generate all the composites in the definition of a strict \(\infty\)-category. For example the vertical composite of \(2\)-cells is the standard composite over the context given by the diagram:
\[
  \begin{tikzcd}
    x && y
    \arrow[""{name=0, anchor=center, inner sep=0}, "f"', curve={height=24pt}, from=1-1, to=1-3]
    \arrow[""{name=1, anchor=center, inner sep=0}, "h", curve={height=-24pt}, from=1-1, to=1-3]
    \arrow[""{name=2, anchor=center, inner sep=0}, "g"{description}, from=1-1, to=1-3]
    \arrow["\alpha", shorten <=3pt, shorten >=3pt, Rightarrow, from=0, to=2]
    \arrow["\beta", shorten <=3pt, shorten >=3pt, Rightarrow, from=2, to=1]
  \end{tikzcd}
\]
and the horizontal composite of \(2\)-cells is the standard composite over:
\[
  \begin{tikzcd}
    x & y & z
    \arrow[""{name=0, anchor=center, inner sep=0}, "g", curve={height=-18pt}, from=1-1, to=1-2]
    \arrow[""{name=1, anchor=center, inner sep=0}, "f"', curve={height=18pt}, from=1-1, to=1-2]
    \arrow[""{name=2, anchor=center, inner sep=0}, "i", curve={height=-18pt}, from=1-2, to=1-3]
    \arrow[""{name=3, anchor=center, inner sep=0}, "h"', curve={height=18pt}, from=1-2, to=1-3]
    \arrow["\alpha", shorten <=5pt, shorten >=5pt, Rightarrow, from=1, to=0]
    \arrow["\beta", shorten <=5pt, shorten >=5pt, Rightarrow, from=3, to=2]
  \end{tikzcd}
\]
Noting that the standard type over the above diagram has source \(f * h\) and target \(g * i\), themselves being standard compositions demonstrating the mutual recursive behaviour of these constructions.

\begin{remark}
  Above we gave two Ps-contexts by drawing a diagram of the globular set that they represent. Ps-contexts fix the order that variables occur in and as such the mapping from Ps-contexts to globular sets is injective. The use of diagrams to define Ps-contexts is therefore unambiguous.
\end{remark}

\paragraph{Further examples}
The substitution component of a coherence allows operations to be combined into compound operations. Consider the (Ps-)context given by the following diagram:
\[\Gamma =
  \begin{tikzcd}
    s & t & u & v
    \arrow["a", from=1-1, to=1-2]
    \arrow["b", from=1-2, to=1-3]
    \arrow["c", from=1-3, to=1-4]
  \end{tikzcd}
\]
There are (at least) 3 ways to compose together the elements of this context. We could take the unbiased ternary composite \(a * b * c = \stdcoh \Gamma 1\sub{\langle a, b, c\rangle}\), but could also construct either biased composite:
\begin{align*}
  (a * b) * c &= \stdcoh \Delta 1\sub{\langle \stdcoh \Delta 1\sub{\langle a,b\rangle}, c\rangle}\\
  a * (b * c) &= \stdcoh \Delta 1\sub{\langle a, \stdcoh \Delta 1\sub{\langle b, c\rangle}\rangle}\\
\end{align*}
Using the equivalence typing rule, we can relate these biased composite with the following term:
\[ \alpha_{a,b,c} = \Coh \Gamma {\arr {(a * b) * c} {} {a * (b * c)}} {\id_\Gamma}\]
which is the associator. Similarly for a term \(f : \arr x \star y\), unitors can be form over the disc context \(D^1\) using the equivalence rule:
\begin{align*}
  \lambda_f &= \Coh {D^1} {\arr {\id(d_0^-) * d_1} {} {d_1}} {\{f\}}\\
  \rho_f &= \Coh {D^1}  {\arr {d_1 * \id(d_0^-)} {} {d_1}} {\{f\}}
\end{align*}
The remainder of the operations for a 2-category can be defined similarly, as each displays the equivalence of two terms built over a pasting diagram. We observe that both the unitors and associator (as well as any coherence typed with the equivalence rule) are trivially invertible.

\subsection{Suspension}
\label{sec:suspension}

To end this section, we describe the meta-operation of \emph{suspension}, as described by \citeauthor{benjamin2020type}~\cite{benjamin2020type}. Suspension takes any piece of syntax as input and produces one with a dimension one higher. It can be used as an aid to defining operations in \Catt, but will also form a key part of the formal development of the constructions described in \cref{sec:operations-catt}.

Suspension is inspired by the identically named operation on topological spaces. Given a topological space \(X\), its suspension \(\Sigma X\) is formed by quotienting the space \(X \times [0,1]\) by the relation that identifies all points of the form \((x,0)\) for \(x \in X\) and identifies points \((x,1)\) for \(x \in X\).

The suspension on a space \(X\) can be alternatively viewed as the space containing two distinguished points \(N\) and \(S\), and a path from \(N\) to \(S\) for each point \(x \in X\). The names \(N\) and \(S\) stand for north and south, as the suspension of a circle can be visualised as a globe, with \(N\) and \(S\) being the north and south pole and each of the paths between them being a meridian.

A similar operation can be applied to globular sets. Given a globular set \(G\), its suspension \(\Sigma G\) is obtained by shifting the dimension of every \(n\)-cell up by one (making it into an \((n+1)\)-cell), adding two new \(0\)-cells \(N\) and \(S\), and letting the source of every \(1\)-cell be \(N\) and the target be \(S\). The globularity conditions for this construction can be quickly verified.

This construction extends to all computads~\cite{benjamin2024duamity}, and can be defined in \Catt by mutually defining the operation on contexts, types, terms, and substitutions.

\begin{definition}
  For a contexts \(\Gamma \in \Ctx\), types \(A \in \Type_\Gamma\), terms \(t \in \Term_\Gamma\), and substitutions \(\sigma : \Delta \to \Gamma\), we define their \emph{suspensions} \(\Sigma(\Gamma) \in \Ctx\), \(\Sigma(A) \in \Type_{\Sigma(\Gamma)}\), \(\Sigma(t)\in \Term_{\Sigma(\Gamma)}\), and \(\Sigma(\sigma) : \Sigma(\Delta) \to \Sigma(\Gamma)\) by mutual recursion.
  \begin{align*}
    \Sigma (\emptyset) &= (N : \star), (S : \star)
    &\Sigma (\Gamma, (x : A)) &= \Sigma \Gamma, (x : \Sigma A)\\
    \Sigma (\star) &= \arr N \star S
    &\Sigma (\arr s A t) &= \arr {\Sigma s} {\Sigma A} {\Sigma t}\\
    \Sigma(\langle \rangle) &= \langle N, S \rangle
    &\Sigma(\langle \sigma, x \rangle) &= \langle \Sigma(\sigma), \Sigma(t) \rangle\\
    \Sigma (x) &= x
    &\Sigma (\Coh \Delta A \sigma) &= \Coh {\Sigma(\Delta)} {\Sigma(A)} {\Sigma(\sigma)}
  \end{align*}
where \(x\) is a variable of \(\Gamma\).
\end{definition}

The dimension shift of suspension is driven by the cases for types, especially the case for the base type \(\star\), which returns a type of dimension \(1\), namely \(\arr N \star S\), using the two new variables \(N\) and \(S\). We note the suspension of any Ps-context is also a Ps-context, and in general the suspension of any piece of well-formed \Catt syntax can be well-formed. These results are given in \cite[Section~3.2]{benjamin2020type}, but will be proved in \cref{sec:ruleset} in more generality.

We can now investigate the action of suspension on the operations we have already defined. Take the context:
\[ (x : \star), (y : \star), (f : \arr x \star y), (z : \star), (g : \arr y \star z) \]
used in \cref{sec:basic-constructions} to generate 1-composition. Applying suspension to this context gives:
\[
  \begin{tikzcd}
    N && S
    \arrow[""{name=0, anchor=center, inner sep=0}, "x"', curve={height=24pt}, from=1-1, to=1-3]
    \arrow[""{name=1, anchor=center, inner sep=0}, "z", curve={height=-24pt}, from=1-1, to=1-3]
    \arrow[""{name=2, anchor=center, inner sep=0}, "y"{description}, from=1-1, to=1-3]
    \arrow["f", shorten <=3pt, shorten >=3pt, Rightarrow, from=0, to=2]
    \arrow["g", shorten <=3pt, shorten >=3pt, Rightarrow, from=2, to=1]
  \end{tikzcd}
\]
the context used to generate vertical 2-composition. Furthermore, applying suspension directly to 1-composition operation forms the vertical 2-composition operation.

The suspension of each disc context \(D^n\) is (up to \(\alpha\)-renaming) \(D^{n+1}\). It can be checked that applying suspension to the identity operation for \(n\)-dimensional terms returns the identity operation for \((n+1)\)-dimensional terms. Repeating this logic, all identity operations can be obtained as iterated suspensions of the identity for \(0\)-cells. The following more general result about standard coherences holds:

\begin{proposition}
  The following syntactic equalities hold:
  \[\Sigma(\stdcoh \Delta n) = \stdcoh {\Sigma(\Delta)} {n+1}\qquad
    \Sigma(\stdtm \Delta n) = \stdtm {\Sigma(\Delta)} {n+1}\qquad
    \Sigma(\stdty \Delta n) = \stdty {\Sigma(\Delta)} {n+1}\]
  for all Ps-contexts \(\Delta\) and \(n \in \mathbb{N}\).
\end{proposition}

The proof of these results is delayed to \cref{sec:operations-catt}, where we will have more tools for dealing with theses constructions.



\chapter{A formalised presentation of \Catt with equality}
\label{cha:gener-pres-catt}

The main purpose of this chapter will be to define the family of type theories \Cattr, which extend the base type theory \Catt with a specified set \(\mathcal{R}\) of equality rules. These equality rules equate various terms of the theory, which unifies the corresponding operations in the models of these theories, allowing us to generate type theories that model semistrict categories in \cref{cha:cattstrict}, categories where some but not all structure is strictified.

This chapter will also introduce the Agda\todo{citation} formalisation which accompanies this thesis, which compiles with Agda v2.6.4 and standard library v2.0. The formalisation implements the syntax and typing judgements of \Cattr, and contains proofs of most results in this chapter and \cref{sec:operations-catt}. By formalising \Cattr, instead of the more specific type theories \Cattsu and \Cattsua introduced in \cref{sec:cattsu,sec:cattsua}, the formalisation of many results can be applied to both type theories. This also allows these results to be applied to any future type theories that fit into this family.

A dependency graph of the formalisation is given in \cref{fig:dep-graph}, and an online version of this graph can be found at \todo{Put online} for which each node is a clickable link to an html version of the code.

\section{Extended substitution}
\label{sec:extend-subst}

\Cattr uses the same syntax as \Catt with one exception. In \Cattr we make a natural generalisation to substitutions, which will allow more operations to be defined for working with the suspension operation introduced in \cref{sec:suspension}. Unfortunately, the full utility of this generalisation will not be realised until \cref{sec:structured-terms}, but we choose to introduce it here as it forms a core part of the syntax, and requires very little modification to the rules of the type theory.

We recall that the suspension operation \(\Sigma\) acts on contexts, substitutions, types, and terms. Given a substitution \(\sigma : \Delta \to \Gamma\), its substitution \(\Sigma(\sigma)\) has domain \(\Sigma(\Delta)\) and codomain \(\Sigma(\Gamma)\). When we define trees and tree labellings in \cref{sec:operations-catt}, which will be used to define the insertion operation in \cref{sec:insertion}, we will need to be able to define substitutions from suspended contexts to arbitrary contexts. More generally, we would like to be able to describe substitutions of the form:
\[ \Sigma^n(\Delta) \to \Gamma\]
where \(\Sigma^n(\Delta)\) is the operation that applies suspension \(n\) times to \(\Delta\).

Consider the data contained in a substitution \(\tau : \Sigma(\Delta) \to \Gamma\). There are two terms \(N \sub \tau\) and \(S \sub \tau\) of type \(\star\), and then a term for each variable of \(\Delta\). Temporarily ignoring the typing conditions for substitutions, we see that the data is equivalent to a substitution from \(\Delta\) to \(\Gamma\) and two additional terms.

If we now consider a substitution \(\tau : \Sigma(\Sigma(\Delta)) \to \Gamma\), we notice that there is a term in \(\Gamma\) for each variable of \(\Delta\), as well as two terms \(s = N \sub \tau\) and \(t = S \sub \tau\) for the outer suspension and terms \(u = N' \sub \tau\) and \(v = S' \sub \tau\) for the inner suspension. As before, the terms \(s\) and \(t\) should have type \(\star\), but the terms \(u\) and \(v\) should have type \(\arr s \star t\). We note that this is the exact condition needed for \(\arr u {\arr s \star t} v\) to be a well-formed type. This motivates the notion of an \emph{extended substitution}, which is obtained by equipping a substitution with a type.

We have not yet determined the typing conditions required on the substitution part of these extended substitutions. We return to the example of a substitution \(\tau : \Sigma^2(\Delta) \to \Gamma\), and suppose that \(\Delta\) has a variable \(x\) of type \(\star\). In \(\Sigma^2(\Delta)\), \(x\) has the type \(\arr {N'} {\arr N \star S} {S'}\), and so \(x\) should be sent to a term of type \(\arr u {\arr s \star t} v\), the type portion of the extended substitution. In a substitution \(\sigma : \Delta \to \Gamma\), \(x\) would be sent to a term of type \(\star \sub \sigma\), which suggests that \(\star \sub \sigma\) should be redefined to send \(\star\) to the type part of the extended substitution.

This one change to the application of substitution to types is sufficient to form the generalisation to substitutions that was required. An extended substitutions \(\sigma : \Delta \to \Gamma\) then has the following intuition: The substitution part specifies where each variable in \(\Delta\) should be sent, and the type part specifies where the base type \(\star\) should be sent. The other cases for the application of substitution extend this to all terms, types, and (extended) substitutions as before. The extended substitution \(\sigma\) then represents a standard substitution \(\Sigma^n(\Delta)\) to \(\Gamma\), where \(n\) is the dimension of the type part of \(\sigma\). Hence, a regular substitution can be recovered as an extended substitution with type part \(\star\).

We modify the syntax of \Catt as follows, and will refer to these extended substitutions simply as substitutions, as extended substitutions are a direct generalisation of substitutions, and the notion of substitution is still recoverable by setting the type part to \(\star\):
\begin{itemize}
\item Substitutions will now be fibred over a type of their codomain context, which we will write \(\sigma : \arr \Delta A \Gamma\) where \(A \in \Type_\Gamma\). We note that this allows us to specify that \(\sigma\) is a regular substitutions by writing \(\sigma : \arr \Delta \star \Gamma\).
\item The constructor \(\langle\rangle\) is removed, and is replaced by the constructor \(\langle A \rangle : \arr \emptyset A \Gamma\), where \(A \in \Type_\Gamma\). Adding a term to a substitution preserves the type of the substiution. As before we may write a substitution \(\langle \langle \langle A \rangle, s \rangle, t \rangle\) as \(\langle A , s, t\rangle\). We let \(\FV(\langle A \rangle) = \FV(A)\).
\item An operation \(\ty(\sigma)\) is introduced that returns the type portion of a substitution. For \(\sigma : \arr \Delta A \Gamma\), we have \(\ty(\sigma) = A\).
\item Coherences \(\Coh \Delta A \sigma \in \Term_\Gamma\) are restricted so that \(\sigma\) is a regular substitution. In other words \(\ty(\sigma)\) must be \(\star\) for \(\sigma\) to appear in a substitution. While this condition could be dropped, it is convenient to keep the same operations as \Catt.
\end{itemize}

To witness the equivalence of extended substitutions \(\Delta \to \Gamma\) and regular substitutions \(\Sigma^n(\Delta) \to \Gamma\), we introduce new operations.

\begin{definition}
  For a substitution \(\sigma : \arr {\Delta} {\arr s A t} \Gamma\), we define its \emph{unrestriction}:
  \[\unrestrict\sigma : \arr {\Sigma(\Delta)} A \Gamma\]
  by induction on the length of \(\Delta\):
  \begin{align*}
    \unrestrict \langle \arr s A t \rangle &= \langle A, s, t \rangle\\
    \unrestrict \langle \sigma' , u \rangle &= \langle \unrestrict \sigma' , u \rangle
  \end{align*}
  The unrestrict operation simply moves two terms from the type part of the substitution into the main body of the substitution.
\end{definition}

To define the second operation, we need to first specify the changes to application of substitution:
\begin{itemize}
\item The composition of substitutions takes substitutions \(\sigma : \arr \Theta A \Delta\) and \(\tau : \arr \Delta B \Gamma\) to a substitution \(\sigma \bullet \tau : \arr \Theta {A \sub \tau} \Gamma\).
\item For a substitution \(\sigma : \arr \Delta A \Gamma\), we define \(\star \sub{\sigma} = A\).
\item As the substitution in a coherence must have type \(\star\), we define the application of an extended substitution \(\tau : \arr \Delta {\arr s A t} \Gamma\) to a coherence as:
  \[ \Coh \Theta A \sigma \sub \tau = \Coh {\Sigma(\Theta)} {\Sigma(A)} {\Sigma(\sigma)} \sub {\unrestrict \tau}\]
  The case for applying a regular substitution to a coherence remains unchanged.
\end{itemize}

We can now define an inverse to the unrestriction operation.

\begin{definition}
  For a substitution \(\sigma : \arr {\Sigma(\Delta)} A \Gamma\), its \emph{restriction}
  \[ \restrict \sigma : \arr \Delta {\arr {N \sub \sigma} A {S \sub \sigma}} \Gamma \]
  is defined by induction on the length of \(\Delta\):
  \begin{align*}
    \restrict \langle A, s, t \rangle &= \langle \arr s A t \rangle\\
    \restrict \langle \sigma', u \rangle &= \langle \restrict \sigma', u \rangle
  \end{align*}
  Inversely to the unrestrict operation, the restrict operation moves two terms into the type part of the substitution.
\end{definition}

As restriction and unrestriction cancel eachother, the suspension of the substitution \(\sigma : \arr \Delta \star \Gamma\) can be factored into \((\unrestrict \circ (\restrict \circ \Sigma)) (\sigma)\). We observe that the second part of this composition, \(\restrict \circ \Sigma\), is the operation that simply applies the suspension to each term in the substitution as well as the type of the substitution. This motivates the final definition of this section.

\begin{definition}
  Let the \emph{restricted suspension} of a substitution \(\sigma : \arr \Delta A \Gamma\) be a substitution
  \[\Sigma'(\sigma) : \arr \Delta {\Sigma(A)} {\Sigma(\Gamma)}\]
  defined inductively by the equations:
  \begin{align*}
    \Sigma'(\langle A \rangle) &= \langle \Sigma(A)\rangle \\
    \Sigma'(\langle \sigma' , t \rangle) &= \langle \Sigma'(\sigma'), \Sigma(t) \rangle
  \end{align*}
  The suspension of a substitution \(\tau : \arr \Delta \star \Gamma\) can be defined by \(\Sigma(\tau) = \unrestrict\Sigma'(\tau)\).
\end{definition}
For the rest of the thesis and the formalisation, the suspension on a substitution is defined as the composition of unrestriction and restricted suspension.

\section{\Cattr: \Catt with equality}
\label{sec:catt-with-equality}

This section will define the type theory \Cattr, a variation of \Catt with specified equality rules. This section, in addition to the following sections in this chapter, will be used to motivate certain choices in the formalisation. All the preliminary definitions as well as syntax, typing, and equality rules are assembled in \cref{fig:cattr}.

\subsection{Syntax}
\label{sec:syntax}

The syntax of \Cattr will be identical to \Catt with the exceptions specified in \cref{sec:extend-subst}. This creates a dependence chain of needing to define the base syntax before suspension can be defined, and needing to define suspension before application of substitution can be defined. In the formalisation these are defined in the following files:
\begin{itemize}
\item The core syntax is defined in \module{Catt.Syntax.Base}.
\item Suspension is defined in \module{Catt.Suspension}.
\item Other syntactic operations are defined in \module{Catt.Syntax}, which re-exports the core syntax.
\end{itemize}
To avoid any issues with alpha equivalence, especially as we have terms that contain contexts, we work with de Bruijn indices throughout the formalisation. This means that a context is simply a vector of types, a fixed length list, which we give a nicer syntax to. Variables are then simply bounded natural numbers, represented by the sets \(\mathsf{Fin}_n\), where \(\mathsf{Fin}_n\) is the set \(\{0,\dots,n-1\}\). Given a context \(A , B , C\), the variables over this context are simply \(\mathsf{var\ 0}\), which has type \(C\), \(\mathsf{var\ 1}\), which has type \(B\), and \(\mathsf{var\ 2}\), with type \(A\). We note that \(3\) is not in \(\mathsf{Fin}_3\), and so \(\mathsf{var\ 3}\) is not a term of this context. Hence, we do not need to deal with unknown variables when applying substitutions. We will still make use of variable names in this text to aid readability, and will ignore any potential problems that could arise from this, knowing that the results are formalised in a setting where they do not appear.

The formalisation also differs from the presentation in the texts by the way that the various notions of syntax are fibred. We fibre contexts by a natural number representing their length, and then fibre terms, types, and substitutions over these lengths instead of fibring them over the contexts. We then get the following 4 syntactic classes defined as mutually inductive families, where \(\mathcal{U}\) is a type universe:
\[ \funcn{Catt.Syntax.Base}{Ctx}{\Ctx} : \mathbb{N} \to \mathcal{U} \quad \funcn{Catt.Syntax.Base}{Ty}\Type : \mathbb{N} \to \mathcal{U} \quad \funcn{Catt.Syntax.Base}{Tm}\Term : \mathbb{N} \to \mathcal{U} \quad \funcn{Catt.Syntax.Base}{Sub}\Sub : (n\ m : \mathbb{N}) \to \Type_m \to \mathcal{U}\]
This decision was made purely for convenience, by fibring over natural numbers instead of contexts, we sometimes avoid the need for providing more explicit arguments to syntactic constructions. It comes with drawback that the context must be provided for certain operations, such as the support of a piece of syntax, or the dimension of a term.

One place an explicit argument can be avoided is when defining the weakening of a piece of syntax, an operation witnessing that for a piece of syntax living in a context \(\Gamma\), there is a copy living in \(\Gamma , A\) for any \(A\). These operations are defined in \module{Catt.Syntax} and take the following form, where we reuse the name \(\wk\) here as an abuse of notation:
\[ \funcn{Catt.Syntax}{wk-tm}{\wk} : \Term_{\Gamma} \to \Term_{\Gamma, A}\quad\funcn{Catt.Syntax}{wk-ty}{\wk} : \Type_{\Gamma} \to \Type_{\Gamma, A}\quad \funcn{Catt.Syntax}{169}{wk-sub} : (\arr \Gamma B \Delta) \to (\arr {\Gamma} {\wk(B)} {\Delta, A}) \]
If terms are fibred over contexts then this type \(A\) must often be specified, though with the fibring over context length this is no longer necessary. When using de Bruijn indices, this operation is no longer the identity on terms, as each variable must be incremented due to the index in a variable counting from the end of the context. One might ask why de Bruijn levels (which index from the start of the context) were not used instead, but this would not solve our problem as \(\mathsf{Fin}_n\) is not a sub type of \(\mathsf{Fin}_{n+1}\) in Agda. Furthermore, using de Bruijn levels would cause the substitution application introduced in \cref{sec:syntax-catt} (and expanded in \cref{sec:extend-subst}) to compute poorly, due to the way substitutions are defined. The definition of weakening is given in \cref{fig:wk}.

Weakening can be used to give a short inductive definition of the identity substitution, a substitution \(\id_\Gamma : \Gamma \to \Gamma\) which sends every variable to itself. On the inductive case \(\id_{\Gamma, (x : A)}\), it clear that the variable \(x\) should be sent to \(x\), but the constructor for substitutions also requires a substitution \(\Gamma \to \Gamma, (x : A)\). This can be obtained by weakening a recursive call to the identity on \(\Gamma\). Similarly, an inclusion \(\Gamma \to \Gamma, (x : A)\) can be defined as \(\wk(\id_\Gamma)\), and applying this substitution is the same operation as weakening.

To begin proving syntactic properties of \Cattr, we need a notion of syntactic equality. This will be written \(\Gamma \equiv \Delta\) for contexts \(\Gamma\) and \(\Delta\), and similarly for terms \(s\) and \(t\), types \(A\) and \(B\), and substitutions \(\sigma\) and \(\tau\). It is given by alpha equivalence, and so we would hope that the formalisation could leverage the use of de Bruijn indices to use the in-built equality type for syntactic equality. This is too restrictive however, there will be many times where we want to compare two terms of differing context length (in practice this context length will be propositionally equal, instead of definitionally equal).

Therefore, four syntactic equality relations are defined mutually inductively on the constructors of each piece of syntax in \module{Catt.Syntax.Properties}. These definitions can easily be heterogeneous, allowing two terms \(s : \Term_n\) and \(t : \Term_m\) to be compared. Unfortunately, using these comes at the cost of large amounts of boilerplate, as these inductively defined equalities do not come equipped with the J-rule, and so it must be manually proved that each operation respects syntactic equality. An example of such a function is \funcn{Catt.Syntax.Properties}{wk-tm-}{\textsf{wk-tm-\(\simeq\)}}, which states that the weakenings of two syntactically equal terms are syntactically equal.

\module{Catt.Syntax.Properties} contains many of the basic properties about the syntax of \Cattr, including:
\begin{itemize}
\item Syntactic equality is decidable.
\item Syntactic equality is propositional, there is at most one proof of \(s \equiv t\).
\item Functoriality of suspension.
\item Interaction of weakening with substitution application. We have \(\wk(s) \sub {\langle \sigma , t \rangle} \equiv s \sub \sigma\) and \(s \sub {\wk(\sigma)} \equiv \wk(s \sub \sigma)\) and equivalent lemmas for the application of substitution to types and substitutions.
\end{itemize}
It also contains the following proposition.

\begin{proposition}
  \label{prop:categorical}
  Application of substitution is associative and unital with respect to the identity substitution. More precisely, given substitutions \(\sigma : \arr \Theta A \Delta\) and \(\tau : \arr \Delta B \Gamma\), the following equalities hold:
  \begin{mathpar}
    A \sub \sigma \sub \tau \equiv A \sub {\sigma \bullet \tau} \and A \sub \id_\Theta \equiv A\\
    t \sub \sigma \sub \tau \equiv t \sub {\sigma \bullet \tau} \and t \sub \id_\Theta \equiv t\\
    (\mu \bullet \sigma) \bullet \tau \equiv \mu \bullet (\sigma \bullet \tau) \and \mu \bullet \id_\Theta \equiv \mu \and \id_\Xi \bullet \mu \equiv \mu
  \end{mathpar}
  for types \(A \in \Type_\Theta\), terms \(t \in \Term_\Theta\), and substitutions \(\mu : \arr \Xi C \Theta\).
\end{proposition}

\begin{proof}
  The last equation is a simple induction on \(\mu\) (and the context \(\Xi\)). Both the unitality equations and associativity equations, as with the vast majority of syntactic proofs, are given by mutual induction on types, terms, and substitutions. The only difficult case is:
  \[ \Coh \Theta C \mu \sub \sigma \sub \tau \equiv t \sub {\sigma \bullet \tau} \]
  where the type part of \(\sigma: \arr \Theta A \Delta\) or \(\tau : \arr \Delta B \Gamma\) is not \(\star\). First suppose \(B = \arr s {B'} t\) but \(A = \star\):
  \begin{align*}
    \Coh \Theta C \mu \sub \sigma \sub \tau
    &\equiv \Coh \Theta C {\mu \bullet \sigma} \sub \tau\\
    &\equiv \Coh {\Sigma(\Theta)} {\Sigma(C)} {\Sigma(\mu \bullet \sigma)} \sub {\unrestrict \tau}\\
    &\equiv \Coh {\Sigma(\Theta)} {\Sigma(C)} {\Sigma(\mu) \bullet \Sigma(\sigma)} \sub {\unrestrict \tau}\\
    &\equiv \Coh {\Sigma(\Theta)} {\Sigma(C)} {\Sigma(\mu)} \sub {\Sigma(\sigma) \bullet \unrestrict \tau}\\
    &\equiv \Coh {\Sigma(\Theta)} {\Sigma(C)} {\Sigma(\mu)} \sub {\unrestrict (\sigma \bullet \tau)}\\
    &\equiv \Coh {\Theta} {C} {\mu} \sub {\sigma \bullet \tau}
  \end{align*}
  where the second to last line is given by property
  \[\unrestrict (\sigma \bullet \tau) \equiv \Sigma(\sigma) \bullet \unrestrict \tau\]
  which holds for all \(\sigma : \arr \Theta \star \Delta\) and is proven in \funcn{Catt.Syntax.Properties}{-comp}{\textsf{\(\downarrow\)-comp}}, and the line before is given by the inductive hypothesis.

  If instead we had \(A = \arr s {A'} t\), then:
  \begin{align*}
    \Coh \Theta C \mu \sub \sigma \sub \tau
    &\equiv \Coh {\Sigma(\Theta)} {\Sigma(C)} {\Sigma(\mu)} \sub {\unrestrict \sigma} \sub \tau\\
    &\equiv \Coh {\Sigma(\Theta)} {\Sigma(C)} {\Sigma(\mu)} \sub {\unrestrict \sigma \bullet \tau}\\
    &\equiv \Coh {\Sigma(\Theta)} {\Sigma(C)} {\Sigma(\mu)} \sub {\unrestrict (\sigma \bullet \tau)}\\
    &\equiv \Coh \Theta C \mu \sub {\sigma \bullet \tau}
  \end{align*}
  where we use the inductive hypothesis after applying the equality
  \[ \unrestrict (\sigma \bullet \tau) \equiv \unrestrict \sigma \bullet \tau \]
  which holds for all \(\sigma : \arr \Theta {\arr s {A'} t} \Delta\) by \funcn{Catt.Syntax.Properties}{-comp-higher}{\textsf{\(\downarrow\)-comp-higher}}.
\end{proof}

This proposition proves that the syntax of \Cattr forms a category, which we will not name as we will work instead with the subcategory containing well-formed contexts and substitutions, introduced in the following sections.

\paragraph{Discs}
We finish our discussion of the syntax of \Cattr by giving formal definitions of disc and sphere contexts, some constructions on these and their properties. This will allow these to be used as examples in following sections, and preempts the use of discs in the first two equality rules that we will introduce, disc removal and endo-coherence removal.

We begin with the defintions of discs, spheres, and sphere types, which can be found in \module{Catt.Discs} as \func{Catt.Discs}{Disc}, \func{Catt.Discs}{Sphere}, and \func{Catt.Discs}{sphere-type}. We write the sphere type as \(U^n\), which is intentionally close to the notation of the standard type \(\mathcal{U}_\Delta^n\), as it will turn out that these coincide.

\begin{definition}
  We mutually define the disc contexts \(D^n\), sphere contexts \(S^n\), and sphere type \(U^n \in \Type_{S^n}\).
  \begin{mathpar}
    D^n = S^n , (d_n^- : U^n) \and
    S^0 = \emptyset \and
    S^{n+1} = D^n , (d_n^+ : \wk(U^n)) \\
    U^0 = \star \and
    U^{n+1} = \arr {d_n^-} {\wk(\wk(U^{n+1}))} {d_n^+}
  \end{mathpar}
  We will sometimes refer to the last variable of \(D^n\) as \(d_n\) instead of \(d_n^-\), given that there is no \(d_n^+\) in the context.
\end{definition}

We also characterise the substitutions from a sphere or disc. These are given by \func{Catt.Discs}{sub-from-sphere} and \func{Catt.Discs}{sub-from-disc} in the formalisation.

\begin{definition}
  Let \(A : \Type_\Gamma\) be a type and suppose \(n = \dim(A)\). Define the substitution \(\{A\} : S^n \to \Gamma\) inductively by:
  \[ \{\star\} = \langle \rangle \qquad \{\arr s A t\} = \langle \{ A \}, s, t \rangle\]
  Further, given a term \(t : \Term_\Gamma\), define the substitution \(\{A,t\} : D^n \to \Gamma\) by \(\{A, t\} = \langle \{A\}, t \rangle\).
\end{definition}

In \module{Catt.Discs.Properties}, various facts about these constructions are proved which we list below.

\begin{lemma}
  \label{lem:disc-prop}
  The following hold:
  \begin{lemmaenum}
  \item \label{item:disc-prop-dim}\(\dim(D^n) = \dim(U^n) = n\) and \(\dim(S^n) = \max(n - 1, 0)\).
  \item \label{item:disc-prop-susp} \(\Sigma(D^n) \equiv D^{n+1}\), \(\Sigma(S^n) \equiv S^{n+1}\), and \(\Sigma(U^n) \equiv U^{n+1}\).
  \item \label{item:disc-prop-wk} \(\{\wk(A)\} \equiv \wk(\{A\})\) and \(\{\wk(A), \wk(t)\} \equiv \wk(\{A,t\})\).
  \item \label{item:disc-prop-sub-susp} \(\{\Sigma(A)\} \equiv \Sigma(\{A\})\) and \(\{\Sigma(A),\Sigma(t)\} \equiv \Sigma(\{A,t\})\).
  \item \label{item:disc-prop-sub-sub} \(\{A \sub \sigma\} \equiv \{A\} \bullet \sigma\) and \(\{A \sub \sigma,t \sub \sigma\} \equiv \{A,t\}\bullet \sigma\).
  \item \label{item:disc-prop-sub-from} \(U^n \sub{\{A\}} \equiv A\) and hence \(\wk(U^n)\sub{\{A,t\}} \equiv A\).
  \item For \(\tau : S^n \to \Gamma\), \(\tau \equiv \{U^n \sub \tau\}\).
  \item For \(\tau : D^n \to \Gamma\), \(\tau \equiv \{\wk(U^n) \sub \tau, d_n \sub \tau\}\).
  \end{lemmaenum}
  for all \(n \in \mathbb{N}\) and appropriate \(A\), \(t\), and \(\sigma\).
\end{lemma}

The last two statements finish the characterisation of substitutions from spheres and discs as all such substitutions are of the form \(\{A\}\) or \(\{A,t\}\) respectively.

In \module{Catt.Discs.Pasting}, it is shown that \(D^n\) is a ps-context for each \(n\). Therefore, as in \cref{sec:basic-constructions}, the identity on a term \(t\) of type \(A\) can be defined as:
\[ \id(A,t) = \Coh {D^n} {\arr {d_n} {\wk(U^n)} {d_n}} {\{A,t\}} \]
where \(n = \dim(A)\). Many properties of identity terms can be easily derived from \cref{lem:disc-prop}.


\subsection{Typing and equality}
\label{sec:typing-equality}

The typing rules for \Cattr differ from those from \Catt in three key ways:
\begin{enumerate}
\item The fixed conditions on the support of the types in a coherence have been replaced by a set of operations \(\mathcal{O}\). Instead of having two typing rules for coherences, one for equivalences and one for composites, we simply have one typing rule and specify that a coherence \(\Coh \Delta {\arr s A t} \sigma\) can be well-formed when:
  \[ (\Delta, \supp(s), \supp(t)) \in \mathcal{O} \]
This will be further motivated and explained in \cref{sec:support}.
\item A definitional equality is added to the system, generated by a set of equality rules \(\mathcal{R}\) which specifies pairs of terms which should be equated. The equality take the form of three new judgements:
  \begin{alignat*}{2}
  &\Gamma \vdash A = B&\qquad&\text{\(A, B \in \Type_\Gamma\) are equal in context \(\Gamma\).}\\
  &\Gamma \vdash s = t &&\text{\(s, t \in \Term_\Gamma\) are equal in context \(\Gamma\).}\\
  &\Gamma \vdash \tau = \sigma &&\text{\(\tau : \Theta \to \Gamma\) and \(\sigma : \Delta \to \Gamma\) are equal.}
  \end{alignat*}
  These judgements are all mutually defined (and are in fact mutually defined with the typing judgements). We may sometimes abbreviate these judgements to \(A = B\), \(s = t\), and \(\tau = \sigma\) when the contexts of each piece of syntax is clear.
\item The typing rules are adjusted to account for this definitional equality, via the addition of a conversion rule.
\end{enumerate}

The conversion rule is the only additional typing rule that must be added to \Cattr, and takes the following form:
\begin{mathpar}
  \inferrule {\Gamma \vdash s : A \and \Gamma \vdash A = B}{\Gamma \vdash s : B}\textsc{conv}
\end{mathpar}
allowing the type of any term to vary up to the definitional equality. This rule accounts for all of the semistrict behaviour in the theories we introduce in \cref{cha:cattstrict}.

By adding this rule, and allowing the type of a term to vary up to definitional equality instead of syntactic equality, we allow more terms in the theory to become composable. Suppose we have terms \(f : x \to y\) and \(g : y' \to z\). In \Catt, we would not be able to form the vertical composition of these terms, as \(y\) and \(y'\) are not the same. If we now suppose that \(\Gamma \vdash y = y'\), then it will follow that \(\Gamma \vdash x \to y = x \to y'\), and so using the conversion rule we get:
\begin{mathpar}
  \inferrule{\inferrule*{\Gamma \vdash f : x \to y \and \inferrule*{\Gamma \vdash y = y'}{\Gamma \vdash x \to y = x \to y'}}{\Gamma \vdash f : x \to y'} \and \Gamma \vdash g : y' \to z}{\Gamma \vdash f * g : x \to z}
\end{mathpar}
We remark that adding definitional equality does not simply quotient the terms of the theory, but also allows new terms to be well-formed as above.

The definitional equality judgements are given by the rules in \cref{fig:equality} and appear in the formalisation along side the typing rules in \module{Catt.Typing}. These are generated by the set of \emph{equality rules} \(\mathcal{R}\), which is a set of triples of the form \((\Gamma, s, t)\) where \(\Gamma\) is a context and \(s,t \in \Term_\Gamma\). The key inference rule for equality is then:
\begin{mathpar}
  \inferrule{\Gamma \vdash s : A \and (\Gamma,s,t) \in \mathcal{R}}{\Gamma \vdash s = t}\textsc{rule}
\end{mathpar}
which says that if a triple \((\Gamma, s, t)\) is in \(\mathcal{R}\), then \(\Gamma \vdash s = t\) if \(s\) is well-formed in \(\Gamma\). The typing prerequisite forces the definitions of equality and typing to be mutually defined, and ensures that we only apply our equality rules to well-behaved terms.

We note the asymmetry of this rule, in that only the left hand side is required to be well-formed. Every rule introduced in this thesis will take the form of some reduction from the left hand side to the right hand side, and we will be able to prove that typing for the right hand side follows from typing for the left hand side for every equality we consider. The converse may not hold in general, necessitating the condition on the left hand side. This is similar to \(\beta\)-reduction in the \(\lambda\)-calculus, where an untyped term can reduce to a simply typed term.

The remainder of the inference rules for equality simply close under each constructor, reflexivity, symmetry, and transitivity. It is only necessary to give symmetry and transitivity rules for terms, and a reflexivity rule for variables, with these properties following for the other judgements by simple induction.

\begin{lemma}
  The definitional equality relations on terms, types, and substitutions are equivalence relations, for any \(\mathcal{R}\).
\end{lemma}
\begin{proof}
  Proofs of these are found in \module{Catt.Typing.Properties.Base}.
\end{proof}

It is also possible to prove that each term has a canonical type.

\begin{definition}
  The \emph{canonical type} of a term \(t : \Term_\Gamma\), \(\ty(t)\), is defined by a case split on \(t\). If \(t\) is a variable then the canonical type is the corresponding type in the context \(\Gamma\). Otherwise, if \(t \equiv \Coh \Delta A \sigma\) then the canonical type is \(A \sub \sigma\).
\end{definition}

This can be used to show that the type of a well-formed term is unique up to definitional equality, and is equal to this canonical type.

\begin{lemma}
  \label{lem:ty-unique}
  If \(\Gamma \vdash s : A\), then \(\Gamma \vdash s : ty(s)\) and \(\Gamma \vdash A = \ty(s)\). Further, if \(\Gamma \vdash s : A\) and \(\Gamma \vdash s : B\) then \(\Gamma \vdash A = B\).
\end{lemma}
\begin{proof}
  We prove the first part by induction on the derivation \(\Gamma \vdash s : A\). If the derivation is derived from the conversion rule applied to \(\Gamma \vdash s : B\) and \(\Gamma \vdash A = B\), then by inductive hypothesis we have \(\Gamma \vdash s : \ty(s)\) and \(\Gamma \vdash B = \ty(s)\). By transitivity, we obtain \(\Gamma \vdash A = \ty(s)\) as required. The second part follows directly from the applying the first part to both derivations.
\end{proof}

Using the canonical type, we can define the canonical identity on a term.

\begin{definition}
  \label{def:canonical-id}
  Given a term \(t : \Term_\Gamma\), let its \emph{canonical identity} be given by:
  \[ \id(t) \equiv \id(\ty(t), t)\]
  This construction can be iterated, and we say that a term is an \emph{iterated canonical identity} if it is on the form \(\id^k(t)\) for some \(k\).
\end{definition}

There is not much more that can be proved about the definitional equality at this point without knowing more about the rule set \(\mathcal{R}\). In \cref{sec:ruleset}, certain conditions will be imposed on the set of equality rules, that will allow further lemmas to be proved in large generality.

\paragraph{Disc removal}

We now give our first example of an equality rule, \emph{disc removal}. Disc removal removes unary composites, replacing them with the underlying term. We recall that for every \(n\), there exists the \(n\)-dimensional disc context \(D^n\), and that given a term \(t \in \Term_\Gamma\) and \(n\)-dimensional type \(A \in \Type_\Gamma\), there exists a substitution \(\{A,t\} : D^n \to \Gamma\). The unary composite of a term \(t\) of type \(A\) of dimension \(n\) is then the coherence:
\[\Coh {D^n} {\wk(U^n)} {\{A,t\}}\]
Disc removal equates this with the term \(t\), making the following rule admissible:
\begin{mathpar}
  \inferrule{\Gamma \vdash t : A \\ \Gamma \vdash A}{\Gamma \vdash \Coh {D^n} {\wk(U^n)} {\{A,t\}} = t}\textsc{dr}
\end{mathpar}
with the removal of the disc coherence giving the name to this equality rule.

Assembling disc removal into a rule set \(\mathcal{R}\) is simple, as it is possible to simply give a syntactic condition with no need to refer to typing.

\begin{definition}
  The \emph{disc removal rule set}, \dr, is the set consisting of the triples:
  \[ (\Gamma, \Coh {D^n} {\wk(U^n)} {\{A,t\}}, t) \]
  for each context \(\Gamma\), type \(A : \Type_\Gamma\), and term \(t : \Term_\Gamma\) where \(n = \dim(A)\).

  A set of rules \(\mathcal{R}\) \emph{contains disc removal} if \(\dr \subseteq \mathcal{R}\). Further we say that \(\mathcal{R}\) \emph{has disc removal} if the rule \textsc{dr} holds in the generated theory.
\end{definition}

The inference rule \textsc{dr} follows the \textsc{rule} and typing properties about discs which will be given in \cref{sec:ruleset}.

We draw attention to the typing premise of \textsc{rule}. If we know that the unary composite of a term \(t\) is well typed, then it follows that \(t\) itself must have been well-formed, but we cannot infer that the term \(\Coh {D^n} {\wk(U^n)} {\{A,t\}}\) is well-formed from \(t\) being well-formed. In particular, knowing that \(t\) is well-formed does not constrain \(A\) at all without knowing that the given type \(A\) is the type of \(t\). We must therefore include an additional typing premise if we want to avoid well-formed and non-well-formed terms being equated.

\afterpage{%
    \clearpage% flush all other floats
    \ifodd\value{page}
    \else% uncomment this else to get odd/even instead of even/odd
      \expandafter\afterpage% put it on the next page if this one is odd
    \fi
    {%
      \begin{figure}[hbtp]
        \centering
        \fbox{\begin{subfigure}{0.46\textwidth}
            \vspace{0.4pt}
            \begin{mathpar}
              \inferrule{ }{\star : \Type_\Gamma}
              \and
              \inferrule{x \in \Var(\Gamma)} {x : \Term_\Gamma}
              \and
              \inferrule{A : \Type_\Gamma}{\langle A \rangle : \emptyset \to \Gamma}
              \and
              \inferrule{ }{\emptyset : \Ctx}
              \and
              \inferrule{\Gamma : \Ctx \\ A : \Type_\Gamma}{\Gamma, (x : A) : \Ctx}
              \and
              \inferrule{\sigma : \arr \Delta A \Gamma \\ t : \Term_\Gamma \\ B : \Type_\Delta}{\langle \sigma , t \rangle : \arr {\Delta, (x : B)} A \Gamma}
              \and
              \inferrule{A : \Type_\Gamma \\ s : \Term_\Gamma \\ t : \Term_\Gamma} {\arr s A t : \Type_\Gamma}
              \and
              \inferrule{\\\\\Delta : \Ctx \\ A : \Type_\Delta \\ \sigma : \arr \Delta \star \Gamma}{\Coh \Delta A \sigma : \Term_\Gamma}
            \end{mathpar}
            \caption{Syntax}
          \end{subfigure}}
        \hfill
        \fbox{\begin{subfigure}{0.49\textwidth}
            \begin{mathpar}
              \inferrule{ }{\emptyset \vdash}
              \and
              \inferrule{\Gamma \vdash\\ \Gamma \vdash A}{\Gamma, (x : A) \vdash}
              \and
              \inferrule{ }{\Gamma \vdash \star}
              \and
              \inferrule{\Gamma \vdash s : A \\ \Gamma \vdash A \\ \Gamma \vdash t : A}{\Gamma \vdash \arr s A t}
              \and
              \inferrule{\Gamma \vdash A}{\Gamma \vdash \langle A \rangle : \emptyset}
              \and
              \inferrule{\Gamma \vdash \sigma : \Delta\\ \Gamma \vdash t : A\sub\sigma}{\Gamma \vdash \langle \sigma , t \rangle : \Delta, (x : A)}
              \and
              \inferrule{(x : A) \in \Gamma}{\Gamma \vdash x : A}
              \and
              \inferrule{\Gamma \vdash t : A\\ \Gamma \vdash A = B}{\Gamma \vdash t : B}\textsc{conv}
              \and
              \inferrule{\Delta \vdash_{\mathsf{ps}}\\ \Delta \vdash \arr s A t \\ \Gamma \vdash \sigma : \Delta\\(\Delta, \Supp(s), \Supp(t)) \in \mathcal{O}}{\Gamma \vdash \Coh \Delta {\arr s A t} \sigma : \arr {s \sub \sigma} {A \sub \sigma} {t \sub \sigma}}
            \end{mathpar}
            \caption{Typing}
          \end{subfigure}}

        \vspace{7pt}
        \fbox{\begin{subfigure}{0.9852\textwidth}
            \begin{mathpar}
              \inferrule{\Gamma \vdash s : A \\ (\Gamma, s, t) \in \mathcal{R}}{\Gamma \vdash s = t}\textsc{rule} \and
              \inferrule{x \in \Var(\Gamma)}{\Gamma \vdash x = x} \and
              \inferrule{\Gamma \vdash s = t}{\Gamma \vdash t = s} \and
              \inferrule{\Gamma \vdash s = t \\ \Gamma \vdash t = u}{\Gamma \vdash s = u} \and
              \inferrule{\Delta \vdash A = B \\ \Gamma \vdash \sigma = \tau}{\Gamma \vdash \Coh \Delta A \sigma = \Coh \Delta B \tau} \and
              \inferrule{ }{\Gamma \vdash \star = \star} \and
              \inferrule{\Gamma \vdash s = s' \\ \Gamma \vdash t = t' \\ \Gamma \vdash A = A'}{\Gamma \vdash \arr s A t = \arr {s'} {A'} {t'}}\and
              \inferrule{\Gamma \vdash A = B}{\Gamma \vdash \langle A \rangle = \langle B \rangle}\and
              \inferrule{\Gamma \vdash \sigma = \tau \\ \Gamma \vdash s = t}{\Gamma \vdash \langle \sigma, s \rangle = \langle \tau, t \rangle}
            \end{mathpar}
            \caption{Equality}
            \label{fig:equality}
          \end{subfigure}}

        \vspace{7pt}
        \fbox{\begin{subfigure}{0.46\textwidth}
            \vspace{1pt}
            \begin{mathpar}
              \inferrule{ }{(x : \star) \vdash_{\mathsf{ps}} x : \star}
              \and
              \inferrule{\Gamma \vdash_{\mathsf{ps}} x : A}{\Gamma, (y : A), (f : \arr x A y)}
              \and
              \inferrule{\Gamma \vdash_{\mathsf{ps}} x : \arr s A t}{\Gamma \vdash_{\mathsf{ps}} t : A}
              \and
              \inferrule{\Gamma \vdash_{\mathsf{ps}} x : \star}{\Gamma \vdash_{\mathsf{ps}}}
            \end{mathpar}
            \caption{Ps-contexts}
          \end{subfigure}}
        \hfill
        \fbox{\begin{subfigure}{0.49\textwidth}
            \vspace{6pt}
            \begin{mathpar}
              \FV(\star) = \{\}
              \and
              \FV(\langle A \rangle) = \FV(A)
              \\
              \FV(x) = \{x\} \text{ for }x \in \Var
              \\
              \FV(\Coh \Delta A \sigma) = \FV(\sigma)
              \\
              \FV(\arr s A t) = \FV(s) \cup \FV(A) \cup \FV(t)
              \\
              \FV(\langle \sigma , t \rangle) = \FV(\sigma) \cup \FV(t)
            \end{mathpar}
            \caption{Free variables}
          \end{subfigure}}
        \caption{\Cattr: syntax, typing, and operations}
        \label{fig:cattr}
      \end{figure}

      \begin{figure}
        \ContinuedFloat
        \fbox{\begin{subfigure}{1\textwidth}
            \begin{align*}
              \DC_\emptyset(\emptyset) &= \emptyset\\
              \DC_{\Gamma, x : A}(V) &= \begin{cases*}
                \DC_\Gamma(V)&if \(x \not\in V\)\\
                \{x\} \cup \DC_\Gamma(V \setminus \{x\} \cup \FV(A))&if \(x \in V\)\\
              \end{cases*}\\
              \Supp(t) &= \DC_\Gamma(\FV(t))\text{ for }t \in \Term_\Gamma\\
              \Supp(A) &= \DC_\Gamma(\FV(A))\text{ for }A \in \Type_\Gamma\\
              \Supp(\sigma) &= \DC_\Gamma(\FV(\sigma))\text{ for }\sigma : \arr {\Delta} A \Gamma
            \end{align*}
            \caption{Support}
          \end{subfigure}}

        \vspace{7pt}
        \fbox{\begin{subfigure}{\textwidth}
            \begin{align*}
              x \sub \sigma &= t\text{ if }(x \mapsto t) \in \sigma\\
              \Coh \Theta A \tau \sub \sigma &=
                                               \begin{cases*}
                                                 \Coh \Theta A {\tau \bullet \sigma}&if \(\dim(\ty(\sigma)) = 0\)\\
                                                 \Coh {\Sigma(\Theta)} {\Sigma(A)} {\Sigma(\tau)} \sub {\unrestrict\sigma}&otherwise
                                               \end{cases*}
              \\
              \star \sub \sigma &= \ty(\sigma)\\
              (\arr s A t) \sub \sigma &= \arr {s \sub \sigma} {A \sub \sigma} {t \sub \sigma}\\
              \langle A \rangle \bullet \sigma &= \langle A \sub \sigma \rangle\\
              \langle \tau , t \rangle \bullet \sigma &= \langle \tau \bullet \sigma , t \sub \sigma \rangle
            \end{align*}
            \caption{Substitution application}
          \end{subfigure}}

        \vspace{7pt}
        \fbox{\begin{subfigure}{0.475\textwidth}
            \begin{align*}
              \Sigma (\emptyset) &= (N : \star), (S : \star)\\
              \Sigma (\Gamma, (x : A)) &= \Sigma \Gamma, (x : \Sigma A)\\
              \Sigma (\star) &= \arr N \star S\\
              \Sigma (\arr s A t) &= \arr {\Sigma s} {\Sigma A} {\Sigma t}\\
              \Sigma (x) &= x\\
              \Sigma (\Coh \Delta A \sigma) &= \Coh {\Sigma(\Delta)} {\Sigma(A)} {\Sigma(\sigma)}\\
              \Sigma(\sigma) &= \unrestrict(\Sigma'(\sigma))\\[7.25pt]
              \Sigma'(\langle A \rangle) &= \langle \Sigma(A) \rangle\\
              \Sigma'(\langle \sigma, x \rangle) &= \langle \Sigma'(\sigma), \Sigma(t) \rangle\\
              \unrestrict\langle \arr s A t \rangle &= \langle A , s , t \rangle\\
              \unrestrict\langle \sigma, t \rangle &= \langle \unrestrict \sigma, t \rangle
            \end{align*}
            \caption{Suspension}
          \end{subfigure}}
        \hfill
        \begin{subfigure}{0.49\textwidth}
          \fbox{\begin{subfigure}{1\textwidth}
              \begin{align*}
                \wk(\star) &= \star\\
                \wk(\arr s A t) &= \arr {\wk(s)} {\wk(A)} {\wk(t)}\\
                \wk(x) &= x\\
                \wk(\Coh \Delta A \sigma) &= \Coh \Delta A {\wk(\sigma)}\\
                \wk(\langle A \rangle) &= \langle \wk(A) \rangle\\
                \wk(\langle \sigma, t \rangle) &= \langle \wk(\sigma), \wk(t) \rangle
              \end{align*}
              \caption{Weakening}
              \label{fig:wk}
            \end{subfigure}}

          \vspace{7pt}
          \fbox{\begin{subfigure}{1\textwidth}
              \begin{align*}
                \id_\emptyset &= \langle \star \rangle\\
                \id_{\Gamma, (x : A)} &= \langle \wk(\id_\Gamma), x \rangle
              \end{align*}
              \caption{Identity substitution}
            \end{subfigure}}
        \end{subfigure}
        \caption{\Cattr: syntax, typing, and operations}
      \end{figure}
    }%
  }

\section{The set of operations \texorpdfstring{\(\mathcal{O}\)}{O}}
\label{sec:support}

In \cref{sec:typing-equality}, we introduced a set of operations \(\mathcal{O}\), which allows us to vary the operations available in the theory, much like the set \(\mathcal{R}\) allows us to vary the equality rules of the theory. The set \(\mathcal{O}\) replaces the conditions on the support of the type contained in a coherence, and consists of a set of triples of a context \(\Delta\), along with two sets \(x,y \subseteq \Var(\Delta)\). A certain type \(\arr s A t : \Type_\Delta\) is permitted to appear in a coherence exactly when \((\Delta , \supp(s), \supp(t))\) is an element of \(\mathcal{O}\).

There are two key advantages to setting up the theory this way.
\begin{itemize}
\item A clear separation is introduced in the metatheory and formalisation between properties that are specific to the support conditions in \Catt and those that are independent of the specific support conditions present.
\item The results in the following sections can be proven generically for different variants of \Catt.
\end{itemize}
In particular, the main utility we extract in this thesis is the ability to define groupoidal versions of the various semistrict theories we define in \cref{cha:cattstrict}. By letting \(\mathcal{O}\) consists of all possible triples, the support condition is effectively removed, producing a version of \Catt closer to Grothendieck's definition of \(\infty\)-groupoid (see \cref{sec:weak}).

\subsection{Operation sets}
\label{sec:operation-sets}

As previously mentioned, an operation set \(\mathcal{O}\) consists of a collection of triples of a context \(\Delta\) and two subsets of the variables of \(\Delta\).

We call a subset of the variables of a context a \emph{variable set}. In the formalisation, these variable sets are given as a list of booleans, one boolean for each variable of the context. These are given in \module{Catt.Support}, which also contains many constructions on them, including unions of these sets, subset relations, and the free variables of each piece of syntax. The variable sets of \(\Delta\) form a lattice with top element \(\Var(\Delta)\) and bottom element \(\emptyset\). The free variable constructions commute with weakening, as is proved in \module{Catt.Support.Properties} by mutual induction.

We recall the function \(\DC\) on these variable sets, given by \func{Catt.Support}{DC} in the formalisation, which produces the downwards closure of a variable set. This admits the following properties:

\begin{proposition}
  \(\DC\) is an idempotent join-semilattice homomorphism. It preserves binary joins (unions), subset inclusions, and preserves the top and bottom element of the lattice.
\end{proposition}

We further define the application of a substitution to a variable set below.

\begin{definition}
  Given a variable set \(V\) of \(\Delta\) and (standard) substitution \(\sigma : \Delta \to \Gamma\), we define the application of \(\sigma\) to \(V\), written \(V \sub \sigma\) to be a variable set of \(\Gamma\) given by:
  \begin{align*}
    V \sub {\langle \rangle} &= \emptyset\\
    V \sub {\langle \sigma , t \rangle} &=
                                          \begin{cases*}
                                            (V \setminus \{x\}) \sub \sigma \cup \FV(t)&if \(x \in V\)\\
                                            V \sub \sigma &otherwise
                                          \end{cases*}
  \end{align*}
  Where \(x\) is assumed to be the last variable of \(\Delta\) in the second case.
\end{definition}

We note that when representing variable sets as a list of booleans, these definitions are given by simple inductions on the length of the context. These constructions admit the following properties.

\begin{proposition}
  \label{prop:vs-sub}
  Let \(\Delta\) be a context. Then the function taking a variable set \(V\) of \(\Delta\) to \(V \sub \sigma\) is a join-semilattice homomorphism for any substitution \(\sigma : \Delta \to \Gamma\). Further, for a term \(t : \Term_\Delta\), a type \(A : \Type_\Delta\), or a substitution \(\tau : \arr \Theta A \Delta\), the following equalities hold:
  \begin{align*}
    \FV(t \sub \sigma) &= \FV(t) \sub \sigma \\
    \FV(A \sub \sigma) &= \FV(A) \sub \sigma \\
    \FV(\tau \bullet \sigma) &= \FV(\tau) \sub \sigma
  \end{align*}
  and hence \(\Var(\Delta) \sub \sigma = \FV(\id_\Delta) \sub \sigma = \FV(\id_\Delta \bullet \sigma) = \FV(\sigma)\). Finally, for any variable set \(V \subseteq \Var(\Theta)\) we have:
  \[ V \sub {\id_\Theta} = V \qquad V \sub {\tau \bullet \sigma} = V \sub \tau \sub \sigma \]
  for \(\tau : \Theta \to \Delta\) and \(\sigma : \Delta \to \Gamma\).
\end{proposition}
\begin{proof}
  All proofs proceed by induction on the length of the context \(\Delta\) and are given in \module{Catt.Support.Properties}.
\end{proof}

An operation set is then an element of:
\[ \Sigma_{\Delta : \Ctx} \mathcal{P}(\Var(\Delta)) \times \mathcal{P}(\Var(\Delta)) \]
In the formalisation this is defined in \module{Catt.Ops} to be a function from a context and two variable sets of that context to a universe.

\begin{remark}
  The definition of an operation set in the formalisation deviates from the presentation given here, as the version in the formalisation is proof relevant. The proof relevant definition allows us to give any type as the type of witnesses that a certain triple appears in \(\mathcal{O}\), including a type containing many distinct witnesses.

  If we wished to recover a definition closer to the classical set-based definition, we could enforce that this function has a universe of propositions as its codomain, instead of a universe of types, and use propositional truncations to define various versions of \(\mathcal{O}\). This is however unnecessary for any of the proofs appearing in this thesis, hence the choice of the proof relevant definition for simplicity. A similar observation will apply to the definition of equality rule sets introduced in \cref{sec:ruleset}.
\end{remark}

We can now introduce our first operation set, the operation set for groupoidal operations, which imposes no support conditions and allows all operations.

\begin{definition}
  We define the \emph{groupoidal operation set} \(\Group\) as:
  \[ \Group = \{ (\Delta, U, V) \mid \Delta : \Ctx, U \subseteq \Var(\Delta), V \subseteq \Var(\Delta) \} \]
  We will refer to \Cattr with the operation set \(\Group\) as \emph{groupoidal \Cattr} or \emph{groupoidal \Catt} (when \(\mathcal{R} = \emptyset\)).
\end{definition}

To recover the standard definition of \Catt, we must define the boundary sets of a pasting diagram. In \cref{sec:typing-catt}, these are given as the free variables of the boundary inclusion substitutions of pasting diagrams. Here we will instead give a direct definition of the variable sets corresponding to the free variables of the substitutions, delaying the definition of boundary inclusions of pasting diagrams until \cref{sec:trees}.

\begin{definition}
  Let \(\Delta\) be a ps-context. Define the \(n\)-boundary variable sets \(\bdry n -  \Delta\) and \(\bdry n + \Delta\) by induction on \(\Delta\):
\begin{align*}
  \bdry i \epsilon {(x : \star)} &= \{ x \}\\
  \bdry i \epsilon {\Gamma, (y : A) , (f : \arr x A y)} &=
                                                           \begin{cases*}
                                                             \bdry i \epsilon \Gamma&if \(i < \dim(A)\)\\
                                                             \bdry i - \Gamma&if \(i = \dim(A)\) and \(\epsilon = -\)\\
                                                             (\bdry i + \Gamma \cup \{ y \}) \setminus \{x\}&if \(i = \dim(A)\) and \(\epsilon = +\)\\
                                                             \bdry i \epsilon \Gamma \cup \{ y , f \}&otherwise
                                                           \end{cases*}
\end{align*}
These boundary sets appear in the formalisation as \func{Catt.Support}{pd-bd-vs}.
\end{definition}

The following lemma is immediate:

\begin{lemma}
  \label{lem:bdry-full}
  If \(n \geq \dim(\Delta)\), then \(\bdry n \epsilon \Delta = \Var(\Delta)\).
\end{lemma}
\begin{proof}
  A simple induction on the definition. A formalised proof appears as \func{Catt.Support.Properties}{pd-bd-vs-full}.
\end{proof}

With this definition we can introduce the regular operation set, which recovers the regular support conditions used in the definition of \Catt.

\begin{definition}
  The \emph{regular operation set} \Reg is defined to be:
  \[ \Reg = \{ (\Delta, \Var(\Delta), \Var(\Delta)) \mid \Delta \vdash_{\mathsf{ps}} \} \cup \{ (\Delta, \bdry {\dim(\Delta)-1} - \Delta, \bdry {\dim(\Delta)-1} + \Delta) \mid \Delta \vdash_{\mathsf{ps}} \} \]
  The first component allows equivalences to be well-formed, and the second gives the support condition for composites.
\end{definition}

The regular operation set has more standard presentation.

\begin{proposition}
  \label{prop:std-op}
  Define the set \Std of standard operations be defined as:
  \[ \Std = \{ (\Delta, \bdry n - \Delta, \bdry n + \Delta) \mid \Delta \vdash_{\mathsf{ps}} , n \geq \dim(\Delta) - 1 \} \]
  Then \(\Std = \Reg\).
\end{proposition}
\begin{proof}
  Suppose \((\Delta, U, V) \in \Reg\). If \(U = \bdry {\dim(\Delta) - 1} - \Delta\) and \(V = \bdry {\dim(\Delta) - 1} + \Delta\), then \((\Delta , U ,V)\) is trivially in \Std by letting \(n = \dim(\Delta) - 1\). If instead \(U = V = \Var(\Delta)\), then \((\Delta, U , V) \in \Std\) by letting \(n = \dim(\Delta)\) and applying \cref{lem:bdry-full}.

  Conversely, assume \((\Delta, U, V) \in \Std\). Then there is \(n \geq \dim(\Delta) - 1\) with \(U = \bdry n - \Delta\) and \(V = \bdry n + \Delta\). If \(n = \dim(\Delta) - 1\) then \((\Delta, U ,V)\) is trivially in \(\Reg\), and otherwise by \cref{lem:bdry-full} we have \(U = V = \Var(\Delta)\), and so \((\Delta,U,V)\) is again an element of \Reg. Hence \(\Reg = \Std\).
\end{proof}

This more uniform is sometimes easier to work with, and will be used to prove properties of \Reg in \cref{sec:operation-properties}.

\begin{remark}
  By letting \(\mathcal{O} = \emptyset\), we recover the type theory \textsf{GSeTT}~\cite{benjamin2021globular}, a type theory for globular sets.
\end{remark}

It would be possible to generalise the notion of operation set presented here by instead letting the set \(\mathcal{O}\) consist of triples \((\Delta, s,t)\) where \(s\) and \(t\) are terms over \(\Delta\) instead of variable sets over \(\Delta\). This would allow more control over which operations were allowed in the theory. As an example, we would be able to restrict the class of composites to contain only the standard composites, or even further restrict it to binary composites.

This is however unnecessary to present the regular and groupoidal versions of \Cattr. By only allowing the set of available operations to be specified up to the support of the contained terms, it is possible to show that a coherence being an operation is closed under equality by proving that equality preserves the support of a term.

\subsection{Operation properties}
\label{sec:operation-properties}

Currently, our set of operations is completely unconstrained, and we will be limited in the constructions that can be made in \Cattr. We therefore constrain these sets in two ways. The first enforces that our set of operations is closed under suspension, for which we need to be able to suspend variable sets. This is defined in the formalisation as \func{Catt.Suspension.Support}{susp-vs}.

\begin{definition}
  Let \(\Delta\) be a context. The suspension of a variable set \(V\) over \(\Delta\) is defined to be:
  \[ \Sigma(V) = \{ N , S \} \cup V \]
  where \(\Sigma(V)\), the suspension of \(V\) is a variable set over \(\Sigma(\Delta)\).
\end{definition}
The suspension of a variable set commutes with taking the support of a piece of syntax, as shown in the next lemma.
\begin{lemma}
  \label{lem:susp-vs-prop}
  The following equalities hold:
  \[ \Supp(\Sigma(s)) = \Sigma(\Supp(s)) \qquad \Supp(\Sigma(A)) = \Sigma(\Supp(A)) \qquad \Supp(\Sigma(\sigma)) = \Sigma(\Supp(\sigma)) \]
  for term \(s : \Term_\Gamma\), type \(A : \Type_\Gamma\), and substitution \(\sigma : \arr \Delta \star \Gamma\).
\end{lemma}
\begin{proof}
  All equalities hold by a mutual induction on terms, types, and substitutions, with a secondary induction on the context \(\Gamma\) for the case of the variables and the base type \(\star\). These calculations are given in \module{Catt.Suspension.Support}.
\end{proof}

We can then define our first property on operation sets.

\begin{definition}
  An operation set \(\mathcal{O}\) is \emph{suspendable} if:
  \[ (\Delta, U, V) \in \mathcal{O} \implies (\Sigma(\Delta), \Sigma(U), \Sigma(V)) \in \mathcal{O} \]
  For \(\Delta : \Ctx\) and \(U, V \subseteq \Var(\Delta)\).
\end{definition}

The groupoidal operation set is trivially suspendable. To show that the regular operation set is suspendable, we prove the following proposition.

\begin{proposition}
  Let \(\Delta\) be a ps-context. Then:
  \[\Sigma(\bdry n \epsilon \Delta) = \bdry {n + 1} {\epsilon} {\Sigma(\Delta)}\]
  for \(n \in \mathbb{N}\) and \(\epsilon \in \{-,+\}\).
\end{proposition}
\begin{proof}
  We proceed by induction on \(\Delta\). First suppose \(\Delta = (x : \star)\). We then have:
  \[ \Sigma(\bdry n \epsilon {(x : \star)}) = \Sigma(\{x\}) = \{N,S,x\} = \bdry {n + 1} {\epsilon} {\Sigma((x: \star))} \]
  Now suppose that \(\Delta = \Delta', (y : A), (f : \arr x A y)\). We split into cases on \(n\), \(\dim(A)\), and \(\epsilon\):
  \begin{itemize}
  \item If \(n < \dim(A)\) then
    \begin{align*}
      \Sigma(\bdry n \epsilon \Delta) &= \Sigma(\bdry n \epsilon {\Delta'})\\
                                      &=  \bdry {n + 1} {\epsilon} {\Sigma(\Delta')} &\text{by inductive hypothesis}\\
                                      &= \bdry {n + 1} {\epsilon} {\Sigma(\Delta)} &\text{as }n + 1 < \dim(\Sigma(A))\\
      \intertext{
      \item If \(n = \dim(A)\) and \(\epsilon = -\) then the proof is similar to the preceding case.
      \item If \(n = \dim(A)\) and \(\epsilon = +\) then:
      }
      \Sigma(\bdry n + \Delta) &= \Sigma((\bdry n + {\Delta'} \cup \{y\}) \setminus \{x\})\\
                               &= (\Sigma(\bdry n + {\Delta'}) \cup \{y\}) \setminus \{x\} \\
                               &= (\bdry {n+1} + {\Sigma(\Delta')} \cup \{y\}) \setminus \{x\} &\text{by inductive hypothesis}\\
                               &= \bdry {n+1} + {\Sigma(\Delta)} &\text{as }n + 1 = \dim(\Sigma(A))\\
      \intertext{\item If \(n > \dim(A)\) then}
      \Sigma(\bdry n \epsilon \Delta) &= \Sigma((\bdry n \epsilon {\Delta'} \cup \{y,f\})\\
                                      &= \Sigma(\bdry n + {\Delta'}) \cup \{y,f\} \\
                                      &= \bdry {n+1} + {\Sigma(\Delta')} \cup \{y, f\} &\text{by inductive hypothesis}\\
                                      &= \bdry {n+1} + {\Sigma(\Delta)} &\text{as }n + 1 > \dim(\Sigma(A))
    \end{align*}
  \end{itemize}
  Hence, the desired equality holds in all cases.
\end{proof}

\begin{corollary}
  The regular operation set is suspendable.
\end{corollary}
\begin{proof}
  By \cref{prop:std-op}, it suffices to show that the standard operation set is suspendable, which is clear from the above proposition.
\end{proof}

The second restriction we put on operation sets is that there are enough operations to create the standard coherences presented in \cref{sec:basic-constructions}.

\begin{definition}
  An operation set \(\mathcal{O}\) \emph{contains the standard operations} if \(\Std \subseteq \mathcal{O}\).
\end{definition}

The groupoidal operation set clearly contains the standard operations, and the regular operation set does due to \cref{prop:std-op}. The empty operation set does not contain the standard operations. We end this section with the following proposition about the support of terms in a disc.

\begin{proposition}
  For \(n \in \mathbb{N}\) the following two equations hold:
  \[ \bdry n - {D^{n+1}} = \Var(S^n) \cup \{d_n^-\} = \Var(D^n) \qquad \bdry n + {D^{n+1}} = \Var(S^n) \cup \{d_{n+1}^+\}\]
  Further, the following equations hold:
    \[\FV(U^n) = \Var(S^n) \qquad \Supp(d_n^-) = \Var(D^n) = \bdry n - {D^{n+1}} \qquad \Supp(d_n^+) = \bdry n + {D^{n+1}} \]
  again for any \(n \in \mathbb{N}\).
\end{proposition}
\begin{proof}
  The first equations follow by a simple case analysis, using that \(\bdry n - {D^n} = \Var(D^n)\) by \cref{lem:bdry-full,item:disc-prop-dim}. The free variables of \(U^n\) are easily calculated inductively, and the support of \(d_n^-\) and \(d_n^+\) are easy to compute using the first parts of the proposition, and that \(FV(U^n) \subseteq \Supp(d_n^-)\) and \(\FV(U^n) \subseteq \Supp(d_n^+)\) as the support of a term is downwards closed.

  These proofs are formalised in \module{Catt.Discs.Support}.
\end{proof}

\begin{corollary}
  \label{cor:disc-op}
  Both \((D^{n+1}, d_n^-, d_n^+)\) and \((D^n, d_n, d_n)\) are in \(\Std\) for each \(n\).
\end{corollary}

\subsection{Invertible generators}
\label{sec:invertibility}

\todo[inline]{Ideas about invertibility here?}

\todo[inline]{New type generator}

\todo[inline]{Limitation of this generator}

\todo[inline]{Some variations on support schemes}

\todo[inline]{Explain results you would want to prove}
\todo[inline]{Pasting contexts vs Contractible contexts}

\section{The set of equality rules \texorpdfstring{\(\mathcal{R}\)}{R}}
\label{sec:ruleset}

In \Cattr, the definitional equality relation is generated by a set of rules \(\mathcal{R}\) formed of triples of a contexts and two terms in the context which should be made equal. In this section we discuss some operations on these equality sets and properties that they may have.

\begin{remark}
  In the formalisation the set of equality rules is defined similarly to the set of operations \(\mathcal{O}\). It is defined as a function that takes a context and two terms over that context and returns a type. It is therefore proof relevant in the same way as the operation sets.
\end{remark}

The equality rule sets inherit some operations and relations just by being sets. We can easily form the empty equality set, which allows us to recover the weak type theory \Catt, and given two equality sets we can take their union, to get a type theory with equalities from both sets (we note that the equality generated by a union is in general coarser than the union of the equalities generated by the individual sets).

To aid readability when reasoning about typing and equality with multiple distinct operation, we may subscript the turnstile symbol in various judgements with the set of equality rules being used. For example, we may write the judgements for typing of a term \(t\) in the type theory generated from rules \(\mathcal{R}\) as
\[ \Gamma \vdash_{\mathcal{R}} t : A \]
and the corresponding judgement for the equality of two terms \(s\) and \(t\) as
\[ \Gamma \vdash_{\mathcal{R}} s = t \]
Equality rule sets can also be subsets of eachother, leading to the following lemma.

\begin{lemma}
  \label{lem:subset-lem}
  Let \(\mathcal{R}\) and \(\mathcal{S}\) be two equality rule sets and suppose that
  \[ \Gamma \vdash_{\mathcal{S}} s = t\]
  for all \((\Gamma,s,t) \in \mathcal{R}\) with \(\Gamma \vdash_{\mathcal{S}} s : A\) for some \(A : \Type_\Gamma\). Then the following inference rules hold:
  \begin{mathpar}
    \inferrule{\Gamma \vdash_{\mathcal{R}}}{\Gamma \vdash_{\mathcal{S}}} \and
    \inferrule{\Gamma \vdash_{\mathcal{R}} t : A}{\Gamma \vdash_{\mathcal{S}} t : A} \and
    \inferrule{\Gamma \vdash_{\mathcal{R}} A}{\Gamma \vdash_{\mathcal{S}} A} \and
    \inferrule{\Gamma \vdash_{\mathcal{R}} \sigma : \Delta}{\Gamma \vdash_{\mathcal{S}} \sigma : \Delta} \\
    \inferrule{\Gamma \vdash_{\mathcal{R}} s = t}{\Gamma \vdash_{\mathcal{S}} s = t} \and
    \inferrule{\Gamma \vdash_{\mathcal{R}} A = B}{\Gamma \vdash_{\mathcal{S}} A = B} \and
    \inferrule{\Gamma \vdash_{\mathcal{R}} \sigma = \tau}{\Gamma \vdash_{\mathcal{S}} \sigma = \tau}
  \end{mathpar}
  In particular these inference rules hold when \(\mathcal{R} \subseteq \mathcal{S}\).
\end{lemma}
\begin{proof}
  Follows from a simple induction. Details are given in the formalisation in module \module{Catt.Typing.Rule.Properties}.
\end{proof}
\begin{corollary}
  \label{cor:catt-to-r}
  Any context, term, type, or substitution that is well-formed in \Catt is also well-formed in \Cattr, for any equality set \(\mathcal{R}\).
\end{corollary}

Furthermore, we can immediately show that the application of a substitution to piece of syntax that is well-formed in \Catt is well-formed.

\begin{lemma}
  \label{lem:sub-catt}
  Let \(\mathcal{R}\) be any equality rule set. Then the following inference rules hold for \(\sigma : \arr \Delta \star \Gamma\):
  \begin{mathpar}
    \inferrule{\Delta \vdash_\emptyset A \\ \Gamma \vdash_{\mathcal{R}} \sigma : \Delta}{\Gamma \vdash_{\mathcal{R}} A \sub \sigma }\and
    \inferrule{\Delta \vdash_\emptyset s : A \\ \Gamma \vdash_{\mathcal{R}} \sigma : \Delta}{\Gamma \vdash_{\mathcal{R}} s \sub \sigma : A \sub \sigma } \and
    \inferrule{\Delta \vdash_\emptyset \tau : \Theta \\ \Gamma \vdash_{\mathcal{R}} \sigma : \Delta}{\Gamma \vdash_{\mathcal{R}} \tau \bullet \sigma : \Theta }
  \end{mathpar}
  where the judgements with a subscript empty set are judgements in the theory generated by the empty rule sets (judgements in \Catt).
\end{lemma}
\begin{proof}
  Follows immediately from a mutual induction, using that any equality in \Catt is syntactic. The proof is formalised in \module{Catt.Typing.Properties.Base}.
\end{proof}

An arbitrary set \(\mathcal{R}\) has very few restrictions on the equality relation it generates, and the terms that are well-formed because of it. A rule set \(\mathcal{R}\) could identify terms of different types, or identify two different variables (or even identify all variables or terms). This makes it difficult to prove much about the theory generated by an arbitrary set \(\mathcal{R}\).

To this end, we introduce certain conditions that these equality rule sets can satisfy. The first three of these conditions put certain closure properties on the set of rules \(\mathcal{R}\), and each allow various constructions to be well typed. We call theories that satisfy these three properties \emph{tame theories} and introduce these in \cref{sec:tame-theories}. In \cref{sec:further-conditions}, we introduce two more conditions which take the form of a property that the generated equality must satisfy.

By introducing theses conditions, we can prove various metatheoretic properties about \Cattr in a modular and generic way. This will allow the reuse of many constructions and proofs about the properties of these constructions in \cref{cha:cattstrict}, where two distinct type theories for semistrict \(\infty\)-categories are given.

In the following subsections, we will also show that the rule set for disc removal satisfies all these conditions. For all these conditions, we will have that if the condition holds on \(\mathcal{R}\) and on \(\mathcal{S}\) then it also holds on \(\mathcal{R}\cup \mathcal{S}\), and so these conditions can be proved individually for each rule set that is introduced. Further, the empty set will satisfy all of these conditions trivially, and so all proofs and constructions in the section apply to \Catt.

\subsection{Tame theories}
\label{sec:tame-theories}

Here we introduce the three core conditions on the equality rule set \(\mathcal{R}\) which we expect hold for any reasonable choice of rule set:
\begin{itemize}
\item The \emph{weakening condition}, which allows weakening to be well-formed.
\item The \emph{suspension condition}, which allows suspension to be well-formed.
\item The \emph{substitution condition}, which implies that the application of substitution to terms, types, and other substitutions (as substitution composition) preserves typing and equality.
\end{itemize}
We call an equality rule set \emph{tame} if it satisfies all three of these theories, and call the corresponding theory \Cattr a \emph{tame theory}.

\paragraph{Weakening condition}

For the weakening operation to be well-formed, meaning that the weakening of a well-formed piece of syntax is itself well-formed, the following closure property must hold on the set of rules \(\mathcal{R}\).

\begin{definition}
  A set of rules \(\mathcal{R}\) satisfies the \emph{weakening condition} if for all \((\Gamma,s,t) \in \mathcal{R}\) we have:
  \[ ((\Gamma, x : A), \wk(s), \wk(t)) \in \mathcal{R} \]
  for all \(A : \Type_\Gamma\).
\end{definition}

The following proposition is immediately provable by mutual induction on typing and equality. Its proof is given in \module{Catt.Typing.Properties.Weakening}.

\begin{proposition}
  Let \(\mathcal{R}\) satisify the weakening condition. Then the following inference rules are admissible in \Cattr.
  \begin{mathpar}
    \inferrule{\Gamma \vdash B}{\Gamma, (x : A) \vdash \wk(A)} \and
    \inferrule{\Gamma \vdash s : B}{\Gamma, (x : A) \vdash \wk(s) : \wk(B)} \and
    \inferrule{\Gamma \vdash \sigma : \Delta}{\Gamma, (x : A) \vdash \wk(\sigma) : \Delta}
  \end{mathpar}
  for types \(A,B : \Type_\Gamma\), term \(s : \Term_\Gamma\) and substitution \(\sigma : \arr \Delta C \Gamma\).
\end{proposition}

\begin{corollary}
  \label{cor:id-sub-ty}
  If \(\mathcal{R}\) satisfies the weakening condition then:
  \[ \Gamma \vdash \id_\Gamma : \Gamma \]
  for any \(\Gamma : \Ctx\).
\end{corollary}

Using only the above proposition we can immediately prove typing properties for several constructions using discs.

\begin{lemma}
  \label{lem:disc-typing}
  Suppose the weakening condition holds. Then the following judgements hold:
  \[ S^n \vdash U^n \qquad S^n \vdash \qquad D^n \vdash \]
  For all \(n \in \mathbb{N}\). Further, the following inference rules are admissible:
  \begin{mathpar}
    \inferrule{\Gamma \vdash A \\ n = \dim(A)} {\Gamma \vdash \{A\} : S^n} \and
    \inferrule{\Gamma \vdash A \\ n = \dim(A) \\ \Gamma \vdash s : A} { \Gamma \vdash \{A,s\} : D^n} \\
    \inferrule{\Gamma \vdash \{A\} : S^n}{\Gamma \vdash A} \and
    \inferrule{\Gamma \vdash \{A,s\} : D^n}{\Gamma \vdash A} \and
    \inferrule{\Gamma \vdash \{A,s\} : D^n}{\Gamma \vdash s : A}
  \end{mathpar}
  For \(A : \Type_\Gamma\) and \(s : \Term_\Gamma\).
\end{lemma}
\begin{proof}
  The first three typing judgements follow from a simple mutual induction, making use of the typing of weakening. We prove that \(\Gamma \vdash \{A\} : S^n\) by induction on \(n\) and \(A\). The base case is trivial. For the inductive step we assume that \(\Gamma \vdash \arr s A t\), with \(n = \dim(A)\), and want to show that:
  \[ \Gamma \vdash \langle \{A\},s ,t \rangle : S^n, (d_{n+1}^- : U^n), (d_{n+1}^+ : \wk(U^n)) \]
  The judgement \(\Gamma \vdash \{A\} : S^n\) holds by inductive hypothesis, and so it remains to show that the following two judgements hold:
  \[ \Gamma \vdash s : U^n \sub {\{A\}} \qquad \Gamma \vdash t : \wk(U^n)\sub{\langle\{A\}, s\rangle} \]
  As \(\Gamma \vdash \arr s A t\), we know (by case analysis on the typing derivation) that \(\Gamma \vdash s : A\) and \(\Gamma \vdash t : A\). These judgements are sufficient to finish the proof, since \(A \equiv U^n \sub {\{A\}} \equiv \wk(U^n) \sub {\langle \{A\}, s \rangle}\) by \cref{item:disc-prop-sub-from} and the interaction of weakening with substitution application.

  To show that \(\Gamma \vdash A\) follows from \(\Gamma \vdash \{A\} : S^n\), we instead show that \(\Gamma \vdash U^n \sub {\{A\}}\), leveraging that typing is invariant under syntactic equality. The typing of \(U^n \sub {\{A\}}\) follows from \(U^n\) being well-formed in \Catt (as it is well-formed in any theory with the weakening property), and \cref{lem:sub-catt}. The second to last inference rule follows trivially from the preceding one. For the last rule, we get that \(\Gamma \vdash s : U^n\sub{\{A\}}\) by case analysis on \(\Gamma \vdash \{A,s\} : D^n\), and so we are finished by the invariance of typing rules under syntactic equality.
\end{proof}

If we further have that the set of operations includes the standard operations then we get the following corollary.

\begin{corollary}
  \label{cor:id-typing}
  Suppose that \(\mathcal{O}\) contains the standard operations in addition to \(\mathcal{R}\) satisfying the weakening condition. Then the following are equivalent:
  \begin{itemize}
  \item \(\Gamma \vdash A\) and \(\Gamma \vdash s : A\),
  \item There exists some \(B: \Type_\Gamma\) such that \(\Gamma \vdash \id(A,t) : B\),
  \item \(\Gamma \vdash \id(A,t) : \arr t A t\).
  \end{itemize}
  If we further have that \(\dim(A) \neq 0\) then the following two conditions are also equivalent:
  \begin{itemize}
  \item There exists some \(B: \Type_\Gamma\) such that \(\Gamma \vdash \Coh {D^n} {\wk(U^n)} {\{A,t\}} : B\),
  \item \(\Gamma \vdash \Coh{D^n} {\wk(U^n)} {\{A,t\}} : A\).
  \end{itemize}
  where \(n = \dim(A)\).
\end{corollary}
\begin{proof}
  The proof follows from \cref{lem:disc-typing,item:disc-prop-sub-from,cor:disc-op}.
\end{proof}

We end this section with the following \lcnamecref{prop:dr-weak}.

\begin{proposition}
  \label{prop:dr-weak}
  The set \dr satisfies the weakening condition.
\end{proposition}
\begin{proof}
  It suffices to show that for all \(\Gamma : \Ctx\), \(A, B : \Type_\Gamma\), and \(t : \Term_\Gamma\) that:
  \[ ((\Gamma, (x : B)), \Coh {D^n} {\wk(U^n)} {\wk(\{A,t\})}, \wk(t)) \in \dr \]
  when \(n = \dim(A)\). By \cref{item:disc-prop-wk}, \(\wk(\{A,t\}) \equiv \{ \wk(A), \wk(t)\}\) and so the triple above is clearly contained in \dr.
\end{proof}

The semistrict type theories \Cattsu and \Cattsua (which will be introduced in \cref{sec:cattsu,sec:cattsua}) will be generated by equality rule sets that are the union of multiple smaller rulesets (including disc removal). Since the weakening condition is clearly preserved under unions, we will be able to show that the rule sets generating \Cattsu and \Cattsua satisfy the weakening condition by showing that it is satisfied by each individual component.

\paragraph{Suspension condition}

For suspension, we introduce the following condition, which is similar to the corresponding condition for weakening.

\begin{definition}
  A set of equality rules \(\mathcal{R}\) satisfies the \emph{suspension condition} if
  \[ (\Sigma(\Gamma), \Sigma(s), \Sigma(t)) \in \mathcal{R} \]
  for all \((\Gamma,s,t) \in \mathcal{R}\).
\end{definition}

If the set of operations \(\mathcal{O}\) is suspendable, then this condition is sufficient to show that the suspension of a well-formed piece of syntax is well-formed.

\begin{proposition}
  Suppose \(\mathcal{O}\) is suspendable and \(\mathcal{R}\) satisfies the suspension condition. Then the following inference rules are admissible for \(\Gamma, \Delta, \Delta' : \Ctx\), \(A,B,C,D : \Type_\Gamma\), \(s,t : \Term_\Gamma\), \(\sigma : \arr \Delta C \Gamma\), and \(\tau : \arr {\Delta'} D \Gamma\).
  \begin{mathpar}
    \inferrule{\Gamma \vdash}{\Sigma(\Gamma) \vdash}\and
    \inferrule{\Gamma \vdash A}{\Sigma(\Gamma) \vdash \Sigma(A)}\and
    \inferrule{\Gamma \vdash s : A}{\Sigma(\Gamma) \vdash \Sigma(s) : \Sigma(A)}\and
    \inferrule{\Gamma \vdash \sigma : \Delta}{\Sigma(\Gamma) \vdash \Sigma'(\sigma) : \Delta}\\
    \inferrule{\Gamma \vdash A = B}{\Sigma(\Gamma) \vdash \Sigma(A) = \Sigma(B)}\and
    \inferrule{\Gamma \vdash s = t}{\Sigma(\Gamma) \vdash \Sigma(s) = \Sigma(t)}\and
    \inferrule{\Gamma \vdash \sigma = \tau}{\Sigma'(\Gamma) \vdash \Sigma'(\sigma) = \Sigma(\tau)}
  \end{mathpar}
  For all \(\mu : \arr \Delta {\arr s A t} \Gamma\) and \(\mu' : \arr {\Delta'} {\arr {s'} {A'} {t'}} {\Gamma'}\) the following two rules are admissible:
  \begin{mathpar}
    \inferrule{\Gamma \vdash \mu : \Delta}{\Gamma \vdash \unrestrict \mu : \Sigma(\Delta)} \and
    \inferrule{\Gamma \vdash \mu = \mu'}{\Gamma \vdash \unrestrict \mu = \unrestrict \mu'}
  \end{mathpar}
  and so the inference rules
  \begin{mathpar}
    \inferrule{\Gamma \vdash \sigma : \Delta}{\Sigma(\Gamma) \vdash \Sigma(\sigma) : \Sigma(\Delta)} \and
    \inferrule{\Gamma \vdash \sigma = \tau} {\Sigma(\Gamma) \vdash \Sigma(\sigma) = \Sigma(\tau)}
  \end{mathpar}
  hold for \(\sigma : \arr \Delta \star \Gamma\) and \(\tau : \arr {\Delta'} \star \Gamma\).
\end{proposition}
\begin{proof}
  The rules concerning the unrestriction operation follow by simple induction on the typing judgement or equality in the premise, and in fact do not need the suspension condition.

  The remainder of the rules follow from a routine mutual induction on all typing and equality rules, which can be found in \module{Catt.Suspension.Typing}. The suspension condition and the suspendability of the operation set are used for the case involving the typing rule for coherences, which also makes use of \cref{lem:susp-vs-prop}. In this case, the functoriality of suspension is used to show that the coherence has the correct type.
\end{proof}

Similarly to the weakening condition, the suspension condition is closed under unions of rule sets, and we can show it is satisfied by \dr, with a similar proof to the proof for weakening.

\begin{proposition}
  \label{prop:dr-susp}
  The set \dr satisfies the suspension condition.
\end{proposition}
\begin{proof}
  It is sufficient to prove that for all \(\Gamma : \Ctx\), \(A : \Type_\Gamma\), and \(t : \Term_\Gamma\) that:
  \[(\Sigma(\Gamma), \Coh {\Sigma(D^n)} {\Sigma(\wk(U^n))} {\Sigma(\{A,t\})}, \Sigma(t)) \in \dr\]
  when \(n = \dim(A)\). By \cref{item:disc-prop-susp}, we get that \(\Sigma(D^n) \equiv D^{n+1}\) and \(\Sigma(\wk(U^n)) \equiv \wk(\Sigma(U^n) \equiv \wk(U^{n+1})\). By \cref{item:disc-prop-sub-susp}, \(\Sigma(\{A,t\}) \equiv \{\Sigma(A),\Sigma(t)\}\). Therefore, it is sufficient to show that:
  \[(\Sigma(\Gamma), \Coh {D^{n+1}} {\wk(U^{n+1})} {\{\Sigma(A),\Sigma(t)\}}, \Sigma(t)) \in \dr\]
  which is clear as \(\dim(\Sigma(A)) = \dim(A) + 1 = n+1\).
\end{proof}

\paragraph{Substitution condition}

The substitution condition takes a slightly different form to the previous two conditions. Instead of requiring that the rule set is closed under application of any arbitrary substitution \(\sigma\), we instead only ensure it is closed under well-formed substitutions. This will not prevent us proving that typing is closed under the application of substitutions, but will be critical in proving that the supported rules construction, which will be given in \cref{def:rule-with-supp} and is used for proving the support condition, satisfies the substitution condition.

\begin{definition}
  An equality rule set \(\mathcal{R}\) satisfies the \emph{\(\mathcal{R}'\)-substitution condition} if:
  \[ (\Gamma, s \sub \sigma, t\sub \sigma) \in \mathcal{R} \]
  whenever \((\Delta, s, t) \in \mathcal{R}\) and \(\sigma : \arr \Delta \star \Gamma\) with \(\Gamma \vdash_{\mathcal{R}'} \sigma : \Delta\). We say the set \(\mathcal{R}\) satisfies the \emph{substitution condition} if it satisfies the \(\mathcal{R}\)-substitution condition.
\end{definition}

We make two comments about this definition:
\begin{itemize}
\item We only close under substitutions with type part \(\star\). It will still be possible that typing is preserved by arbitrary (well-formed) substitutions when combined with the suspension condition.
\item We introduce a second rule set \(\mathcal{R}'\) in the definition, which is only used for the typing premise of the substitution \(\sigma\). The reason for this is that the substitution condition is not closed under unions, and so we will instead prove that certain rule sets satisfy the \(\mathcal{R}'\)-substitution condition for an arbitrary \(\mathcal{R}'\), which is closed under unions.
\end{itemize}
The substitution condition allows us to give the next proposition.

\begin{proposition}
  \label{prop:sub-prop-1}
  Suppose \(\mathcal{R}\) satisfies the substitution condition. For any \(\sigma : \arr \Delta \star \Gamma\), the following rules are admissible:
  \begin{mathpar}
    \inferrule{\Delta \vdash A \\ \Gamma \vdash \sigma : \Delta}{\Gamma \vdash A \sub \sigma}\and
    \inferrule{\Delta \vdash s : A \\ \Gamma \vdash \sigma : \Delta}{\Gamma \vdash s \sub \sigma : A \sub \sigma}\and
    \inferrule{\Delta \vdash \tau : \Theta \\ \Gamma \vdash \sigma : \Delta}{\Gamma \vdash \tau \bullet \sigma : \Theta}\\
    \inferrule{\Delta \vdash A = B\\ \Gamma \vdash \sigma : \Delta}{\Gamma \vdash A \sub \sigma = B \sub \sigma}\and
    \inferrule{\Delta \vdash s = t \\ \Gamma \vdash \sigma : \Delta}{\Gamma \vdash s \sub \sigma = t \sub \sigma}\and
    \inferrule{\Delta \vdash \tau = \mu \\ \Gamma \vdash \sigma : \Delta}{\Gamma \vdash \tau \bullet \sigma = \mu \bullet \sigma}
  \end{mathpar}
  If \(\mathcal{R}\) additionally satisfies the suspension conditions, then all the above rules are admissible for any substitution \(\sigma : \arr \Delta B \Gamma\).
\end{proposition}
\begin{proof}
  The proof for a non-extended substitution is given by another routine mutual induction in \module{Catt.Typing.Properties.Substitution}. For an arbitrary substitution \(\sigma : \arr \Delta B \Gamma\), we also proceed by mutual induction, but for the application of the substitution to an equality of terms \(s\) and \(t\) we further split on \(B\). If \(B = \star\), then the proof for non-extended substitutions can be used. Otherwise, we have:
  \begin{align*}
    s \sub \sigma &\equiv \Sigma s \sub {\unrestrict \sigma}\\
                  &= \Sigma t \sub {\unrestrict \sigma}\\
                  &\equiv t \sub \sigma
  \end{align*}
  with the non-syntactic equality following from the preservation of equality by suspension and inductive hypothesis. These proofs that the extended versions of these rules are admissible is found in \module{Catt.Typing.Properties.Substitution.Suspended}.
\end{proof}

We also prove that application of substitution respects equality in its second argument, which does in fact not need to substitution condition. This is also proved by a simple mutual induction in \module{Catt.Typing.Properties.Substitution}.

\begin{proposition}
  \label{prop:sub-prop-2}
  The following inference rules are admissible:
  \begin{mathpar}
    \inferrule{\Gamma \vdash \sigma = \tau}{\Gamma \vdash s \sub \sigma = s \sub \tau}\and
    \inferrule{\Gamma \vdash \sigma = \tau}{\Gamma \vdash A \sub \sigma = A \sub \tau}\and
    \inferrule{\Gamma \vdash \sigma = \tau}{\Gamma \vdash \mu \bullet \sigma = \mu \bullet \tau}
  \end{mathpar}
  for substitutions \(\sigma : \arr \Delta A \Gamma\), \(\tau : \arr \Delta B \Gamma\), and \(\mu : \arr \Theta C \Delta\), term \(s : \Term_\Delta\), and type \(A : \Type_\Delta\).
\end{proposition}

This allows us to finally define a category of well-formed syntax in \Cattr. which is well defined by the two preceding definitions.

\begin{definition}
  Suppose \(\mathcal{R}\) satisfies the substitution and weakening conditions. Then we can define the \emph{syntactic category} of \Cattr, which by an abuse of notation we also call \Cattr, to have:
  \begin{itemize}
  \item Objects given by contexts \(\Gamma\) where \(\Gamma \vdash\).
  \item Morphisms \(\Delta \to \Gamma\) given by substitutions \(\sigma : \arr \Delta \star \Gamma\) where \(\Gamma \vdash \sigma : \Delta\) quotiented by the relation which equates substitutions \(\sigma\) and \(\tau\) when \(\Gamma \vdash \sigma = \tau\).
  \item The identity morphism \(\Gamma \to \Gamma\) given by \(\id_\Gamma\).
  \item Composition is given by \(\tau \circ \sigma = \sigma \bullet \tau\).
  \end{itemize}
  By \cref{cor:id-sub-ty}, the identity substitution is a well-defined morphism, and the above two propositions prove that compostition is well defined., Composition satisfies associativity and unitality by \cref{prop:categorical}.
\end{definition}

By taking the weakening of the identity substitution \(\id_\Gamma : \Gamma \to \Gamma\) we get a substitution:
\[ \proj_{\Gamma} = \wk(\id_\Gamma) : \Gamma \to \Gamma, (x : A)\]
which includes \(\Gamma\) into \(\Gamma, x : A\). It can be checked (and is given by \func{Catt.Syntax.Properties}{apply-project-is-wk-tm} in the formalisation) that applying this substitution to a term is the same operation as weakening the term. Using this, the following can be proved:

\begin{lemma}
  Suppose \(\mathcal{R}\) satisfies the substitution condition. Then it also satisfies the weakening condition.
\end{lemma}
\begin{proof}
  For \((\Gamma,s ,t) \in \mathcal{R}\) and \(A : \Type_\Gamma\), we must prove that:
  \[ ((\Gamma,(x:A)),\wk(s),\wk(t)) \equiv ((\Gamma, (x : A)), s \sub {\proj_{\Gamma}}, t \sub {\proj_{\Gamma}}) \in \mathcal{R} \]
  which will follow from the substitution condition if it can be proved that
  \[ \Gamma, x : A \vdash_{\mathcal{R}} \proj_\Gamma : \Gamma \]
  holds. This judgement is easy to derive when \(\mathcal{R}\) satisfies the weakening condition, but this is what we are trying to prove. Instead, since \(\emptyset\) trivially satisfies the weakening condition, \(\proj_\Gamma\) is well-formed in \Catt, and so the derivation above follows from \cref{cor:catt-to-r}.
\end{proof}

We lastly show that \dr also satisfies the substitution condition.

\begin{proposition}
  \label{prop:dr-sub}
  The set \dr satisfies the \(\mathcal{R}\)-substitution condition for any equality set \(\mathcal{R}\).
\end{proposition}
\begin{proof}
  The proof is similar to \cref{prop:dr-weak,prop:dr-susp}, and follows from the equality \(\{A,t\} \bullet \sigma \equiv \{A \sub \sigma, t \sub \sigma\}\) which holds by \cref{item:disc-prop-sub-sub} .
\end{proof}

\begin{remark}
  The proof of the substitution condition for \dr makes no use of the typing of \(\sigma\). In fact this premise is only necessary for the supported rules construction which will be given in \cref{def:rule-with-supp}
\end{remark}

\paragraph{Tameness}

We can finally define tameness.

\begin{definition}
  An equality rule set \(\mathcal{R}\) is tame if it satisfies the weakening, substitution, and suspension conditions. An operation set \(\mathcal{O}\) is tame if it is suspendable and contains the standard operations. A theory generated by \(\mathcal{R}\) and \(\mathcal{O}\) is tame if both \(\mathcal{R}\) and \(\mathcal{O}\) are.
\end{definition}

\begin{proposition}
  The set \dr is tame.
\end{proposition}

In the formalisation, each module is parameterised by the various conditions that the module needs, and where possible we avoid using extra unnecessary conditions. Given that every theory we will consider in this thesis is tame, and that it is hard to imagine a sensible theory that isn't tame, the argument could be made that the effort put into making distinctions between these conditions is wasted or at least unnecessary.

The case for including the weakening condition is especially unconvincing as it is implied by the substitution condition which likely holds in any theory of significant interest. It is however included here as it is used in the formalisation, where its introduction is an artefact of the natural progression of this research.

To this end, from \cref{sec:operations-catt}, we will assume that the theory we are working over is tame, and build a library of constructions and results that work in any tame theory, even when some of the results may not need all the conditions above.

Since we have limited use for proving properties about theories that do not satisfy the substitution condition, we could have instead enforced that all theories respect substitution by adding a constructor to the (term) equality relation that takes an equality \(\Delta \vdash s = t\) and typing relation \(\Gamma \vdash \sigma : \Delta\) to an equality \(\Gamma \vdash s \sub \sigma = t \sub \sigma\). This may remove some overhead of setting up the weakening and substitution conditions. It would also allow more minimal equality rule sets to be given, as a rule set such as disc removal could be given by
\[ \{(D^n, \Coh {D^n} {\wk(U^n)} {\id_{D^n}}, d_n) \mid n \in \mathbb{N}\} \]
On the other hand, including the extra constructor would effectively add an extra case to each inductive proof, and it is less clear how to minimise some of the equality rules that will be introduced in \cref{sec:operations-catt}. Taking either approach would likely lead to a similar development of the theory.

\subsection{Further conditions}
\label{sec:further-conditions}

Knowing that the theory we are working in is tame will be sufficient for giving most of the constructions and proofs in \cref{sec:operations-catt}. Here we introduce some extra conditions that instead serve to aid in the proof of metatheoretic properties of the generated theory. These conditions take the form of predicates on each rule in the equality rule sets, rather than being closure properties as the conditions for tameness were.

\paragraph{Support condition}

The support of a term plays a central role in classifying the operations of the theory (see \cref{sec:support}). Although it is known that support is respected by syntactic equality, we have not yet shown it is preserved by definitional equality. The following condition allows this to be proved.

\begin{definition}
  A set \(\mathcal{R}\) satisfies the \emph{\(\mathcal{R}'\)-support condition} for an equality set \(\mathcal{R}'\) when:
  \[ \Gamma \vdash_{\mathcal{R}'} s : A \implies \Supp(s) = \Supp(t) \]
  for each \((\Gamma,s,t) \in \mathcal{R}\) and \(A : \Type_\Gamma\). A set \(\mathcal{R}\) satisfies the \emph{support condition} if it satisfies the \(\mathcal{R}\)-support condition.
\end{definition}

The use of support instead of free variables in this definition is critical, as we do not expect the free variables of a piece of syntax to be preserved by equality in general. As an example, we would like to have the equality:
\[ D^1 \vdash \Coh {D^1} {U^1} {\id_{D^1}} = d_1 \]
given by disc removal, yet the free variables of each side are not equal (though the support of each side is).

We also draw attention to typing premise. Without this, the left hand side of each equality rule is too unconstrained (at least with how the equality rules are currently presented), and this condition would fail to hold on the equality sets we introduce in this thesis. Having this typing premise come from a separate rule set \(\mathcal{R}'\) allows the support condition to be preserved by unions of equality sets, similar to the substitution condition.

From the support condition, we immediately get the following proposition, proved by mutual induction.

\begin{proposition}
  \label{prop:supp-prop}
  Let \(\mathcal{R}\) satisfy the support condition. Then the following rules are admissible:
  \begin{mathpar}
    \inferrule{\Gamma \vdash s = t}{\Supp(s) = \Supp(t)}\and
    \inferrule{\Gamma \vdash A = B}{\Supp(A) = \Supp(B)}\and
    \inferrule{\Gamma \vdash \sigma = \tau}{\Supp(\sigma) = \Supp(\tau)}
  \end{mathpar}
  For \(s,t: \Term_\Gamma\), \(A,B : \Type_\Gamma\) and substitutions \(\sigma : \arr \Delta A \Gamma\) and \(\tau : \arr \Theta B \Gamma\).
\end{proposition}

In traditional presentations of \Catt, \(\FV(t) \cup \FV(A)\) is used instead of \(\Supp(t)\) for a term \(t\) of type \(A\). Equipped with the support condition we can now show that these are the same.

\begin{lemma}
  The following hold when \(\mathcal{R}\) satisfies the support condition:
  \begin{lemmaenum}
  \item \(\Supp(A) = \FV(A)\) when \(\Gamma \vdash A\),
  \item \label{item:supp-sub-char} \(\Supp(\sigma) = \FV(\sigma)\) when \(\Gamma \vdash \sigma : \Delta\),
  \item \label{item:supp-tm-char-1} \(\Supp(t) = \Supp(A) \cup \FV(t)\) when \(\Gamma \vdash t : A\),
  \item \label{item:supp-tm-char-2} \(\Supp(t) = \FV(A) \cup \FV(t) = \Supp(A) \cup \Supp(t)\) when \(\Gamma \vdash t : A\) and \(\Gamma \vdash A\).
  \end{lemmaenum}
\end{lemma}
\begin{proof}
  All properties are proven by a single mutual induction on the typing derivations in the premises.
  \begin{enumerate}[(i)]
  \item Suppose \(\Gamma \vdash A\). If \(A \equiv \star\) then \(\Supp(A) = \FV(A) = \emptyset\). Instead suppose \(A \equiv \arr s B t\). Then we have that \(\Gamma \vdash B\), \(\Gamma \vdash s : B\), and \(\Gamma \vdash t : B\) and so:
    \begin{align*}
      \Supp(A) &= \Supp(B) \cup \Supp(s) \cup \Supp(t)\\
               &= \FV(B) \cup (\FV(B) \cup \FV(s)) \cup (\FV(B) \cup \FV(t))&(*)\\
               &= \FV(B) \cup \FV(s) \cup \FV(t)\\
               &= \FV(A)
    \end{align*}
    where the equality \((*)\) is derived from the inductive hypothesis for (i) applied to \(B\) and the inductive hypothesis for (iv) applied to \(s\) and \(t\).
  \item Suppose \(\Gamma \vdash \sigma : \Delta\). If \(\sigma \equiv \langle A \rangle\) then \(\Gamma \vdash A\) and so:
    \[\Supp(\sigma) = \Supp(A) = \FV(A) = \FV(\sigma)\]
    If instead \(\sigma \equiv \langle \tau, t \rangle\) and \(\Delta = \Theta, (x : A)\) then \(\Gamma \vdash \tau : \Theta\) and \(\Gamma \vdash t : A \sub \tau\) and so:
    \begin{align*}
      \Supp(\sigma) &= \Supp(\tau) \cup \Supp(t)\\
                    &= \Supp(\tau) \cup (\Supp(A \sub \tau) \cup \FV(t))&(*)\\
                    &= \DC_\Gamma(\FV(\tau) \cup \FV(A \sub \tau)) \cup \FV(t)\\
                    &= \Supp(\tau) \cup \FV(t)&\text{as }\FV(A \sub \tau) \subseteq \FV(\tau)\\
                    &= \FV(\tau) \cup \FV(t)&(\dagger)\\
                    &= \FV(\sigma)
    \end{align*}
    where the equality \((*)\) is derived from the inductive hypothesis for (iii) applied to \(t\) and the equality \((\dagger)\) is derived from the inductive hypothesis for (ii) applied to \(\tau\).
  \item Suppose \(\Gamma \vdash t : A\). We then split on the constructor used for the typing derivation:

    If the derivation is the result of a conversion rule applied to \(\Gamma \vdash t : B\) and \(\Gamma \vdash A = B\), then inductive hypothesis gives \(\Supp(t) = \Supp(B) \cup \FV(t)\) and \cref{prop:supp-prop} gives \(\Supp(A) = \Supp(B)\) and so \(\Supp(t) = \Supp(A) \cup \FV(t)\) as required.

    If the derivation is derived from the typing rule for variables, then a simple induction on the context \(\Gamma\), using that \(\Supp(\wk(A)) = \Supp(A)\), gives the required result.

    If the derivation is given by the typing rule for coherences then \(t \equiv \Coh \Delta B \sigma\), \(\Gamma \vdash \sigma : \Delta\), and \(A \equiv B \sub \sigma\) . Therefore,
    \begin{align*}
      \Supp(t) &= \Supp(\sigma)\\
               &= \DC_\Gamma(\FV(B \sub \sigma) \cup \FV(\sigma))&\text{as }\FV(B \sub \sigma) \subseteq \FV(\sigma)\\
               &= \Supp(A) \cup \Supp(\sigma)\\
               &= \Supp(A) \cup \FV(\sigma)&(*)\\
               &= \Supp(A) \cup \FV(t)
    \end{align*}
    where the equality \((*)\) is the result of applying the inductive hypothesis for (ii) to \(\sigma\).
  \item If \(\Gamma \vdash t : A\) and \(\Gamma \vdash A\) then:
    \[ \Supp(t) = \Supp(A) \cup \FV(t) = \FV(A) \cup \FV(t) \]
    trivially follows from (i) and (iii) and:
    \[ \Supp(t) = \DC_\Gamma(\Supp(t)) = \DC_\Gamma(\FV(A) \cup \FV(t)) = \Supp(A) \cup \Supp(t) \]
    with the first equality resulting from the idempotency of the downwards closure operator.
  \end{enumerate}
  This proof is formalised in \module{Catt.Typing.Properties.Support}.
\end{proof}
\begin{corollary}
  \label{cor:dc-sub}
  Let \(\mathcal{R}\) satisfy the support condition and suppose \(\Gamma \vdash \sigma : \Delta\). Then the following equality holds:
  \[ \DC_\Gamma(V \sub \sigma) = \DC_\Delta(V) \sub \sigma \]
  for all \(V \subseteq \Var(\Delta)\); downwards closure commutes with the application of \(\sigma\) to variable sets.
\end{corollary}
\begin{proof}
  Proceed by induction on \(\Delta\). If \(\Delta \equiv \emptyset\) then the equation is trivial. Therefore assume \(\Delta \equiv \Theta, (x : A)\) and so \(\sigma \equiv \langle \tau , t \rangle\) with \(\Gamma \vdash \tau : \Theta\) and \(\Gamma \vdash t : A \sub \tau\) by case analysis. We now split on whether \(x \in V\).

  If \(x \not\in V\) then \(\DC_\Gamma(V \sub \sigma) = \DC_\Gamma(V \sub \tau) = \DC_\Theta(V) \sub \tau = \DC_\Delta(V) \sub \tau\) with the second equality due to inductive hypothesis. Otherwise \(x \in V\) and so letting \(U = V \setminus \{x\}\) we get the equality:
  \begin{align*}
    \DC_\Gamma(V \sub \sigma) &= \DC_\Gamma(U \sub \tau \cup \FV(t))\\
                              &= \DC_\Gamma(U \sub \tau) \cup \Supp(t)\\
                              &= \DC_\Gamma(U \sub \tau) \cup \Supp(A \sub \tau) \cup \FV(t)&(\dagger)\\
                              &= \DC_\Gamma(U \sub \tau) \cup \DC_\Gamma(\FV(A) \sub \tau) \cup \FV(t) \\
                              &= \DC_\Gamma(U \sub \tau \cup \FV(A) \sub \tau)  \cup \FV(t)\\
                              &= \DC_\Gamma((U \cup \FV(A)) \sub \tau) \cup \FV(t)\\
                              &= \DC_\Theta(U \cup \FV(A)) \sub \tau \cup \FV(t)&(*)\\
                              &= (\{x\} \cup \DC_\Theta(U \cup \FV(A))) \sub \sigma \\
                              &= \DC_\Delta(V) \sub \sigma
  \end{align*}
  where equality \((*)\) is by inductive hypothesis and equality \((\dagger)\) is by \cref{item:supp-tm-char-1}.
\end{proof}

Unfortunately, proving that the support condition holds for most equality rule sets is not as trivial as the proofs for the tameness properties. Consider the case for disc removal, which gives rise to the equality
\[ \Gamma \vdash \Coh {D^n} {\wk(U^n)} {\{A,t\}} = t \]
To prove the support condition for this case we need to show that:
\[ \Supp(\{A,t\}) = t \]
where we can assume that \(\Gamma \vdash t : A\). Intuitively this should hold, as the support of a substitution should be equal to the support of the locally maximal arguments, and if the derivation \(\Gamma \vdash t : A\) held in \Catt, we would be able to prove this. However, this proof (and intuition) relies on the derivation \(\Gamma \vdash_{\mathcal{R}} t : A\) holding in a theory generated by \(\mathcal{R}\) where \(\mathcal{R}\) already satisfies the support condition, without which the typing derivation offers little utility.

We therefore introduce a proof strategy for showing that the support condition holds. The key insight of this strategy is to prove by induction that every equality and every typing derivation in the system is well-behaved with respect to support. Then, for the case of an equality \(\Gamma \vdash s = t\) arising from a rule \((\Gamma, s, t)\), we have \(\Gamma \vdash s : A\) as a premise and so by inductive hypothesis can assume that this typing derivation is well behaved with respect to support.

We formalise this with the following definition, called the \emph{supported rules} construction:
\begin{definition}
  \label{def:rule-with-supp}
  Let \(\mathcal{R}\) be some equality rule set. The \emph{supported rules} construction applied to \(\mathcal{R}\) produces the equality rule set \(\mathcal{R}_{\mathsf{S}}\), given by:
  \[ \mathcal{R}_{\mathsf{S}} = \{ (\Gamma, s, t) \in \mathcal{R} \mid \Supp(s) = \Supp(t)\} \]
  The rule set \(\mathcal{R}_{\mathsf{S}}\) satisfies the support condition by construction.
\end{definition}

The proof strategy then proceeds as follows: to prove that \(\mathcal{R}\) satisfies the support condition, we instead prove that \(\mathcal{R}\) satisfies the \(\mathcal{R}_{\mathsf{S}}\)-support condition, leveraging that \(\mathcal{R}_\mathsf{S}\) itself satisfies the support condition. The proof is then completed by the following lemma:
\begin{lemma}
  \label{lem:proof-strat-supp}
  Let \(\mathcal{R}\) be an equality rule set that satisfies the \(\mathcal{R}_{\mathsf{S}}\)-support condition. Then the following inference rules are admissible:
  \begin{mathpar}
    \inferrule{\Gamma \vdash_\mathcal{R} A}{\Gamma \vdash_{\mathcal{R}_\mathsf{S}} A}\and
    \inferrule{\Gamma \vdash_\mathcal{R} s : A}{\Gamma \vdash_{\mathcal{R}_\mathsf{S}} s : A}\and
    \inferrule{\Gamma \vdash_\mathcal{R} \sigma : \Delta}{\Gamma \vdash_{\mathcal{R}_\mathsf{S}} \sigma : \Delta}\and
    \inferrule{\Gamma \vdash_\mathcal{R} A = B}{\Gamma \vdash_{\mathcal{R}_\mathsf{S}} A = B}\and
    \inferrule{\Gamma \vdash_\mathcal{R} s = t}{\Gamma \vdash_{\mathcal{R}_\mathsf{S}} s = t}\and
    \inferrule{\Gamma \vdash_\mathcal{R} \sigma = \tau}{\Gamma \vdash_{\mathcal{R}_\mathsf{S}} \sigma = \tau}
  \end{mathpar}
  and hence \(\mathcal{R}\) satisfies the support condition.
\end{lemma}
\begin{proof}
  The inference rules are all proven using a mutual induction on all typing and equality rules, using that \(\mathcal{R}\) satisfies the \(\mathcal{R}_\mathsf{S}\)-support condition in the case where the equality \(\Gamma \vdash s = t\) is derived from a rule \((\Gamma, s, t) \in \mathcal{R}\). This induction is formalised in \module{Catt.Support.Typing}.

  The set \(\mathcal{R}\) then satisfies the support condition as if \((\Gamma,s,t) \in \mathcal{R}\) and \(\Gamma \vdash_{\mathcal{R}} s : A\), then \(\Gamma \vdash_{\mathcal{R}_{\mathsf{S}}} s : A\) holds by the first part of the lemma and so \(\Supp(s) = \Supp(t)\) as \(\mathcal{R}\) is already known to satisfy the \(\mathcal{R}_{\mathsf{S}}\)-support condition.
\end{proof}

\begin{remark}
  The original motivation for parameterising \Catt by an arbitrary set of equality rules \(\mathcal{R}\) was not to share proofs between \Cattsu and \Cattsua but was to be able to state the supported rules construction.
\end{remark}

To be able to prove that \(\mathcal{R}\) satisfies the \(\mathcal{R}_{\mathsf{S}}\)-support condition, we will commonly need to know that \(\mathcal{R}_{\mathsf{S}}\) satisfies various tameness conditions, which are given by the next lemma.

\begin{lemma}
  \label{lem:supp-sat-conds}
  Let \(\mathcal{R}\) be any equality set. Then \(\mathcal{R}_{\mathsf{S}}\) satisfies the weakening, suspension, and substitution conditions if \(\mathcal{R}\) respects the corresponding condition.
\end{lemma}
\begin{proof}
  Let \((\Gamma, s, t) \in \mathcal{R}\) be an arbitrary rule. To show \(\mathcal{R}_{\mathsf{S}}\) satisfies the weakening condition we need to show that:
  \[ (\Gamma, s, t) \in \mathcal{R}_{\mathsf{S}} \implies ((\Gamma, (x : A)), \wk(s), \wk(t)) \in \mathcal{R}_{\mathsf{S}} \]
  By assumption, \((\Gamma, \wk(s), \wk(t)) \in \mathcal{R}\) and by the premise of the implication we have \(\Supp(s) = \Supp(t)\). From this it follows that \(\Supp(\wk(s)) = \Supp(\wk(t))\) and so the conclusion of the implication holds.

  The case for suspension is similar except we need to use the equality:
  \[ \Supp(\Sigma(s)) = \Sigma(\Supp(s)) = \Sigma(\Supp(t)) = \Supp(\Sigma(t)) \]
  derived from \cref{lem:susp-vs-prop} and \(\Supp(s) = \Supp(t)\) from the premise of the implication.

  For the substitution condition we need to show that:
  \[ \Supp(s) = \Supp(t) \implies \Supp(s \sub \sigma) = \Supp(t \sub \sigma) \]
  under the assumption that \(\Delta \vdash_{\mathcal{R}_\mathsf{S}} \sigma : \Gamma\). Since \(\mathcal{R}_\mathsf{S}\) satisfies the support rule, we can use \cref{cor:dc-sub} to get:
  \[ \Supp(s \sub \sigma) = \DC_\Gamma(\FV(s) \sub \sigma) = \Supp(s) \sub \sigma = \Supp(t) \sub \sigma = \DC_\Gamma(\FV(t) \sub \sigma) = \Supp(t \sub \sigma) \]
  as required.
\end{proof}

We now prove the appropriate support condition for disc removal.

\begin{proposition}
  \label{prop:dr-supp}
  Let \(\mathcal{R}\) satisfy the support and weakening conditions. Then the set \(\dr\) satisfies the \(\mathcal{R}\)-support condition.
\end{proposition}
\begin{proof}
  It is sufficient to prove that given \(s : \Term_\Gamma\), \(A : \Type_\Gamma\), and \(n = \dim(A)\) that:
  \[\Gamma \vdash_{\mathcal{R}} \Coh {D^n} {\wk(U^n)} {\{A,t\}} : B \implies \Supp(\{A,t\}) = \Supp(t) \]
  Assume the premise of the implication. Then \(\Gamma \vdash_{\mathcal{R}} \{A,t\} : D^n\) by case analysis on the typing derivation and so \(\Gamma \vdash_{\mathcal{R}} A\) and \(\Gamma \vdash_{\mathcal{R}} t : A\) by \cref{lem:disc-typing} as \(\mathcal{R}\) satisfies the weakening condition.

  By a simple induction, it can be shown that \(\Supp(\{A,t\}) = \Supp(A) \cup \Supp(t)\). By \cref{item:supp-tm-char-2} we have \(\Supp(t) = \Supp(A) \cup \Supp(t)\) as \(\mathcal{R}\) satisfies the support condition and so \(\Supp(\{A,t\}) = \Supp(t)\) as required.
\end{proof}

\paragraph{Preservation condition}

Our last allows us to prove preservation, the property that typing is preserved by equality.

\begin{definition}
  A set \(\mathcal{R}\) satisfies the \emph{\(\mathcal{R}'\)-preservation condition} for an equality set \(\mathcal{R}'\) when:
  \[ \Gamma \vdash_{\mathcal{R}'} s : A \implies \Gamma \vdash_{\mathcal{R}'} t : A \]
  for each \((\Gamma, s, t) \in \mathcal{R}\) and \(A : \Type_\Gamma\). The set \(\mathcal{R}\) satisfies the \emph{preservation condition} if it satisfies the \(\mathcal{R}\)-preservation condition.
\end{definition}

When a rule set \(\mathcal{R}\) has all the properties presented in this section, we are able to show preservation for the generated theory.

\begin{proposition}
  Let \(\mathcal{R}\) satisfy the support condition and preservation condition, as well as being tame. Then the following inference rules are admissible:
  \begin{mathpar}
    \inferrule{\Gamma \vdash A\\ \Gamma \vdash A = B}{\Gamma \vdash B}\and
    \inferrule{\Gamma \vdash s : A\\ \Gamma \vdash s = t \\ \Gamma \vdash A = B}{\Gamma \vdash t : B}\and
    \inferrule{\Gamma \vdash \sigma : \Delta\\ \Gamma \vdash \sigma = \tau}{\Gamma \vdash \tau : \Delta}
  \end{mathpar}
  for \(A, B : \Type_\Gamma\), \(s,t : \Term_\Gamma\), \(\sigma : \arr \Delta A \Gamma\), and \(\tau : \arr \Delta B \Gamma\).
\end{proposition}
\begin{proof}
  We prove the following bidirectional versions of the inference rules by mutual induction on the equality derivation:
  \begin{alignat*}{5}
    &\Gamma \vdash A = B &&\implies (\Gamma \vdash A \iff \Gamma \vdash B)\\
    &\Gamma \vdash s = t &&\implies (\forall A.\ \Gamma \vdash s : A \iff \Gamma \vdash t : A)\\
    &\Gamma \vdash \sigma = \tau &&\implies (\Gamma \vdash \sigma : \Delta \iff \Gamma \vdash \tau : \Delta)
  \end{alignat*}
  which imply the inference rules of the proposition are admissible (using the conversion rule for the second rule).

  The only non trivial cases are for the statement for terms. We split on the equality derivation \(\Gamma \vdash s = t\). The cases for reflexivity on variables and transitivity are also trivial. The case for symmetry follows from the symmetry of the ``if and only if'' relation.

  Now suppose the equality is of the form \(\Coh \Delta A \sigma = \Coh \Delta B \tau\) and is derived from the equality rule for coherences from equalities \(\Delta \vdash A = B\) and \(\Gamma \vdash \sigma = \tau\). We prove the first direction, with the second following symmetrically. We therefore assume we have a typing derivation \(\Gamma \vdash \Coh \Delta A \sigma : C\), and will induct on this derivation to construction a derivation of \(\Gamma \vdash \Coh \Delta B \tau : C\).
  \begin{itemize}
  \item If the derivation is constructed with the conversion rule from \(\Gamma \vdash \Coh \Delta A \sigma : D\) and \(\Gamma \vdash D = C\), then we get a derivation \(\Gamma \vdash \Coh \Delta B \tau : D\) by inductive hypothesis and can apply the conversion rule to get a derivation \(\Gamma \vdash \Coh \Delta B \tau : C\).
  \item If instead the derivation is constructed with the coherence rule then \(C \equiv A \sub \sigma\) and  \(A \equiv \arr s {A'} t\) and therefore \(B \equiv \arr {u} {B'} {v}\) with \(\Delta \vdash s = u\) and \(\Delta \vdash t = v\). We also have that \(\Delta \vdash_{\mathsf{ps}}\), \((\Delta, \Supp(s), \Supp(t)) \in \mathcal{O}\), \(\Delta \vdash A\), and \(\Gamma \vdash \sigma : \Delta\). By the inductive hypothesis on the equality, we have \(\Delta \vdash B\) and \(\Gamma \vdash \tau : \Delta\). By \cref{prop:supp-prop}, \(\Supp(s) = \Supp(u)\) and \(\Supp(t) = \Supp(v)\) and so \((\Delta, \Supp(u), \Supp(v)) \in \mathcal{O}\). Hence by the coherence rule we have \(\Gamma \vdash \Coh \Delta B \tau : B \sub \tau\). By \cref{prop:sub-prop-1,prop:sub-prop-2}, \(\Gamma \vdash A \sub \sigma = B \sub \tau\) and so by the conversion rule we obtain a derivation \(\Gamma \vdash \Coh \Delta B \tau : C\).
  \end{itemize}

  Finally suppose the equality is derived from \textsc{rule}, such that \((\Gamma, s,t) \in \mathcal{R}\) and \(\Gamma \vdash s : A\). If \(\Gamma \vdash s : B\), then the preservation condition gives a derivation \(\Gamma \vdash t : B\). Conversely, if \(\Gamma \vdash t : B\), then we need to show that \(\Gamma \vdash A = B\). By applying the preservation condition to the derivation \(\Gamma \vdash s : A\), we get a derivation \(\Gamma \vdash t : A\). Then by \cref{lem:ty-unique}, we have \(\Gamma \vdash A = B\) and so the proof is complete by applying the conversion rule to the derivation \(\Gamma \vdash s : A\).
\end{proof}

As with the other conditions, we end this section by showing that \dr satisfies the preservation condition.

\begin{proposition}
  \label{prop:dr-preserve}
  Suppose \(\mathcal{R}\) satisfies the weakening condition, and the set of operations \(\mathcal{O}\) contains the standard operations. Then \dr satisfies the \(\mathcal{R}\)-preservation condition.
\end{proposition}
\begin{proof}
  Take \((\Gamma, \Coh {D^n} {\wk(U^n)} {\{A,t\}}, t) \in \dr\) and suppose \(\Gamma \vdash \Coh {D^n} {U^n} {\{A,t\}} : B\). Then by \cref{lem:ty-unique}:
  \[\Gamma \vdash B = \wk(U^n) \sub {\{A,t\}} \equiv A\]
  By \cref{lem:disc-typing}, \(\Gamma \vdash t : A\) and so by the conversion rule \(\Gamma \vdash t : B\) as required.
\end{proof}

\subsection{Endo-coherence removal}
\label{sec:ecr}

We conclude this chapter with a second example of a family of equality rules called \emph{endo-coherence removal}. As suggested by the name, these equalities simplify a class of terms known as a endo-coherences.

\begin{definition}
  An \emph{endo-coherence} is a coherence term \(\Coh \Delta {\arr s A s} \sigma\).
\end{definition}

If we consider the (ps-context):
\[ \Delta = (x : \star) (y : \star) (f : \arr x \star y) (z : \star) (g : \arr y \star z) \]
then we see that there are two distinct endo-coherences with source and target \(f * g\), the identity on \(f * g\) and the ``fake identity'' \(\Coh \Delta {f*g \to f*g} {\id_\Delta}\). In the type theories \Cattsu and \Cattsua introduced in \cref{sec:cattsu,sec:cattsua}, identities will be privileged, and these fake identities will be reduced to the true identity.

More generally, for each term \(t\) there is a canonical endo-coherence with source and target \(t\), the identity on \(t\). Endo-coherence removal simplifies any other endo-coherence on that term to an identity. It makes the following rule admissible:
\begin{mathpar}
  \inferrule{\Delta \vdash_{\mathsf{ps}} \\ \Delta \vdash A \\ \Delta \vdash s : A \\ \Supp(s) = \Var(\Delta) \\ \Gamma \vdash \sigma : \Delta}{\Gamma \vdash \Coh \Delta {\arr s A s} \sigma = \id(A \sub \sigma,s \sub \sigma)}\textsc{ecr}
\end{mathpar}
Endo-coherence removal can be assembled into the following equality rule set.

\begin{definition}
  The \emph{endo-coherence removal set}, \ecr, is the set consisting of the triples:
  \[ \Gamma, \Coh \Delta {\arr s A s} \sigma, \id(A\sub \sigma, s \sub \sigma)) \]
  for contexts \(\Gamma\) and \(\Delta\), \(A : \Type_\Delta\), \(s : \Term_\Delta\), and \(\sigma : \arr \Delta \star \Gamma\).

  A set of rules \(\mathcal{R}\) \emph{contains endo-coherence removal} if \(\ecr \subseteq \mathcal{R}\). We say that \(\mathcal{R}\) \emph{has endo-coherence removal} if the rule \textsc{ecr} holds in the generated theory.
\end{definition}

The set \ecr satisfies all the conditions introduced in this chapter, as proven in the next proposition, which concludes this chapter.

\begin{proposition}
  \label{prop:ecr-props}
  Suppose the set of operations \(\mathcal{O}\) contains the standard operations. Then the set \ecr satisfies the following properties:
  \begin{lemmaenum}
  \item The set \ecr satisfies the weakening condition.
  \item The set \ecr satisfies the suspension condition.
  \item The set \ecr satisfies the \(\mathcal{R}\)-substitution condition, for any equality set \(\mathcal{R}\).
  \item \label{item:ecr-supp} The set \ecr satisfies the \(\mathcal{R}\)-support condition, for any equality set \(\mathcal{R}\) satisfying the support condition.
  \item \label{item:ecr-preserve} The set \ecr satisfies the \(\mathcal{R}\)-preservation condition, for any equality set \(\mathcal{R}\) satisfying the weakening and substitution conditions.
  \end{lemmaenum}
\end{proposition}
\begin{proof}
  Suppose \((\Gamma, \Coh \Delta {\arr s A s} \sigma, \id(A \sub \sigma, s \sub \sigma)) \in \ecr\). To show that the substitution holds, we suppose that \(\tau : \arr \Gamma \star \Theta\), and then must prove that:
  \[ (\Theta, \Coh \Delta {\arr s A s} {\sigma \bullet \tau}, \id(A \sub \sigma, s \sub \sigma) \sub \tau) \in \ecr \]
  It is immediate that:
  \[ (\Theta, \Coh \Delta {\arr s A s} {\sigma \bullet \tau}, \id(A \sub {\sigma \bullet \tau}, s \sub {\sigma \bullet \tau})) \in \ecr \]
  and so it suffices to prove that \(\id(A \sub \sigma, s \sub \sigma) \sub \tau \equiv \id(A \sub {\sigma \bullet \tau},s \sub {\sigma \bullet \tau})\), but this follows from \cref{item:disc-prop-sub-sub,prop:categorical}. The weakening condition then follows from the substitution condition.

  For the suspension condition, it must be shown that:
  \[ (\Sigma(\Gamma), \Coh {\Sigma(\Delta)} {\arr {\Sigma(s)} {\Sigma(A)} {\Sigma(s)}} {\Sigma(\sigma)}, \Sigma(\id(A\sub \sigma, s \sub \sigma))) \in \ecr \]
  and so it suffices to show that \(\Supp(\Sigma(s)) = \Var(\Sigma(\Delta))\), which follows from \(\Supp(\Sigma(s)) = \Sigma(\Supp(s))\), and
  \[ \Sigma(\id(A \sub \sigma, s \sub \sigma)) \equiv \id(\Sigma(A) \sub {\Sigma(\sigma)}, \Sigma(s) \sub {\Sigma(\sigma)}) \]
  which follows from the functoriality of suspension and \cref{item:disc-prop-sub-susp,item:disc-prop-susp}.

  For the support condition, assume that \(\Gamma \vdash_{\mathcal{R}} \Coh \Delta {\arr s A s} \sigma : B\) for some \(B : \Type_\Gamma\) and that \(\mathcal{R}\) satisfies the support condition. Then:
  \begin{align*}
    \Supp(\Coh \Delta {\arr s A s} \sigma) &= \Supp(\sigma)\\
                                           &= \FV(\sigma)&\text{by \cref{item:supp-sub-char}}\\
                                           &= \Var(\Delta) \sub \sigma \\
                                           &= \Supp(s) \sub \sigma&\text{by assumption}\\
                                           &= (\Supp(A) \cup \Supp(s)) \sub \sigma &\text{by \cref{item:supp-tm-char-2}}\\
                                           &= \DC_\Delta(\FV(A) \cup \FV(s)) \sub \sigma\\
                                           &= \DC_\Gamma(\FV(A) \sub \sigma \cup \FV(s) \sub \sigma)&\text{by \cref{cor:dc-sub}}\\
    &= \DC_\Gamma(\FV(A \sub \sigma) \cup \FV(s \sub \sigma))&\text{by \cref{prop:vs-sub}}\\
                                           &= \Supp(A \sub \sigma) \cup \Supp(s \sub \sigma)\\
    &= \Supp(\id(A \sub \sigma, s \sub \sigma))
  \end{align*}
  as required.

  Lastly for the preservation condition, let \(\mathcal{R}\) satisfy the weakening and substitution conditions, and assume \(\Gamma \vdash \Coh \Delta {\arr s A s} {\sigma} : B\). By deconstructing the typing derivation, we must have that \(\Delta \vdash A\), \(\Delta \vdash s : A\), and \(\Gamma \vdash \sigma : \Delta\). Therefore, by \cref{prop:sub-prop-1}, \(\Gamma \vdash A \sub \sigma\) and \(\Gamma \vdash s \sub \sigma : A \sub \sigma\). Hence, by \cref{cor:id-typing}, \(\Gamma \vdash \id(A \sub \sigma, s \sub \sigma) : (\arr s A s) \sub \sigma\). It remains to prove that \(\Gamma \vdash (\arr s A s) \sub \sigma = B\), but this is immediate from \cref{lem:ty-unique}, applied to the derivation \(\Gamma \vdash \Coh \Delta {\arr s A s} \sigma : B\).
\end{proof}

\begin{figure}[t]
  \centering
  \label{fig:dep-graph}
  \includegraphics[height=\textheight - 25pt]{test.pdf}
  \caption{Dependency graph of Agda formalisation}
\end{figure}


\chapter{Constructions in \Cattr}
\label{sec:operations-catt}

This chapter will investigate some more involved constructions that can be given in the type theory \Cattr. These constructions will be central to defining the reductions that underpin the type theories \Cattsu and \Cattsua which appear in \cref{cha:cattstrict}. We will give a definition of each construction, describe under what conditions it is well-formed, and state various properties describing the behaviour of the construction and its interaction with other constructions.

For this chapter we will assume that we are working in a tame theory, as described in \cref{sec:tame-theories}. This means that all proofs in this section will hold in any variant of \Cattr such that the equality set \(\mathcal{R}\) satisfies the weakening, substitution, and suspension conditions, and the set of operations \(\mathcal{O}\) is suspendable and contains the standard operations. We will also use all the relevant proofs from \cref{sec:catt-with-equality}, without explaining exactly what condition of the set \(\mathcal{R}\) is being
used.

The formalisation in commonly more specific when specifying which conditions are necessary for each module, for example omitting the suspension condition when it is not needed for a specific construction, but for the body of this text we ignore these distinctions and simply that every theory we work with will be tame, as will be case for all theories introduced in \cref{cha:cattstrict}.

This chapter builds up to the following two constructions, that can be viewed as meta-operations on \Cattr.
\begin{itemize}
\item The \emph{pruning} operation will be introduced in \cref{sec:pruning} and is main component of the type theory \Cattsu, defined in \cref{sec:cattsu}, a type theory for strictly unital \(\infty\)-categories. Pruning removes unnecessary identities from a term, simplifying the resulting term in the process.
\item The \emph{insertion} operation will be introduced in \cref{sec:insertion}. It powers the type theory \Cattsua, a type theory for strictly unital and associative \(\infty\)-categories. Insertion merges certain arguments to a coherence into the body of the coherence itself, effectively ``inserting'' the argument into the head term. It can be viewed as a generalisation of pruning, but is a far more complex construction.
\end{itemize}

Both pruning and insertion perform more radical modifications to the structure of a term that disc removal and endo-coherence removal, the equality rules we have seen so far. Both pruning and insertion modify the pasting diagram in the coherence at the head of the term they act on. In this chapter, more combinatorial descriptions of pasting diagrams will be introduced to enable the pasting diagrams involved in these constructions to be constructed by induction.

The pruning construction identifies locally maximal arguments of a coherence that are syntactically identities, and removes these arguments from term, while also removing the component of the pasting diagram in the coherence for which corresponded to this argument. Pruning could be applied to the term \(f * g * \id\), a ternary composite, to remove the identity argument and convert the ternary composite to a binary composite, returning the term \(f*g\).

Insertion does not just simply remove parts of a term, but flattens the structure of a term, moving data from a locally maximal argument into the head term. The motivating example for insertion is the term \(f * (g * h)\), a binary composite where one of the locally maximal arguments is itself a binary composite. Under insertion, the inner composite \(g * h\) is merged with the outer binary composite to form a single ternary composite \(f * g * h\).

When a locally maximal argument is an identity, it will always be insertable, and the result of inserting the identity into the head term will be similar to pruning the same argument, motivating the viewpoint that insertion is a generalisation of pruning. At the end of this chapter, this relationship will be made precise.

Insertion again performs more radical changes to the head coherence of the term than pruning, and needs to be able to merge two pasting diagrams into one along a locally maximal argument. The operation on pasting diagrams is best understood as an operation on \emph{trees}, an alternative characterisation of pasting diagrams which will be introduced in \cref{sec:trees}.

Although the definition of these trees is simple, to be able to use them effectively we must be able to describe their relationship to the \Catt contexts they represent. It will also be necessary to describe the morphisms between these trees, which correspond to substitutions between the underlying contexts, and the composition of such morphisms.

Certain constructions on trees will not compute nicely with the presentation of the syntax in \Catt. We therefore introduce a new notion of \emph{structured term}, an alternative syntax for \Catt which allows more complex representations of terms over contexts derived from trees. Structured terms effectively retain more information about how they are constructed, allowing constructions to compute on them in ways that is not possible on the raw syntax of \Catt. This representation of terms will be crucial in the formalisation, as it aids the proof assistant in simplifying various constructions. These structured terms are defined in \cref{sec:structured-terms}.

Finally, \cref{sec:insertion} defines the constructions used in the insertion operation, using the structured syntax form the preceding section. In this section, many properties of insertion are stated, including a universal property that is satisfied by insertion.

\section{Pruning}
\label{sec:pruning}

Pruning drives the strictly unital behaviour of \Cattsu. Unitality in \(\infty\)-categories is the property that the identity acts as a unit with respect to composition, so that composing with the unit is equivalent to doing nothing at all. If an \(\infty\)-category is strictly unital, then it exhibits this behaviour up to equality rather than equivalence.

For \Catt, strict unitality means that a composition containing a identity as one of its arguments should be definitionally equal to the same composition but with this argument removed. Pruning is the operation that removes an argument from a composition, taking a term such as \(f * g * \id\) to \(f * g\), or \(\id * f\) to the unary composite on \(f\). In the presence of strict units, it is also desirable to simplify the higher dimensional data that witnessed the (weak) unitality in \Catt. For example, the left unitor on \(f\), given by the term:
\[ \Coh {(x : \star), (y : \star), (f : \arr x \star y)} {\arr {\id(x) * f} {} {f}} {\id} \]
which witnesses that composing on the left with an identity is equivalent to the original term, can be simplified to the identity on \(f\), and the triangle equations which govern the coherence laws for the unitors can also trivialise. For this reason, pruning is defined to be able to apply to any term which has identities as a locally maximal argument. We review the definition of a locally maximal argument below.

\begin{definition}
  In a context \(\Gamma\), a \emph{locally maximal variable} is a variable \(x\) of \(\Gamma\) that does not appear in the source or target of any other variable of \(\Gamma\). Alternatively, \(x\) is locally maximal when:
  \[ x \not\in \Supp(y) \]
  for any \(y \neq x \in \Var(\Gamma)\). Given a substitution \(\sigma : \Delta \to \Gamma\), a \emph{locally maxixal argument} of \(\sigma\) is a term \(x \sub \sigma\) where \(x\) is a locally maximal variable of \(\Delta\).
\end{definition}

\begin{example}
  \label{ex:lm}
  Consider the pasting diagram given by the following diagram:
  % https://q.uiver.app/#q=WzAsMyxbMCwwLCJ4Il0sWzIsMCwieSJdLFszLDAsInoiXSxbMCwxLCJmIiwwLHsiY3VydmUiOi01fV0sWzAsMSwiaCIsMix7ImN1cnZlIjo1fV0sWzAsMSwiZyIsMV0sWzEsMiwiaiJdLFszLDUsIlxcYWxwaGEiLDAseyJzaG9ydGVuIjp7InNvdXJjZSI6MjAsInRhcmdldCI6MjB9fV0sWzUsNCwiXFxiZXRhIiwwLHsic2hvcnRlbiI6eyJzb3VyY2UiOjIwLCJ0YXJnZXQiOjIwfX1dXQ==
  \[
    \begin{tikzcd}
      x && y & z
      \arrow[""{name=0, anchor=center, inner sep=0}, "f", curve={height=-30pt}, from=1-1, to=1-3]
      \arrow[""{name=1, anchor=center, inner sep=0}, "h"', curve={height=30pt}, from=1-1, to=1-3]
      \arrow[""{name=2, anchor=center, inner sep=0}, "g"{description}, from=1-1, to=1-3]
      \arrow["j", from=1-3, to=1-4]
      \arrow["\alpha", shorten <=4pt, shorten >=4pt, Rightarrow, from=0, to=2]
      \arrow["\beta", shorten <=4pt, shorten >=4pt, Rightarrow, from=2, to=1]
    \end{tikzcd}
  \]
  which corresponds to the \Catt context (written to highlight the dimension of each term):
  \begin{alignat*}{3}
    \Theta ={} &(x : \star),\\
    &(y : \star),{}&&(f : x \to y),\\
    &&&(g : x \to y),{}&&(\alpha : f \to g),\\
    &&&(h : x \to y),&&(\beta : g \to h),\\
    &(z : \star),&&(j : y \to z)
  \end{alignat*}
  The locally maximal variables of \(\Theta\) are \(\alpha\), \(\beta\), and \(j\). Note that \(j\) is locally maximal, despite not being of maximal dimension in the context. Pruning the context \(\Theta\) along locally maximal variable \(\alpha\) removes the variables \(\alpha\) and \(g\) from the context, and must amend the type of \(\beta\) so that its source is \(f\).
\end{example}

To perform the pruning construction, we start with a coherence term \(\Coh \Delta A \sigma : \Term_\Gamma\), and assume that some locally maximal argument of \(\sigma\) is an identity, that is \(x \sub \sigma \equiv \id(B,t)\) for some locally maximal variable \(x\), type \(B : \Type_\Gamma\), and term \(t : \Term_\Gamma\). We then construct the following:
\begin{itemize}
\item A new pasting diagram \(\Delta \sslash x\), corresponding to \(\Delta\) with the variable \(x\) and its target removed.
\item A new set of arguments \(\sigma \sslash x\), consisting of the same terms as \(\sigma\) except those corresponding to \(x\) and its target.
\item A projection substitution \(\pi_x : \Delta \to \Delta \sslash x\), from which a type \(A \sub {\pi_x} : \Type_{\Delta \sslash x}\) can be obtained. This projection sends the source of \(x\) to the identity on its source, the target of \(x\) to the source of \(x\), and every other variable to itself.
\end{itemize}
We note that the source and target of the locally maximal variable \(x\) are well defined as \(x\) must be sent by \(\sigma\) to an identity, which cannot be zero dimensional.

\subsection{Dyck words}

To be able to easily reason about the structures involved in pruning, we wish them by induction. To do this we introduce a different presentation of pasting diagrams called \emph{Dyck words}, which have a simpler inductive structure. Dyck words more directly encode the structure of the pasting diagram, and will allow us to give an inductive characterisation of the locally maximal variables of the associated context.

\begin{definition}
  The set of \emph{Dyck words}, \(\Dyck_d\) of trailing dimension \(d\) consists of lists of ``up'' and ``down'' moves according to the following rules.
  \begin{mathpar}
    \inferrule{ }{\circleddash : \Dyck_0} \and
    \inferrule{d : \mathbb{N} \\\mathcal{D} : \Dyck_d}{\mathcal{D} \Uparrow : \Dyck_{d + 1}} \and
    \inferrule{d : \mathbb{N} \\ \mathcal{D} : \Dyck_{d + 1}}{\mathcal{D} \Downarrow : \Dyck_d}
  \end{mathpar}
  In any suffix of a Dyck word \(D : \Dyck_d\), the number of ``up'' moves (given by constructor \(\Uparrow\)) must be greater than or equal to the number of ``down'' moves (given by constructor \(\Downarrow\)). The difference between the number of each move is given by the trailing dimension \(d\).
\end{definition}

Dyck words can be given a visual interpretation as a \emph{mountain diagram}. To obtain such a diagram we start on the left hand side, and draw a continuous line by drawing an upwards sloping segment for each \(\Uparrow\) in the word, and a downwards sloping line for each \(\Downarrow\) in the word. An example of such a diagram is given in \cref{fig:mountain}.

\begin{figure}[h]
  \centering
\[\begin{tikzcd}[column sep = small, cells={inner sep = 0}, arrows={no head}]
	&& \bullet && \bullet \\
	& \bullet && \bullet && \bullet && \bullet \\
	\bullet &&&&&& \bullet && \bullet
	\arrow[from=3-1, to=2-2]
	\arrow[from=2-2, to=1-3]
	\arrow[from=1-3, to=2-4]
	\arrow[from=2-4, to=1-5]
	\arrow[from=1-5, to=2-6]
	\arrow[from=2-6, to=3-7]
	\arrow[from=3-7, to=2-8]
	\arrow[from=2-8, to=3-9]
\end{tikzcd}\]
  \caption[Mountain diagram]{Mountain diagram for \(\circleddash \Uparrow\, \Uparrow\, \Downarrow\, \Uparrow\, \Downarrow\, \Downarrow\, \Uparrow\, \Downarrow\, : \Dyck_0\)}
  \label{fig:mountain}
\end{figure}

The rules \(\circleddash\), \(\Uparrow\), and \(\Downarrow\) directly correspond to the rules \textsc{pss}, \textsc{pse}, and \textsc{psd} that generate the typing judgement for ps-contexts. From a Dyck word, we can directly construct this context by induction.

\begin{definition}
  For a Dyck word \(\mathcal{D} : \Dyck_d\), its associated context \(\lfloor \mathcal{D} \rfloor\), associated type \(\ty_{\mathcal{D}} : \Type_{\lfloor \mathcal{D} \rfloor}\), and associated term \(\tm_{\mathcal{D}} : \Term_{\lfloor \mathcal{D} \rfloor}\) are defined by mutual induction on \(\mathcal{D}\):
  \begin{align*}
    \lfloor \circleddash \rfloor &= (x : \star)\\
    \lfloor \mathcal{D} \Uparrow \rfloor &= \lfloor \mathcal{D} \rfloor, (y_{\mathcal{D}} : \ty_{\mathcal{D}}), (f_{\mathcal{D}} : \arr {\wk(\tm_{\mathcal{D}})} {\wk(\ty_{\mathcal{D}})} {y_{\mathcal{D}}})\\
    \lfloor \mathcal{D} \Downarrow \rfloor &= \lfloor \mathcal{D} \rfloor\\[10pt]
    \ty_{\circleddash} &= \star\\
    \ty_{\mathcal{D}\Uparrow} &= \arr{\wk(\wk(\tm_{\mathcal{D}}))} {\wk(\wk(\ty_{\mathcal{D}}))} {y_{\mathcal{D}}}\\
    \ty_{\mathcal{D} \Downarrow} &= \base(\ty_{\mathcal{D}})&\text{where }\base(\arr s A t) = A\\[10pt]
    \tm_{\circleddash} &= x\\
    \tm_{\mathcal{D}\Uparrow} &= f_{\mathcal{D}}\\
    \tm_{\mathcal{D}\Downarrow} &= \tgt(\ty_{\mathcal{D}})&\text{where }\tgt(\arr s A t) = t
  \end{align*}
  The variable names given here are used to avoid ambiguity in the definition. As we consider contexts up to \(\alpha\)-equality, we may freely change these variable names. The \(\tgt\) and \(\base\) operations are well defined here as it may be checked by a simple induction that \(\dim(\ty_{\mathcal{D}}) = d\) for \(\mathcal{D} : \Dyck_d\), ensuring the we only apply \(\tgt\) and \(\base\) to types of strictly positive dimension.
\end{definition}

The tight correspondence between the rules used to construct Dyck words and ps-contexts allow an easy proof that the contexts associated to Dyck words are in fact pasting diagrams.

\begin{lemma}
  \label{lem:dyck-typing}
  For a Dyck word \(\mathcal{D} : \Dyck_d\), its associated context, type, and term are all well-formed:
  \[ \lfloor \mathcal{D} \rfloor \vdash \qquad \lfloor \mathcal{D} \rfloor \vdash \ty_{\mathcal{D}} \qquad \lfloor \mathcal{D} \rfloor \vdash \tm_{\mathcal{D}} : \ty_{\mathcal{D}} \]
  In addition to being a well-formed context, the context associated to a Dyck word is a ps-context; the following judgement holds:
  \[ \lfloor \mathcal{D} \rfloor \vdash_{\mathsf{ps}} \tm_{\mathcal{D}} : \ty_{\mathcal{D}} \]
  and so if \(\mathcal{D} : \Dyck_0\), we have \(\lfloor \mathcal{D} \rfloor \vdash_{\mathsf{ps}}\). Further, all ps-contexts are the associated context of a Dyck word.
\end{lemma}
\begin{proof}
  Due to the similarity of the rules for ps-contexts and Dyck words, this follows quickly from simple inductions, which are given in the formalisation. The proofs for the typing judgements appear in \module{Catt.Dyck.Typing} and the proofs for the ps-context judgements appear in \module{Catt.Dyck.Pasting}.
\end{proof}

The locally maximal variables in the context associated to a Dyck word correspond exactly to the points in the word where there is an upwards move followed immediately by a downwards move, creating a peak in the mountain diagram. These peaks can be given an inductive characterisation.

\begin{definition}
  Let \(\mathcal{D} : \Dyck_d\) be a Dyck word. A \emph{peak} of \(\mathcal{D}\), \(p : \Peak_{\mathcal{D}}\) is inductively defined by the following rules:
  \begin{mathpar}
    \inferrule{d \in \mathbb{N} \\ \mathcal{D} : \Dyck_d}{\mathcal{D} \UDPeak : \mathcal{D} \Uparrow\,\Downarrow}\and
    \inferrule{d \in \mathbb{N} \\ \mathcal{D} : \Dyck_d \\ p : \Peak_{\mathcal{D}}}{p \UpPeak : \Peak_{\mathsf{D}} \Uparrow}\and
    \inferrule{d \in \mathbb{N} \\ \mathcal{D} : \Dyck_{d+1} \\ p : \Peak_{\mathcal{D}}}{p \DownPeak : \Peak_{\mathcal{D} \Downarrow}}
  \end{mathpar}
  From each peak \(p : \Peak_{\mathcal{D}}\), a term \(\lfloor p \rfloor\) of \(\lfloor \mathcal{D} \rfloor\) can be inductively defined by:
  \[ \lfloor \mathcal{D} \UDPeak \rfloor = f_\mathcal{D} \qquad \lfloor p \UpPeak \rfloor = \wk(\wk \lfloor p \rfloor) \qquad \lfloor p \DownPeak \rfloor = \lfloor p \rfloor\]
  The term \(\lfloor p \rfloor\) is a locally maximal variable of \(\lfloor \mathcal{D} \rfloor\).
\end{definition}

\begin{example}
  \label{ex:dyck-peaks}
  Recall the ps-context \(\Theta\) from \cref{ex:lm}. This context is the associated context of the Dyck word:
  \[ \circleddash \Uparrow\, \Uparrow\, \Downarrow\, \Uparrow\, \Downarrow\, \Downarrow\, \Uparrow\, \Downarrow\]
  for which the mountain diagram is given in \cref{fig:mountain}. The three locally maximal variables \(\alpha\), \(\beta\), and \(j\) correspond to the peaks:
  \[ \circleddash \Uparrow\, \UDPeak\, \UpPeak\, \DownPeak\, \DownPeak\, \UpPeak\, \DownPeak \qquad \circleddash \Uparrow\, \Uparrow\, \Downarrow\, \UDPeak\, \DownPeak\, \UpPeak\, \DownPeak \qquad \circleddash \Uparrow\, \Uparrow\, \Downarrow\, \Uparrow\, \Downarrow\, \Downarrow\, \UDPeak \]
  which themselves correspond to the three peaks of the mountain diagram, with the height of each peak corresponding to the dimension of each locally maximal variable.
\end{example}

As all disc contexts are pasting diagrams, and hence are the associated context of a Dyck word.

\begin{definition}
  Let \(\mathcal{D}^n\) be the Dyck word with \(n\) upwards moves followed by \(n\) downwards moves. The equality \( \lfloor \mathcal{D}^n \rfloor \equiv D^n\) follows from a trivial induction. If \(n > 0\), There is a unique peak of \(\mathcal{D}^n\) with associated term \(d_n\).
\end{definition}

We lastly show that a Dyck word can be suspended, which is expected as ps-contexts are closed under suspension. The various constructions associated to a suspended Dyck word are equal to the same constructions on the unsuspended Dyck word.

\begin{lemma}
  Dyck words are closed under suspension. We define the suspension of a Dyck word \(\mathcal{D} : \Dyck_d\) to be the Dyck word \(\Sigma(\mathcal{D}) : \Dyck_{d+1}\) which is obtained by inserting an additional up move to the start of the work, or can alternatively be inductively defined by:
  \[ \Sigma(\circleddash) = \circleddash \Uparrow \qquad \Sigma(\mathcal{D}\Uparrow) = \Sigma(\mathcal{D})\Uparrow \qquad \Sigma(\mathcal{D}\Downarrow) = \Sigma(\mathcal{D})\Downarrow \]
  The following equalities hold:
  \[ \lfloor \Sigma(\mathcal{D}) \rfloor = \Sigma(\lfloor \mathcal{D} \rfloor) \qquad \ty_{\Sigma(\mathcal{D})} = \Sigma(\ty_{\mathcal{D}}) \qquad \tm_{\Sigma(\mathcal{D})} = \Sigma(\tm_{\mathcal{D}}) \]
  for each Dyck word \(\mathcal{D}\). For each peak \(p : \Peak_{\mathcal{D}}\), there is an associated peak \(\Sigma(p) : \Peak_{\Sigma(\mathcal{D})}\) which is defined similarly.
\end{lemma}
\begin{proof}
  These properties are all proved by straight forward induction on \(\mathcal{D}\). The formalised proofs appear in \module{Catt.Dyck.Properties}.
\end{proof}

The Dyck words presented in this section can be viewed as a more direct syntax for pasting contexts, which allow induction to be easily performed. For this reason, most of the properties of Dyck words follow from routine inductions, and hence are relegated to the formalisation. The key contribution of this (sub)section is the characterisation of locally maximal variables as peaks, which have an easy inductive definition due to the simplicity of Dyck words.

\begin{remark}
  All locally maximal variables of ps-contexts are identified with peaks, with the exception of the unique variable of the singleton context. This discrepancy will make no difference for pruning, as a \(0\)-dimensional variable could never have been sent to an identity and so would never have been a candidate for pruning.
\end{remark}

\subsection{The pruning construction}

Equipped with Dyck words, and a classification of locally maximal variables as peaks, we are now able to define each of the constructions used in the pruning operation.

\begin{definition}
  Let \(\mathcal{D} : \Dyck_d\) be a dyck word, and \(p : \Peak_{\mathcal{D}}\) be a peak of \(\mathcal{D}\). The pruned Dyck word \(\mathcal{D} \sslash p : \Dyck_d\) and substitution \(\pi_p : \lfloor \mathcal{D}\rfloor \to \lfloor \mathcal{D} \sslash p \rfloor\) are then defined inductively on the peak \(p\) by the following equations:
  \begin{align*}
    \mathcal{D} \Uparrow\, \Downarrow \sslash \mathcal{D} \UDPeak &= \mathcal{D}\\
    \mathcal{D} \Uparrow \sslash p \UpPeak &= (\mathcal{D} \sslash p) \Uparrow \\
    \mathcal{D} \Downarrow \sslash p \DownPeak &= (\mathcal{D} \sslash p) \Downarrow \\[10pt]
    \pi_{\mathcal{D}\UDPeak} &= \langle \id_{\lfloor \mathcal{D} \rfloor} , \tm_{\mathcal{D}}, \id(\ty_{\mathcal{D}}, \tm_{\mathcal{D}}) \rangle\\
    \pi_{p \UpPeak} &= \langle \wk(\wk(\pi_p)) , y_{\mathcal{D}}, f_{\mathcal{D}} \rangle\\
    \pi_{p \DownPeak} &= \pi_p\\
  \intertext{If we further have a substitution \(\sigma : \arr {\lfloor \mathcal{D} \rfloor} \star \Gamma\) for some context \(\Gamma\), then the pruned substitution \(\sigma \sslash p : \arr {\lfloor \mathcal{D} \sslash p \rfloor} \star \Gamma\) can be formed:}
    \langle \sigma, s, t \rangle \sslash \mathcal{D}\UDPeak &= \sigma \\
    \langle \sigma, s, t \rangle \sslash p \UpPeak &= \langle \sigma \sslash p, s, t \rangle \\
    \sigma \sslash p \DownPeak &= \sigma \sslash p
  \end{align*}
\end{definition}

Each peak in a Dyck word corresponds to a consecutive upwards arrow and downwards arrow. Pruning this peak corresponds removing these two arrows, which does not change the trailing dimension of the Dyck word. The effect on the mountain diagram representation can be seen in \cref{fig:prune}.

\begin{figure}[h]
  \centering
% https://q.uiver.app/#q=WzAsMTcsWzAsMiwiXFxidWxsZXQiXSxbMSwxLCJcXGJ1bGxldCJdLFsyLDAsIlxcYnVsbGV0Il0sWzMsMSwiXFxidWxsZXQiXSxbNCwwLCJcXGJ1bGxldCJdLFs1LDEsIlxcYnVsbGV0Il0sWzYsMiwiXFxidWxsZXQiXSxbNywxLCJcXGJ1bGxldCJdLFs4LDIsIlxcYnVsbGV0Il0sWzksMSwiXFxyaWdodHNxdWlnYXJyb3ciXSxbMTAsMiwiXFxidWxsZXQiXSxbMTEsMSwiXFxidWxsZXQiXSxbMTIsMCwiXFxidWxsZXQiXSxbMTMsMSwiXFxidWxsZXQiXSxbMTQsMiwiXFxidWxsZXQiXSxbMTUsMSwiXFxidWxsZXQiXSxbMTYsMiwiXFxidWxsZXQiXSxbMCwxXSxbMSwyLCIiLDAseyJjb2xvdXIiOlswLDYwLDYwXX1dLFsyLDMsIiIsMCx7ImNvbG91ciI6WzAsNjAsNjBdfV0sWzMsNF0sWzQsNV0sWzUsNl0sWzYsN10sWzcsOF0sWzEwLDExXSxbMTEsMTJdLFsxMiwxM10sWzEzLDE0XSxbMTQsMTVdLFsxNSwxNl1d
\[\begin{tikzcd}[column sep = small, cells={inner sep = 0}, arrows={no head}]
	&& |[color={rgb,255:red,204;green,0;blue,14}]|\bullet && \bullet &&&&&&&& \bullet \\
	& \bullet && \bullet && \bullet && \bullet && \rightsquigarrow && \bullet && \bullet && \bullet \\
	\bullet &&&&&& \bullet && \bullet && \bullet &&&& \bullet && \bullet
	\arrow[from=3-1, to=2-2]
	\arrow[color={rgb,255:red,204;green,0;blue,14}, from=2-2, to=1-3]
	\arrow[color={rgb,255:red,204;green,0;blue,14}, from=1-3, to=2-4]
	\arrow[from=2-4, to=1-5]
	\arrow[from=1-5, to=2-6]
	\arrow[from=2-6, to=3-7]
	\arrow[from=3-7, to=2-8]
	\arrow[from=2-8, to=3-9]
	\arrow[from=3-11, to=2-12]
	\arrow[from=2-12, to=1-13]
	\arrow[from=1-13, to=2-14]
	\arrow[from=2-14, to=3-15]
	\arrow[from=3-15, to=2-16]
	\arrow[from=2-16, to=3-17]
\end{tikzcd}\]
  \caption[Pruning]{Pruning of peak \(\circleddash \Uparrow\, \UDPeak\, \UpPeak\, \DownPeak\, \DownPeak\, \UpPeak\, \DownPeak\)}
  \label{fig:prune}
\end{figure}

When a peak is pruned the locally maximal variable and its target are removed from the associated context. The substitution \(\pi_{\mathcal{D} \UDPeak}\) simply maps these two variables to \(\id(\ty_{\mathcal{D}},\tm_{\mathcal{D}})\) and \(\tm_{\mathcal{D}}\), where the Dyck term \(\tm_{\mathcal{D}}\) is the source of the locally maximal variable. Pruning a substitution simply removes the terms corresponding to the removed variables in the associated context.

\begin{example}
  Let \(\Gamma = (x : \star), (f : \arr x \star x)\) and consider the term \(f * \id(x)\), which is given by:
  \[ \Coh {(a : \star), (b : \star), (c : a \to b), (d : \star), (e : b \to d)} {a \to d} {\langle x, x, f, x, \id(\star,x) \rangle} \]
  The context in this coherence is the associated context of the Dyck word \(\circleddash \Uparrow\,\Downarrow\,\Uparrow\,\Downarrow\) which has a peak \(\circleddash \Uparrow\,\Downarrow\,\UDPeak\), which corresponds to the locally maximal variable \(e\). Since \(e\) is sent to an identity by the substitution, pruning can be applied to get:
  \begin{align*}
    \circleddash \Uparrow\,\Downarrow\,\Uparrow\,\Downarrow \sslash \circleddash \Uparrow\,\Downarrow\,\UDPeak &= \circleddash \Uparrow\, \Downarrow\\
    \pi_{\circleddash \Uparrow\,\Downarrow\,\UDPeak} &= \langle a, b, c, b, \id(\star,b) \rangle\\
    \langle x, x, f, x, \id(\star,x) \rangle \sslash \circleddash \Uparrow\,\Downarrow\,\UDPeak &= \langle x,x,f\rangle
  \end{align*}
  Which results in the term:
  \[ \Coh {(a : \star), (b : \star), (c : a \to b)} {(a \to d) \sub {\langle a, b, c, b, \id(\star,b) \rangle} } {\langle x, x, f \rangle} \equiv \Coh {(a : \star), (b : \star), (c : a \to b)} {(a \to b)} {\langle x, x, f \rangle} \]
  which is the unary composite on \(f\). In the presence of disc removal, this term could further simplify to the variable \(f\).
\end{example}

With these constructions, we can finally define the pruning rule.

\begin{definition}
  A term \(t\) \emph{is an identity} if \(t \equiv \id(A,s)\) for some type \(A\) and some term \(s\). The \emph{pruning rule set}, \prune, is the set consisting of the triples:
  \[ (\Gamma, \Coh {\lfloor \mathcal{D} \rfloor} {A} \sigma, \Coh {\lfloor \mathcal{D} \sslash p \rfloor} {A \sub {\pi_p}} {\sigma \sslash p}) \]
  for each Dyck word \(\mathcal{D} : \Dyck_0\), peak \(p : \Peak_{\mathcal{D}}\), type \(A : \Type_{\lfloor \mathcal{D} \rfloor}\), and substitution \(\sigma : \arr {\lfloor \mathcal{D} \rfloor} \star \Gamma\) where \(\lfloor p \rfloor \sub \sigma\) is an identity.

  A set of rules \(\mathcal{R}\) \emph{contains pruning} if \(\prune \subseteq \mathcal{R}\). Pruning makes the following rule admissible:
  \begin{mathpar}
    \inferrule{\mathcal{D} : \Dyck_0 \\ p : \Peak_{\mathcal{D}} \\ \lfloor \mathcal{D} \rfloor \vdash A \\ \Gamma \vdash \sigma : \lfloor \mathcal{D} \rfloor \\\\ (\lfloor \mathcal{D} \rfloor, \Supp(\src(A)), \tgt(A)) \in \mathcal{O}\\ \lfloor p \rfloor \sub \sigma \text{ is an identity}}{\Gamma \vdash \Coh {\lfloor \mathcal{D} \rfloor} A \sigma = \Coh {\lfloor \mathcal{D} \sslash p} {A \sub {\pi_p}} {\sigma \sslash p}}\textsc{prune}
  \end{mathpar}
  The set \(\mathcal{R}\) \emph{has pruning} if the rule \textsc{prune} holds in the generated theory.
\end{definition}

\subsection{Properties of pruning}

With start with the aim of proving that each construction involved in pruning satisfies the expected typing judgements. To do this the following lemma will be necessary, which describes the interaction of the Dyck word construction with pruning.

\begin{lemma}
  \label{lem:dyck-prune-prop}
  Let \(\mathcal{D} : Dyck_d\) be a Dyck word. Then the following equations hold:
  \begin{align*}
    \ty_{\mathcal{D}} \sub{\pi_p} &\equiv \ty_{\mathcal{D} \sslash p}\\
    \tm_{\mathcal{D}} \sub{\pi_p} &\equiv \tm_{\mathcal{D} \sslash p}
  \end{align*}
  for any peak \(p : \Peak_{\mathcal{D}}\) of \(\mathcal{D}\).
\end{lemma}
\begin{proof}
  The proof proceeds by a induction on the peak \(p\), proving both equations simultaneously. Both equations hold by routine calculations given in \module{Catt.Dyck.Pruning.Properties} by the functions \func{Catt.Dyck.Pruning.Properties}{dyck-type-prune} and \func{Catt.Dyck.Pruning.Properties}{dyck-term-prune}.
\end{proof}

This allows the main typing properties of this section to be given.

\begin{proposition}
  \label{prop:prune-ty}
  Let \(\mathcal{D} : \Dyck_d\) be a Dyck word and let \(p : \Peak_{\mathcal{D}}\) be a peak of this word. Then:
  \[ \lfloor \mathcal{D} \sslash p \rfloor \vdash \pi_p : \lfloor \mathcal{D} \rfloor \]
  Given a substitution \(\sigma\) with \(\Gamma \vdash \sigma : \lfloor \mathcal{D} \rfloor\), where \(\lfloor p \rfloor \sub \sigma\) is an identity, the equality and typing judgements:
  \[ \Gamma \vdash \sigma = \pi_p \bullet (\sigma \sslash p) \qquad \Gamma \vdash \sigma : \lfloor \mathcal{D} \sslash p \rfloor \]
  hold.
\end{proposition}
\begin{proof}
  We prove each judgement holds in turn by induction on the peak \(p\). For the judgement:
  \[ \lfloor \mathcal{D} \sslash p \rfloor \vdash \pi_p : \lfloor \mathcal{D} \rfloor \]
  the case when the peak is of the form \(p\DownPeak\) is trivial. The case for when it is of the form \(\mathcal{D}\UDPeak\) easily follows from \cref{lem:dyck-typing,cor:id-typing}. For the case where the peak is of the form \(p\UpPeak\), it must be shown that:
  \[ \Delta \vdash \langle \wk(\wk(\pi_p)), y, f \rangle : \lfloor \mathcal{D} \rfloor, (y : \ty_{\mathcal{D}}), (f : \arr {\wk(\tm_{\mathcal{D}})} {\wk(\ty_{\mathcal{D}})} y) \]
  where \(\Delta = \lfloor \mathcal{D} \sslash p \rfloor, (y : \ty_{\mathcal{D} \sslash p}), (f : \arr{\wk(\tm_{\mathcal{D}\sslash p})} {\wk(\ty_{\mathcal{D}\sslash p})} {y})\). This requires proofs of:
  \begin{align*}
    \Delta &\vdash \wk(\wk(\pi_p)) : \lfloor \mathcal{D} \rfloor\\
    \Delta &\vdash y : \ty_{\mathcal{D}} \sub {\pi_p}\\
    \Delta &\vdash f : (\arr {\wk(\tm_{\mathcal{D}})} {\wk(\ty_{\mathcal{D}})} y) \sub {\langle \wk(\pi_p), y \rangle}
  \end{align*}
  The first part follows from inductive hypothesis (and typing of weakening). The other two judgements follow from some calculation and \cref{lem:dyck-prune-prop}.

  For the second judgement:
  \[ \Gamma \vdash \sigma = \pi_p \bullet (\sigma \sslash p)\]
  The \(p \DownPeak\) case is again trivial. The \(p \UpPeak\) case follows easily from properties of weakening and the inductive hypothesis. For the \(\mathcal{D} \UDPeak\) case we suppose the substitution is of the form \(\langle \sigma, s, \id(A,t) \rangle\) and are required to show that:
  \[ \Gamma \vdash \langle \id_{\mathcal{D}}, \tm_{\mathcal{D}}, \id(\ty_{\mathcal{D}}, \tm_{\mathcal{D}})\rangle \bullet \sigma = \langle \sigma, s, \id(A,t) \rangle \]
  It is immediate that \(\id_{\mathcal{D}} \bullet \sigma \equiv \sigma\) and so it remains to show that \(\Gamma \vdash \tm_{\mathcal{D}} \sub \sigma = s\) and \(\Gamma \vdash \id(\ty_{\mathcal{D}},\tm_{\mathcal{D}}) \sub \sigma = \id(A,t)\). By deconstructing the typing derivation of \(\langle \sigma, s, \id(A,t) \rangle\), we have:
  \[ \Gamma \vdash \id(A,t) : (\arr{\wk(\tm_{\mathcal{D}})} {\wk(\ty_{\mathcal{D}})} {y}) \sub {\langle \sigma ,s \rangle} \]
  By \cref{cor:id-typing} and the uniqueness of typing, we must have:
  \[ \Gamma \vdash \arr t A t = (\arr{\wk(\tm_{\mathcal{D}})} {\wk(\ty_{\mathcal{D}})} {y}) \sub {\langle \sigma ,s \rangle} \equiv \arr {\tm_{\mathcal{D}} \sub \sigma} {\ty_{\mathcal{D}} \sub \sigma} {s} \]
  and so \(A = \ty_{\mathcal{D}} \sub \sigma\) and \(s = t = \tm_{\mathcal{D}} \sub \sigma\). The equality \(\id(\ty_{\mathcal{D}}, \tm_{\mathcal{D}}) = \id(A,t)\) follows as equality is respected by the identity construction, which can be proved by a simple induction.

  Lastly, we consider the judgement:
  \[ \Gamma \vdash \sigma \sslash p : \lfloor \mathcal{D} \sslash p \rfloor \]
  The only difficult case is for the peak \(p \UpPeak\), where we can assume that the substitution is of the form \(\langle \sigma, s, t\rangle\), such that:
  \[ \langle \sigma, s, t\rangle \sslash p \UpPeak \equiv \langle \sigma \sslash p, s, t\rangle\]
  Typing for \(\sigma \sslash p\) follows from inductive hypothesis, and the typing for \(s\) and \(t\) follow from applying conversion rules to the corresponding parts of the typing derivation for \(\langle \sigma, s, t \rangle\). After some computation, the following equalities are needed for these conversion rules:
  \begin{align*}
    \Gamma &\vdash \tm_{\mathcal{D}} \sub \sigma = \tm_{\mathcal{D} \sslash p} \sub \sigma \sslash p\\
    \Gamma &\vdash \ty_{\mathcal{D}} \sub \sigma = \ty_{\mathcal{D} \sslash p} \sub \sigma \sslash p
  \end{align*}
  The first is given by:
  \begin{align*}
    \tm_{\mathcal{D}} \sub \sigma &= \tm_{\mathcal{D}} \sub {\pi_p \bullet (\sigma \sslash p)}\\
                                  &\equiv \tm_{\mathcal{D}} \sub {\pi_p} \sub {\sigma \sslash p}\\
    &\equiv \tm_{\mathcal{D} \sslash p} \sub {\sigma \sslash p}
  \end{align*}
  and the second follows similarly, completing the proof.
\end{proof}

We next show that pruning has the expected properties on the the Dyck words \(\mathcal{D}^n\), which correspond to disc contexts.

\begin{proposition}
  \label{prop:prune-disc}
  Let \(n > 0\), and \(p\) be the unique peak of \(\mathcal{D}^n\). Then:
  \[ \mathcal{D}^n \sslash p \equiv \mathcal{D} \qquad \{\arr s A t,u\} \sslash p \equiv \{A,s\}\]
  for all \(A,s,t,u\) where \(\dim(A) = n - 1\).
\end{proposition}
\begin{proof}
  Both properties are immediate.
\end{proof}

We now turn our attention to proving that the pruning equality set satisfies all the conditions from \cref{sec:ruleset}. We begin with the tameness conditions, omitting the weakening condition, as it follows from the substitution condition.

\begin{proposition}
  \label{prop:prune-tame}
  For all \(\mathcal{D} : \Dyck_d\) and peaks \(p : \Peak_{\mathcal{D}}\), and substitutions \(\sigma : \lfloor \mathcal{D} \rfloor \to \Delta\) and \(\tau : \Delta \to \Gamma\) the following equality holds:
  \[ (\sigma \sslash p) \bullet \tau \equiv (\sigma \bullet \tau) \sslash p \]
  Hence, the set \prune satisfies the \(\mathcal{R}\)-substitution condition for any equality set \(\mathcal{R}\), and so also satisfies the weakenening condition.

  Furthermore, the following equalities hold:
  \[\Sigma(\mathcal{D}) \sslash \Sigma(p) = \Sigma(\mathcal{D} \sslash p) \qquad \pi_{\Sigma(p)} \equiv \Sigma(\pi_p) \qquad \Sigma(\sigma \sslash p) \equiv \Sigma(\sigma) \sslash \Sigma(p)\]
  Therefore, the set \prune also satisfies the suspension condition, making the equality set \prune tame.
\end{proposition}
\begin{proof}
  The proofs of each syntactic equality are easily proved by induction on the peak \(p\). Their proofs are given in the formalisation in \module{Catt.Dyck.Pruning.Properties} as \func{Catt.Dyck.Pruning.Properties}{//s-sub}, \func{Catt.Dyck.Pruning.Properties}{prune-susp-peak}, \funcn{Catt.Dyck.Pruning.Properties}{susp-}{susp-\(\pi\)}, and \func{Catt.Dyck.Pruning.Properties}{susp-//s}.
\end{proof}

To show that the support property holds, we must prove that \(\Supp(\sigma) = \Supp(\sigma \sslash p)\). We aim to do this by observing that \(\Supp(\sigma) = \Supp(\pi_p \bullet (\sigma \sslash p))\) and that \(\Supp(\pi_p \bullet (\sigma \sslash p)) = \Supp(\sigma \sslash p)\). By employing the proof strategy for the support condition introduced in \cref{sec:further-conditions}, the first will follow form the equality \(\sigma = \pi_p \bullet (\sigma \sslash p)\), which we can assume holds in a theory which satisfies the support condition. For the second we need the following lemma.

\begin{lemma}
  \label{lem:pi-bdry}
  For all \(n : \mathbb{N}\), \(\epsilon \in \{-,+\}\), \(\mathcal{D} : \Dyck_d\), and \(p : \Peak_{\mathcal{D}}\):
  \[ \bdry n \epsilon {\lfloor \mathcal{D} \rfloor} \sub {\pi_p} = \Supp(\bdry n \epsilon {\lfloor \mathcal{D} \sslash p \rfloor}) \]
  and so \(\Supp(\pi_p) = \Var(\lfloor \mathcal{D} \sslash p \rfloor)\).
\end{lemma}
\begin{proof}
  The main equation in this lemma is given by a long and technical induction on the peak \(p\). The details of this induction appear in the formalisation in the function \funcn{Catt.Dyck.Pruning.Support}{-boundary-vs}{\(\pi\)-boundary-vs} which appears in the module \module{Catt.Dyck.Pruning.Support}.

  The equation \(\Supp(\pi_p) = \Var(\lfloor \mathcal{D} \sslash p \rfloor)\) follows from \cref{prop:vs-sub,lem:bdry-full}, by setting \(n = \dim(\lfloor \mathcal{D} \rfloor)\).
\end{proof}

We are now ready to prove that the support condition holds.

\begin{proposition}
  \label{prop:prune-supp}
  Let \(\mathcal{R}\) be a tame equality rule set that satisfies the support condition. Then the set \prune satisfies the \(\mathcal{R}\)-support condition.
\end{proposition}
\begin{proof}
  It suffices to prove that:
  \[ \Supp(\Coh {\lfloor \mathcal{D} \rfloor} {A} \sigma) = \Supp(\Coh {\lfloor \mathcal{D} \sslash p \rfloor} {A \sub {\pi_p}} {\sigma \sslash p}) \]
  for \(\mathcal{D} : \Dyck_0\), \(p : \Peak_{\mathcal{D}}\), type \(A\), and substitution \(\sigma : \lfloor \mathcal{D} \rfloor \to \Gamma\), where \(\lfloor p \rfloor \sub \sigma\) is an identity and \(\Gamma \vdash_{\mathcal{R}} \Coh {\lfloor \mathcal{D} \rfloor} {A} \sigma : B\) for some \(B\). By inspection of the typing derivation we obtain an instance of the judgement \(\Gamma \vdash_{\mathcal{R}} \sigma : \lfloor \mathcal{D} \rfloor\), and so:
  \begin{align*}
    \Supp(\Coh {\lfloor \mathcal{D} \rfloor} {A} \sigma) &= \Supp(\sigma)\\
                                                         &= \Supp(\pi_p \bullet (\sigma \sslash p))&(*)\\
                                                         &= \Supp(\pi_p) \sub {\sigma \sslash p}\\
                                                         &= \Var{\lfloor \mathcal{D} \sslash p \rfloor} \sub {\sigma \sslash p}&\text{by \cref{lem:pi-bdry}}\\
                                                         &= \Supp(\sigma \sslash p) \\
                                                         &= \Supp(\Coh {\lfloor \mathcal{D} \sslash p \rfloor} {A \sub {\pi_p}} {\sigma \sslash p})
  \end{align*}
  where equality \((*)\) is derived by applying \cref{prop:supp-prop} to the equality
  \[\Gamma \vdash_{\mathcal{R}} \sigma = \pi_p \bullet (\sigma \sslash p)\]
  from \cref{prop:prune-ty}.
\end{proof}

To prove that the preservation condition holds, it is necessary to show that the type \(A \sub{\pi_p}\) created by pruning is a valid operation. This cannot be deduced from any of the conditions that been imposed on the operation set \(\mathcal{O}\) so far. Therefore, we introduce the following additional condition.

\begin{definition}
  An operation set \(\mathcal{O}\) \emph{supports pruning} if for all \(\mathcal{D} : \Dyck_0\), \(p : \Peak_{\mathcal{D}}\), and variable sets \(U,V \subseteq \Var(\lfloor \mathcal{D} \rfloor)\) we have:
  \[ (\lfloor \mathcal{D} \sslash p \rfloor, U \sub{\pi_p}, V \sub{\pi_p}) \in \mathcal{O} \]
  whenever \((\lfloor \mathcal{D} \rfloor, U , V) \in \mathcal{O}\).
\end{definition}

The globular operation set trivially supports pruning. Using \cref{lem:pi-bdry,prop:std-op}, it can be proved that the regular operation set supports pruning. We can now prove that the preservation condition holds.

\begin{proposition}
  \label{prop:prune-preserve}
  Let \(\mathcal{R}\) be a tame equality rule set and suppose the operation set \(\mathcal{O}\) supports pruning. Then the set \prune satisfies the \(\mathcal{R}\)-preservation condition.
\end{proposition}
\begin{proof}
  Let \(\mathcal{D} : \Dyck_d\) be a Dyck word and \(p : \Peak_{\mathcal{D}}\) be a peak of \(\mathcal{D}\). Further suppose \(\arr s A t : \Type_{\lfloor \mathcal{D} \rfloor}\), and \(\sigma : \lfloor \mathcal{D} \rfloor \to \Gamma\) such that \(\lfloor p \rfloor \sub \sigma\) is an identity and:
  \[ \Gamma \vdash_{\mathcal{R}} \Coh {\lfloor \mathcal{D} \rfloor} {\arr s A t} \sigma : B\]
  for some type \(B : \Type_\Gamma\). By inspection on this typing derivation we have:
  \[ \lfloor \mathcal{D} \rfloor \vdash_{\mathcal{R}} A \qquad \Gamma \vdash_{\mathcal{R}} \sigma \lfloor \mathcal{D} \rfloor \qquad (\lfloor \mathcal{D} \rfloor, \Supp(s), \Supp(t)) \in \mathcal{O} \qquad \Gamma \vdash_{\mathcal{R}} B = (\arr s A t) \sub \sigma\]
  and so by \cref{prop:prune-ty}, we have:
  \[\lfloor \mathcal{D} \sslash p \rfloor \vdash_{\mathcal{R}} \pi_p : \lfloor \mathcal{D} \rfloor \qquad \Gamma \vdash_{\mathcal{R}} \sigma \sslash p : \lfloor \mathcal{D} \sslash p \rfloor\]
  therefore, as \(\mathcal{O}\) supports pruning, the following judgement holds:
  \[\Gamma \vdash_{\mathcal{R}} \Coh {\lfloor \mathcal{D} \sslash p \rfloor} {(\arr s A t) \sub {\pi_p}} {\sigma \sslash p} : (\arr s A t) \sub {\pi_p} \sub {\sigma \sslash p}\]
  and so by applying the conversion rule, it suffices to show that
  \[ \Gamma \vdash_{\mathcal{R}} B = (\arr s A t) \sub {\pi_p} \sub {\sigma \sslash p}\]
  but this follows from the equality \(B = (\arr s A t) \sub \sigma\) and the equality \(\sigma = \pi_p \bullet (\sigma \sslash p)\) from \cref{prop:prune-ty}.
\end{proof}

We end this section with a property of pruning that will be required to prove confluence. Suppose we have a Dyck word \(\mathcal{D}\) and two distinct peaks \(p, q : \Peak_{\mathcal{D}}\). Then both peaks can be pruned from \(\mathcal{D}\) in either order. Consider the example below on the Dyck word from \cref{ex:dyck-peaks}.
\[
  \begin{tikzcd}[column sep = 0.7em, row sep = scriptsize, cells={inner sep = 0,shape=circle,anchor=center}, arrows={no head}]
	&&&&&&&&&&& \bullet \\
	&&&&&&&&&& \bullet && \bullet && |[color=blue]|\bullet \\
	&&&&&&&&& \bullet &&&& \bullet && \bullet \\
	&& |[color=red]|\bullet && \bullet &&&& |[color=red, rotate=35]|\mathclap{\rightsquigarrow} &&&&&&&& |[color=blue, rotate=-35]|\mathclap{\rightsquigarrow} && \bullet \\
	& \bullet && \bullet && \bullet && |[color=blue]|\bullet &&&&&&&&&& \bullet && \bullet \\
	\bullet &&&&&& \bullet && \bullet &&&&&&&& \bullet &&&& \bullet \\
	&&&&&&&& |[color=blue, rotate=-35]|\mathclap{\rightsquigarrow} &&& |[color=red]|\bullet && \bullet &&& |[color=red, rotate=35]|\mathclap{\rightsquigarrow} \\
	&&&&&&&&&& \bullet && \bullet && \bullet \\
	&&&&&&&&& \bullet &&&&&& \bullet
	\arrow[from=6-1, to=5-2]
	\arrow[color=red, from=5-2, to=4-3]
	\arrow[color=red, from=4-3, to=5-4]
	\arrow[from=5-4, to=4-5]
	\arrow[from=4-5, to=5-6]
	\arrow[from=5-6, to=6-7]
	\arrow[color=blue, from=6-7, to=5-8]
	\arrow[color=blue, from=5-8, to=6-9]
	\arrow[from=3-10, to=2-11]
	\arrow[from=2-11, to=1-12]
	\arrow[from=1-12, to=2-13]
	\arrow[from=2-13, to=3-14]
	\arrow[color=blue, from=3-14, to=2-15]
	\arrow[color=blue, from=2-15, to=3-16]
	\arrow[from=6-17, to=5-18]
	\arrow[from=5-18, to=4-19]
	\arrow[from=4-19, to=5-20]
	\arrow[from=5-20, to=6-21]
	\arrow[from=9-10, to=8-11]
	\arrow[color=red, from=8-11, to=7-12]
	\arrow[color=red, from=7-12, to=8-13]
	\arrow[from=8-13, to=7-14]
	\arrow[from=7-14, to=8-15]
	\arrow[from=8-15, to=9-16]
  \end{tikzcd}
\]
The following proposition proves that both peaks of the Dyck word can be pruned, and that the order in which this is done does not matter.

\begin{proposition}
  \label{prop:prune-conf}
  Suppose \(\mathcal{D} : \Dyck_d\) is a Dyck word and let \(p\) and \(q\) be two distinct peaks of \(\mathcal{D}\). Then there is a peak \(q_{p}\) of \(\mathcal{D} \sslash p\) such that:
  \[ \lfloor q_{p} \rfloor \equiv \lfloor q \rfloor \sub {\pi_{p}}\]
  and a similar peak \(p_{q}\) of \(\mathcal{D} \sslash q\). Furthermore, the following equations hold syntactically:
  \begin{mathpar}
    (\mathcal{D} \sslash p) \sslash q_{p} = (\mathcal{D} \sslash q) \sslash p_{q} \and
    \pi_p \bullet \pi_{q_p} \equiv \pi_q \bullet \pi_{p_q} \and
    (\sigma \sslash p) \sslash q_{p} = (\sigma \sslash q) \sslash p_{q}
  \end{mathpar}
  where the last equation holds for any \(\sigma : \lfloor \mathcal{D} \rfloor \to \Gamma\).
\end{proposition}
\begin{proof}
  All proofs proceed by a simultaneous induction on both the peaks \(p\) and \(q\), and are given in \module{Catt.Dyck.Pruning.Properties} in the formalisation. The construction of the peak \(q_p\) is given by the function \func{Catt.Dyck.Pruning.Properties}{prune-peak}, the equality \(\lfloor q_p \rfloor \equiv \lfloor q \rfloor \sub {\pi_p}\) is given by \func{Catt.Dyck.Pruning.Properties}{prune-peak-prop}, and the remaining three equations are given by \func{Catt.Dyck.Pruning.Properties}{prune-conf}, \funcn{Catt.Dyck.Pruning.Properties}{-conf}{\(\pi\)-conf}, and \func{Catt.Dyck.Pruning.Properties}{prune-sub-conf}.
\end{proof}

\section{Trees}
\label{sec:trees}

During the next sections we build up to defining the insertion operation. This operation performs larger modifications to pasting diagrams than the pruning operation, and we will again want to represent pasting diagrams in a different way to make the definition in \cref{sec:insertion} as natural as possible. It is well known that pasting diagrams correspond to planar rooted trees \cite{Weber2004,leinster2004higher,batanin1998monoidal}, which we will simply refer to as \emph{trees} and can be defined as follows.

\begin{definition}
  A \emph{tree} \(T : \Tree\) is inductively defined to be a (possibly empty) list of trees.
\end{definition}

Throughout this section we will make use of standard operations and notations for lists. A list that contains the elements \(x_i\) for \(i\) from \(0\) to \(n\) will be written in square bracket notation as \([x_0,x_1,x_2,\dots,x_n]\). Further, we use the notation \(\emp\) for the empty list and \(\doubleplus\) for the concatenation of lists, which is associative and has the empty list as its unit. We will use the Agda-like notation of writing \(n :: ns\) for a list for which the first element (the head) is \(n\) and the rest of the list (the tail) is \(ns\). The length of a list will be given by the operation \(\len\).

We will use the notation \(\Sigma(T) = [T]\), and call \(\Sigma(T)\) the suspension of \(T\), for reasons that will become immediate once the context generated by a tree has been defined in \cref{sec:tree-contexts}.

We note that it will be common to see expressions of the form \(S :: T\) where \(S\) and \(T\) are both trees. It may seem as if this was an error, and that a concatenation operation should have been given instead, but in this case we are exploiting the identification of trees and lists of trees to treat \(S\) as a tree (as an element of the list) and \(T\) as a list of trees.

We now define some common operations on trees.

\begin{definition}
\label{def:treetrunk}
The \emph{depth} of a tree \(\dep(T)\) is \(0\) if \(T\) is empty or \(1 + \max_k{\dep(T_k)}\) if \(T = [T_0,\dots,T_n]\). For a tree \(T\), its \emph{trunk height}, \(\th(T)\), is \(1 + \th(T_0)\) if \(T = [T_0]\) and \(0\) otherwise. A tree is \emph{linear} if its trunk height equals its depth.

Subtrees of a tree can be indexed by a list of natural numbers \(P\), giving a subtree \(T^P\) by letting \(T^{\emp} = T\) and \(T^{k::P} = {(T_k)}^P\) if \(T = [T_0, \dots, T_n]\).
\end{definition}



As these trees represent pasting diagrams, a context can be associated to each one. To be able to make effective use of trees we will need to understand this mapping to contexts, and the associated constructions used in this mapping. One of these constructions is suspension, which we have already seen. The second is an operation known as the wedge sum, which will be introduced in \cref{sec:wedge-sums}. Both these operations are mappings from contexts to contexts which preserve ps-context derivations. We will see in \cref{sec:tree-contexts} that a further result holds, that these two operations (along with the singleton context) are sufficient to generate all ps-contexts.

\begin{remark}
  In the formalisation, trees are defined in \module{Catt.Tree} and take a slightly different form to the trees defined above, and are actually defined to be a binary tree. This exploits an isomorphism between binary trees and trees with arbitrary (finite) branching. The constructors for the trees in the formalisation are called \(\mathsf{Sing}\), which stands for ``singleton'' and takes no arguments, and \(\mathsf{Join}\), which takes two trees as arguments. The isomorphism is generated from the following rules:
  \begin{mathpar}
    \inferrule{}{\mathsf{Sing} \simeq \emp}\and
    \inferrule{S \simeq S' \\ T \simeq T'}{\mathsf{Join}(S,T) \simeq S' :: T'}
  \end{mathpar}
  Presenting trees in this way in the formalisation allows any induction to be done as a single induction over the constructors of a tree, instead of simultaneously inducting on the depth of the tree and on lists. The retain the standard notation of trees for this text for simplicity of notation. Under the above isomorphism, this makes no difference to the formal development.
\end{remark}

\subsection{Wedge sums}
\label{sec:wedge-sums}

The wedge sum, just like suspension, is an operation inspired by a similar operation on topological spaces. Given two spaces \(X\) and \(Y\) and points \(x\) of \(X\) and \(y\) of \(Y\), the space \(X \vee Y\) can be formed, by taking the disjoint union of \(X\) and \(Y\), and identifying the points \(x\) and \(y\).

This construction satisfies a universal property: it is the colimit of the following diagram:
\begin{equation}
  \label[diagram]{diag:wedge-colimit}
  \begin{tikzcd}
    X && Y \\
    & {\{*\}}
    \arrow["x", from=2-2, to=1-1]
    \arrow["y"', from=2-2, to=1-3]
  \end{tikzcd}
\end{equation}
where the arrows labelled \(x\) and \(y\) send the unique point \(*\) to \(x\) and \(y\) respectively. Such a universal construction gives rise to two inclusions:
\[\inc_X : X \to X \vee Y \qquad \inc_Y : Y \to X \vee Y\]
A similar colimit can be formed in the syntactic category of \Cattr. Leveraging that the variables of a context are ordered, every (non-empty) context in \Catt is naturally bipointed. For a context \(\Gamma\), the first point is given by the first variable of the context (which must have type \(\star\)), which we name \(\fst(\Gamma)\), and the second point is given by the last \(0\)-dimensional variable in the context, which we name \(\snd(\Gamma)\). We therefore restrict the construction above to when the chosen point for the left context \(\Gamma\) is \(\fst(\Gamma)\) and the chosen point for the second context is \(\snd(\Delta)\). This simplifies the construction, and will be the only case we need for forming trees. We note that \(\fst(\Sigma(\Gamma)) \equiv N\) and \(\snd(\Sigma(\Gamma)) \equiv S\), as we will commonly take the wedge sums of suspended contexts.

\begin{definition}
  Let \(\Gamma\) and \(\Delta\) be non-empty contexts. We then mutually define the \emph{wedge sum} \(\Gamma \vee \Delta\) and inclusions \(\inc_\Gamma : \arr \Gamma \star {\Gamma \vee_t \Delta}\) and \(\inc_\Delta : \arr \Delta \star {\Gamma \vee \Delta}\) on the context \(\Delta\), noting that the base case is \(\Delta = (x : A)\) as \(\Delta\) is non-empty.
  \begin{align*}
    \Gamma \vee (x : A) &= \Gamma \\
    \Gamma \vee \Delta, (x : A) &= \Gamma \vee \Delta, (x : A \sub {\inc_\Delta})\\[10pt]
    \inc_\Gamma &= \wk^{n - 1}(\id_\Gamma) &\text{when \(\Delta\) has length \(n\)}\\[10pt]
    \inc_{(x : A)} &= \langle t \rangle\\
    \inc_{\Delta, (x : A)} &= \langle \wk(\inc_\Delta), x \rangle
  \end{align*}
  If we further have substitutions \(\sigma : \arr \Gamma A \Theta\) and \(\tau : \arr \Delta A \Theta\), then we can define the substitution \( \sigma \sqcup \tau : \arr {\Gamma \vee \Delta} A \Theta\) again by induction on \(\Delta\):
  \begin{align*}
    \sigma \vee \langle A, s \rangle &= \sigma\\
    \sigma \vee \langle \tau, s \rangle &= \langle \sigma, s \rangle
  \end{align*}
  We note that no extra property is needed to define this universal map, though to show it it well-formed we will need that \(\snd(\Gamma) \sub \sigma = \fst(\Delta) \sub \tau\).
\end{definition}

We firstly prove some basic properties required for \(\Gamma \vee \Delta\) to be the colimit of \cref{diag:wedge-colimit}.

\begin{lemma}
  \label{lem:wedge-sum-prop}
  Let \(\Gamma\) and \(\Delta\) be non-empty contexts. Then:
  \[ \inc_{\Gamma} \vee \inc_{\Delta} \equiv \id_{\Gamma \vee \Delta} \]
  Further, the following equations hold:
  \[ \inc_{\Gamma} \bullet (\sigma \vee \tau) \equiv \sigma \qquad \inc_{\Delta} \bullet (\sigma \vee \tau) \equiv \tau \]
  for substitutions \(\sigma : \arr \Gamma A \Theta\) and \(\tau : \arr \Delta A \Theta\) where the second equality requires that \(\snd(\Gamma) \sub \sigma \equiv \fst(\Delta) \sub \tau\). Lastly:
  \[ (\sigma \vee \tau) \bullet \mu \equiv (\sigma \bullet \mu) \vee (\tau \bullet \mu) \]
  where \(\mu : \arr \Theta B {\Theta'}\) is another substitution.
\end{lemma}
\begin{proof}
  Proofs appear as \func{Catt.Wedge.Properties}{sub-from-wedge-prop}, \func{Catt.Wedge.Properties}{sub-from-wedge-inc-left},  \func{Catt.Wedge.Properties}{sub-from-wedge-inc-right}, and \func{Catt.Wedge.Properties}{sub-from-wedge-sub} in \module{Catt.Wedge.Properties}.
\end{proof}

To simplify definitions of substitutions between wedge sums of contexts, we will write substitutions diagrammatically by specifying the individual components. Consider the following diagram:
% https://q.uiver.app/?q=WzAsNixbMCwyLCJcXFNpZ21hXFxHYW1tYSJdLFsxLDIsIlxcdmVlIl0sWzIsMiwiXFxTaWdtYSBcXERlbHRhIl0sWzAsMCwiXFxTaWdtYSBcXEdhbW1hJyJdLFsyLDAsIlxcU2lnbWFcXERlbHRhJyJdLFsxLDAsIlxcdmVlIl0sWzAsMywiXFxTaWdtYSBcXHNpZ21hIl0sWzIsNCwiXFxTaWdtYSBcXHRhdSJdXQ==
\[\begin{tikzcd}[column sep=tiny, row sep=10pt]
    {\Gamma'} & \vee & {\Delta'} &\vee &{\Theta'} \\
    \\
    \Gamma & \vee & \Delta &
    \arrow["{\sigma}", from=3-1, to=1-1, pos=.4]
    \arrow["{\tau}", from=3-3, to=1-3, pos=.4]
  \end{tikzcd}
\]
which is generated from substitutions \(\sigma : \Gamma \to \Gamma'\) and \(\tau : \Delta \to \Delta'\). A substitution \(\Gamma \vee \Delta \to \Gamma' \vee \Delta' \vee \Theta'\) can be generated by composing each arrow in the diagram with suitable inclusions so that its target is \(\Gamma' \vee \Delta' \vee \Theta'\), and then using the universal property of the wedge to map out of the source context. In the diagram above the generated substitution is:
\[ ((\sigma \bullet \inc_{\Gamma'}) \vee (\tau \bullet \inc_{\Delta'})) \bullet \inc_{\Gamma' \vee \Delta'} \]
To ensure these definitions are unique, the following proposition is needed:
\begin{proposition}
  The wedge sum \(\vee\) is associative and has the singleton context \((x : \star)\) as its left and right unit. Given a context \(\Gamma\), the inclusions satisfy the following unitality properties:
  \[ \inc_{\Gamma} : \Gamma \to \Gamma \vee (x : \star) \equiv \id_\Gamma \qquad \inc_{\Gamma} : \Gamma \to (x : \star) \vee \Gamma \equiv \id_\Gamma \]
  and given substitutions \(\sigma : \arr \Gamma A \Xi\), \(\tau : \arr \Delta A \Xi\), and \(\mu : \arr \Theta A \Xi\) we have:
  \[ (\sigma \vee \tau) \vee \mu \equiv \sigma \vee (\tau \vee \mu)\]
  There is a unique way of including each of the contexts \(\Gamma\), \(\Delta\), and \(\Theta\) into \(\Gamma \vee \Delta \vee \Theta\), that is there is a unique substitution \(\Gamma \to \Gamma \vee \Delta \vee \Theta\) which is built from a composite of inclusions and similarly for \(\Delta\) and \(\Theta\).
\end{proposition}
\begin{proof}
  The proofs of these are given in \module{Catt.Wedge.Properties}, and are all given by inducting on the right most context. The proof for the right unitality of \(\vee\) is omitted from the formalisation as it is immediate from the definitions.

  The uniqueness of inclusions substitutions is given by
  \begin{itemize}
  \item \func{Catt.Wedge.Properties}{wedge-inc-left-assoc}, which says:
    \begin{align*}
      \inc_{\Gamma} \bullet \inc_{\Gamma \vee \Delta} : \Gamma \to (\Gamma \vee \Delta) \vee \Theta &\equiv \inc_{\Gamma} : \Gamma \to \Gamma \vee (\Delta \vee \Theta)\\
      \intertext{\item \func{Catt.Wedge.Properties}{wedge-incs-assoc}, which says:}
      \inc_{\Delta} \bullet \inc_{\Gamma \vee \Delta} : \Delta \to (\Gamma \vee \Delta) \vee \Theta &\equiv \inc_{\Delta} \bullet \inc_{\Delta \vee \Theta} : \Delta \to \Gamma \vee (\Delta \vee \Theta)\\
      \intertext{\item \func{Catt.Wedge.Properties}{wedge-inc-right-assoc}, which says:}
      \inc_{\Theta} : \Theta \to (\Gamma \vee \Delta) \vee \Theta &\equiv \inc_{\Theta} \bullet \inc_{\Delta \vee \Theta} : \Theta \to \Gamma \vee (\Delta \vee \Theta)
    \end{align*}
  \end{itemize}
  We note that the definition of the wedge sum differs slightly in the formalisation, specifying a term \(t\) in \(\Gamma\) which takes the role of \(\snd(\Gamma)\), in order to give more computational control. By replacing the terms \(t\) in the formalisation by \(\snd(\Gamma)\) for the appropriate context \(\Gamma\), and noting that \(\snd(\Delta) \sub{\inc_{\Delta}} \equiv \snd(\Gamma \vee \Delta)\) (which can be proved by an easy induction), the results written here can be recovered.
\end{proof}

The previous proposition ensures that the diagrammatic notation for substitutions between wedge sums uniquely defines a substitution. We next show that all the constructions in this section have the expected typing properties.

\begin{lemma}
  \label{lem:wedge-typing}
  The following inference rules are admissible in \Cattr:
  \begin{mathpar}
    \inferrule{\Gamma \vdash \\ \Delta \vdash}{\Gamma \vee \Delta \vdash}\and
    \inferrule{ }{\Gamma \vee \Delta \vdash \inc_{\Gamma} : \Gamma}\and
    \inferrule{ }{\Gamma \vee \Delta \vdash \inc_{\Delta} : \Delta}\and
    \inferrule{\Theta \vdash \snd(\Gamma) \sub \sigma = \fst(\Delta) \sub \tau}{\Theta \vdash \inc_{\Delta} \bullet (\sigma \vee \tau) = \tau}\and
    \inferrule{\Theta \vdash \sigma : \Gamma \\ \Theta \vdash \tau : \Gamma \\ \Theta \vdash \snd(\Gamma) \sub \sigma = \fst(\Delta) \sub \tau}{\Theta \vdash \sigma \vee \tau : \Gamma \vee \Delta}\and
    \inferrule{\Theta \vdash \sigma = \sigma'\\ \Theta \vdash \tau = \tau'}{\Theta \vdash \sigma \vee \tau = \sigma' \vee \tau'}
  \end{mathpar}
\end{lemma}
\begin{proof}
  All proofs are given in \module{Catt.Wedge.Typing}.
\end{proof}

We finally show that the wedge sum preserves pasting diagrams, the property that wedge sums were initially introduced for.

\begin{proposition}
  \label{prop:wedge-ps}
  The wedge sum of two ps-contexts is a ps-context: If \(\Gamma \vdash_{\mathsf{ps}}\) and \(\Delta \vdash_{\mathsf{ps}}\), then \(\Gamma \vee \Delta \vdash_{\mathsf{ps}}\)
\end{proposition}
\begin{proof}
  It can first be proven that if the derivation \(\Gamma \vdash_{\mathsf{ps}}\) is generated by \(\Gamma \vdash_{\mathsf{ps}} x : \star\), then \(x \equiv \snd(\Gamma)\), by showing for all derivations \(\Gamma \vdash_{\mathsf{ps}} x : A \), where \(\dim(A) > 0\) that the \(0\)-target of the type \(A\) is \(\snd(\Gamma)\) by induction, and then case splitting on the original derivation. Then \(\Gamma \vdash_{\mathsf{ps}}\) implies that \(\Gamma \vdash_{\mathsf{ps}} \snd(\Gamma) : \star\).

  The statement of the proposition is then proven by induction on the following statement: If \(\Gamma \vdash_{\mathsf{ps}}\) and \(\Delta \vdash_{\mathsf{ps}} x : A\), then:
  \[ \Gamma \vee \Delta \vdash_{\mathsf{ps}} x \sub {\inc_{\Delta}} : A \sub {\inc_{\Delta}}\]
  The base case is given by the preceding paragraph, and the other cases follow from routine calculation.

  These proofs are given in \module{Catt.Wedge.Pasting}.
\end{proof}

We lastly give a version of the wedge sum construction for variable sets.

\begin{definition}
  Let \(\Gamma\) and \(\Delta\) be two non-empty contexts, and let \(U \subseteq \Var(\Gamma)\) and \(V \subseteq \Var(\Delta)\) be variable sets. Then define:
  \[U \vee V = U \sub {\inc_\Gamma} \cup V \sub {\inc_\Delta}\]
  to be a variable set of \(\Gamma \vee \Delta\).
\end{definition}

\subsection{Tree contexts}
\label{sec:tree-contexts}

We have now defined suspensions and wedge sums, and shown that both operations preserve ps-contexts. This allows us to finally define the context generated by a tree.

\begin{definition}
  For a tree \(T\), the context $\lfloor T \rfloor$ generated from it is defined recursively by:
    \[\lfloor \emp \rfloor = D^0 \qquad
    \lfloor [T_1,\dots,T_n] \rfloor = \bigvee\limits_{i = 1}^n \Sigma\lfloor T_i \rfloor\]
  It is immediate from this definition that \(\lfloor \Sigma(T) \rfloor \equiv \Sigma(\lfloor T \rfloor)\), \(\lfloor S \doubleplus T \rfloor \equiv \lfloor S \rfloor \vee \lfloor T \rfloor\), and that \(\dim(\lfloor T \rfloor) = \dep(T)\). We will commonly abuse notation and omit the \(\lfloor \_ \rfloor\) operator and use trees as contexts when it will not cause confusion.
\end{definition}

We can immediately give some examples of trees and their associated contexts. The context \(D^0\) is defined to be the context associated to \(\emp\),
and so as \(D^{n+1} \equiv \Sigma(D^n)\), all the disc contexts can easily be recovered from trees as \(D^n \equiv \lfloor \Sigma^n(\emp) \rfloor\). Each tree \(\Sigma^n(\emp)\) is linear and has depth \(n\).

Trees can also be drawn graphically as follows: For a tree \([T_1,\dots,T_n]\), first recursively draw the trees \(T_i\) and lay these out in a horizontal line. Then a single point is drawn underneath these subtrees which we call the root of the tree, and a line is and drawn between the root of the tree and the root of each subtree. An example is given in \cref{fig:tree-example}.

\begin{figure}[h]
  \centering
  \begin{tikzpicture}[every node/.style={scale=0.6},baseline=(x11.base)]
    \node [on grid](x01) {$\bullet$};
    \node [above left=0.5 and 0.3 of x01, on grid] (x11) {$\bullet$};
    \node [above left=0.5 and 0.25 of x11, on grid] (x21) {$\bullet$};
    \node [above right=0.5 and 0.25 of x11, on grid] (x22) {$\bullet$};
    \node [above right=0.5 and 0.3 of x01, on grid](x12) {$\bullet$};
    \draw (x01.center) to (x11.center);
    \draw (x01.center) to (x12.center);
    \draw (x11.center) to (x21.center);
    \draw (x11.center) to (x22.center);
  \end{tikzpicture}
  \qquad
  \begin{tikzcd}
    \bullet & \bullet & \bullet
    \arrow[""{name=0, anchor=center, inner sep=0}, curve={height=-30pt}, from=1-1, to=1-2]
    \arrow[""{name=1, anchor=center, inner sep=0}, curve={height=30pt}, from=1-1, to=1-2]
    \arrow[""{name=2, anchor=center, inner sep=0}, from=1-1, to=1-2]
    \arrow[from=1-2, to=1-3]
    \arrow[shorten <=4pt, shorten >=4pt, Rightarrow, from=1, to=2]
    \arrow[shorten <=4pt, shorten >=4pt, Rightarrow, from=2, to=0]
  \end{tikzcd}
  \caption{The tree \([[\emp,\emp],\emp]\) and generated context}
  \label{fig:tree-example}
\end{figure}

The context associated to a tree is clearly a pasting diagram, as the context is built only using the singleton context, wedge sums, and suspension. In fact, the set of contexts generated by trees is exactly the set containing the singleton context, and closed under wedge sums and suspensions. To see this define an \(S\)-monoid to be a monoid with an extra unary operation \(S\) with no other conditions on this operation. Then, the set of trees is the free \(S\)-monoid with the monoid structure given by concatenation and the \(S\) given by suspension. Similarly, the set of contexts is an \(S\)-monoid with the \(S\) again given by suspension and the monoid structure given by wedge sums. The map \(T \mapsto \lfloor T \rfloor\) is then an \(S\)-monoid homomorphism.

This means that the wedge sum of two trees \(S\) and \(T\) is can be defined to be the concatenation \(S \doubleplus T\), and the equality \(\lfloor S \doubleplus T \rfloor \equiv \lfloor S \rfloor \vee \lfloor T \rfloor\) follows from the associativity of wedge sums for contexts.

We will further see in \cref{sec:equiv-trees-dyck} that all pasting diagrams are generated by some tree, though this will not be needed for any formal development of our type theories.

We next introduces \emph{paths}, which can be thought of as the variables in a tree.

\begin{definition}
  Let \(T\) be a tree. \emph{Paths} \(p : \Path_T\) are non-empty lists of natural numbers of the form \(q \doubleplus [n]\) such that \(q\) indexes a subtree \(T^q\) of \(T\) and \(0 \leq n \leq \len(T^q) \).

  For path \(p : \Path_T\), we obtain a variable of \(\lfloor T \rfloor\) by recursion on \(p\) as follows:
  \begin{itemize}
  \item Suppose \(p = [n]\). Let \(T = [T_0,\dots,T_k]\). It is clear that \(\lfloor T \rfloor\) has exactly \(k+2\) variables of dimension \(0\), corresponding to (inclusion of) the first variable of each context \(\Sigma(\lfloor T_i \rfloor)\) as well as the variable corresponding to the inclusion of \(\snd(\Sigma(T_i))\). We then define \(\lfloor [n] \rfloor\) to be the \(n\)\textsuperscript{th} such variable, indexing from 0.
  \item Let \(p = k :: q\) and \(T = [T_0,\dots,T_k,\dots]\), where \(q\) is a path of \(T_k\). Then by recursion we have a variable \(\lfloor q \rfloor\) of \(\lfloor T_k \rfloor\). This gives a variable \(\Sigma(\lfloor q \rfloor)\) of \(\Sigma(\lfloor T_k \rfloor)\) which can be included into \(\lfloor T \rfloor\) by the appropriate inclusion to get \(\lfloor p \rfloor\).
  \end{itemize}
  We lastly define the set of \emph{maximal paths} \(\MaxPath_T\) of \(T\) to be paths \(p \doubleplus [0] \) such that \(T^p = \emp\). Such paths correspond to locally maximal variables of \(\lfloor T \rfloor\).
\end{definition}

We now turn our attention to substitutions from a tree context \(\sigma : \lfloor T \rfloor \to \Gamma\). A substitution can be viewed as a function from the variables of its source context to terms of the target context. Therefore a substitution \(\sigma : \lfloor T \rfloor \to \Gamma\) acts on variables of \(\lfloor T \rfloor\). However, we have seen that the more natural notion of a variable in a tree context is a path. This motivates the following definition.

\begin{definition}
  A term-labelling \(L : T \to \Gamma\) from a tree \(T\) to context \(\Gamma\) is a pair containing a function \(\Path_T \to \Term_\Gamma\) and a type of \(\Gamma\). To apply the function component of a labelling to a path \(p\), we write \(L(p)\) or \(L[x_0,x_1,\dots]\) for a path \([x_0,x_1,\dots]\). The type component of the labelling is given by \(\ty(L)\).

  If \(T = [T_0,\dots,T_n]\), then there are natural projections \( L_i :T_i \to \Gamma\) given by \(L_i(p) = L(i :: p)\) and \(\ty(L) = \arr {L[i]} {\ty(L)} {L[i+1]}\) for \(0 \leq i \leq n\).
\end{definition}

For labellings to play the role of substitutions, a substitution \(\lfloor L \rfloor : \arr {\lfloor T \rfloor} {\ty(L)} \Gamma\) will be defined for each term-labelling \(L : T \to \Gamma\). A natural way to define this substitution is by induction on the tree \(T\), which finally motivates the use of extended substitutions. Suppose we start with a labelling \(L : \arr {[T_0,\dots,T_n]} \star \Gamma\). To proceed, we will apply the inductive hypothesis to obtain a substitutions:
\[ \lfloor L_i \rfloor : \arr {\lfloor T_i \rfloor} {\arr {L[i]} {A} {L[i+1]}} {\Gamma} \]
These substitutions are not regular (non-extended) substitutions, even though \(L\) has associated type \(\star\), and hence corresponds to a regular substitution.

\begin{definition}
  Let \(L : T \to \Gamma\) be a term-labelling. We define the substitution:
  \[\lfloor L \rfloor : \arr {\lfloor T \rfloor} {\ty(L)} \Gamma\]
  by induction on the tree \(T\) as \(\langle \ty(L), L[0] \rangle\) if \(T = \emp\) and:
  \[ \unrestrict \lfloor L_0 \rfloor \vee \unrestrict \lfloor L_1 \rfloor \vee \cdots \vee \unrestrict \lfloor L_n \rfloor \]
  if \(T = [T_0, \dots, T_n]\). Although it looks like the \(0\)-dimensional terms in the labelling are not used to generate the substitution, they appear in the types of the labellings \(L_i\), and so appear in the unrestricted substitutions.
\end{definition}

There are many ways of giving a more syntactic presentation of labellings. Given a tree \(T = [T_0,\dots,T_n]\), a labelling \(L : T \to \Gamma\) can be written as:
\[ t_0\{L_0\}t_1\{L_1\}t_2\cdots t_n\{L_n\}t_{n+1} : \ty(L) \]
where each \(t_i\) is the term \(L[i]\) and the sublabellings \(L_i\) have been recursively put in this syntactic bracketing format. The syntactic presentation contains all the information of the original labelling, which can be recovered by letting \(L[i] = t_i\) for each \(i\), \(L[i :: p] = L_i(p)\).

As an example, take the tree \(T = [[\emp,\emp], \emp]\) from \cref{fig:tree-example}, and let:
\[\Gamma = (x : \star), (f : x \to x), (\alpha : f*f \to f)\]
Then we can define the labelling \(L : T \to \Gamma\) by:
\[ L = x\bigl\{f*f\{\alpha\}f\{\id(f)\}f\bigr\}x\{f\}x : \star \]
which sends the (maximal) paths \([0,0,0]\) to \(\alpha\), \([0,1,0]\) to \(\id(f)\), and \([1,0]\) to \(f\) and has associated substitution:
\[ \lfloor L \rfloor = \langle x,x,f*f,f,\alpha,f,\id(f),x,f \rangle\]
The curly brackets notation for labellings is used instead of a typical round bracket notation to avoid clashes with notations that already use round brackets, such as \(\id(f)\).

We finish this section by examining a boundary operation for trees. We have already seen that for every ps-context \(\Gamma\) and \(n \in \mathbb{N}\), there are the boundary variable sets:
\[\bdry n - \Gamma \qquad \bdry n + \Gamma\]
Since \(\lfloor T \rfloor\) is a ps-context for any tree \(T\), we immediately obtain such boundary variable sets for \(\lfloor T \rfloor\). However, by recalling the definitions for the wedge sum of variable sets given in \cref{sec:wedge-sums} and the suspension of a variable set given in \cref{sec:operation-properties}, a more natural definition can be given.

\begin{definition}
  For any tree \(T : \Tree\), dimension \(n \in \mathbb{N}\), and \(\epsilon \in \{-,+\}\), we define the boundary set:
  \[\bdry n \epsilon T\]
  by induction on \(n\) and \(T\). If \(n = 0\), then we define:
  \[\bdry 0 - T = \FV(\fst(\lfloor T \rfloor)) \qquad \bdry 0 + T = \FV(\snd(\lfloor T \rfloor))\]
  Now suppose \(n\) is not \(0\). If the tree \(T\) is the singleton tree, then \(\bdry n \epsilon T = \Var(\lfloor T \rfloor)\). Now suppose that \(T = [T_0,\dots,T_n]\). We then define:
  \[ \bdry n \epsilon T = \bdry {n-1} \epsilon {T_0} \vee \cdots \vee \bdry {n-1} \epsilon {T_n}\]
  with the boundary sets \(\bdry n \epsilon {T_i}\) obtained by inductive hypothesis.
\end{definition}

In the formalisation module \module{Catt.Tree.Support}, we prove that the boundary sets \(\bdry n \epsilon T\), the tree boundary, and \(\bdry n \epsilon {\lfloor T \rfloor}\), the ps-context boundary, coincide. Therefore:
\[ (\lfloor S \rfloor, \bdry n - T, \bdry n + T) \in \Std\]
for each \(n \geq \dep(S) - 1\).


\subsection{Equivalence of trees and Dyck words}
\label{sec:equiv-trees-dyck}

\todo[inline]{Mapping back from ps-context}

\section{Structured syntax}
\label{sec:structured-terms}

We now introduce a new class of syntax named \emph{structured syntax}. Terms over tree contexts are commonly built using several of the standard constructions we have seen so far, such as paths, labellings, suspensions, and inclusions. By recording which of these constructions was used in the formation of a term, these terms can compute more usefully, which we will exploit to prove more involved lemmas about insertion in \cref{sec:insertion}. Structured syntax will be our variation on the base syntax of \Catt which records these constructions.

The key problem with the base syntax for \Catt is that term-labellings are difficult to compose. We have so far considered term-labellings of the form \(L : T \to \Gamma\), where \(\Gamma\) is any arbitrary context, but there is no reason a labelling couldn't be of the form \(M : S \to \lfloor T \rfloor\) for trees \(S\) and \(T\). We would then hope to be able to compose these labellings to get a labelling of the form:
\[ M \bullet L : S \to \Gamma \]
Such a labelling would need to send a path \(p: \Path_S\) to a term of \(\Gamma\). The only reasonable way forward is to apply \(M\) to \(p\) to get a term of \(\lfloor T \rfloor\), and then applying \(\lfloor L \rfloor\) to this term to get a term of \(\Gamma\). Unfortunately, for an arbitrary term \(t : \Term_{\lfloor T \rfloor}\) and labelling \(L : T \to \Gamma\), the term:
\[ t \sub {\lfloor L \rfloor}\]
does not have nice computational properties. We examine two examples:
\begin{itemize}
\item Suppose \(t\) was of the form \(\lfloor p \rfloor\) for some path \(p\). We then have:
  \[ \lfloor p \rfloor \sub {\lfloor L \rfloor} \equiv L(p)\]
  and would hope that this syntactic equality would fall out immediately, and that the left hand side would reduce to the right hand side in the formalisation. This is not the case however, and proving that such a syntactic equality holds is non trivial.
\item Suppose \(t \equiv \Sigma(s)\) and \(L = a\{L_1\}b : A\). Similar to the above case we would hope that the syntactic equality:
  \[ \Sigma(s) \sub {\lfloor a\{L_1\}b : A \rfloor} \equiv s \sub {\lfloor L_1 \rfloor}\]
  holds ``on the nose''. This however is not the case.
\end{itemize}

Structured terms alleviates these problems by recording that such a term \(t\) was generated from a path or generated using suspension. This allows the application of a labelling to a structured term to use this information, for example letting the two syntactic equalities above to hold by definition. If a labelling is the ``correct'' notion of substitution from a tree, then a structured term is the ``correct'' notion of term in a tree.

\begin{definition}
  Let \(\U\) be a member of \(\Ctx \uplus \Tree\), either some context \(\Gamma\) or some tree \(T\). We then define the \emph{structured syntax} classes \(\STerm_\U\) of \emph{structured terms}, \(\SType_\U\) of \emph{structured types}, and \emph{(\(\STerm\)-)labellings} \(\arr S A \U\) for some tree \(S\) and structured type \(A\). These syntax classes for structured terms and types are generated by the following rules:
  \begin{mathpar}
    \inferrule{p : \Path_T}{\SPath(p) : \STerm_T}\and
    \inferrule{s : \STerm_{T_i}\\ 0 \leq i \leq n}{\Inc_i(s) : \STerm_{[T_0,\dots,T_n]}} \and
    \inferrule{S : \Tree\\ A : \SType_S \\ L : S \to \U}{\SCoh S A L : \STerm_\U}\and
    \inferrule{t : \Term_\Gamma}{\SOther(t) : \STerm_\Gamma} \\
    \inferrule{ }{\star : \SType_\U}\and
    \inferrule{s : \STerm_\U \\ A : \SType_\U \\ t: \STerm_\U}{\arr s A t : \SType_\U}
  \end{mathpar}
  Labellings \(L : S \to \U\) are defined as pairs of a function \(\Path_S \to \STerm_\U\) and structured type, similarly to term-labellings in \cref{sec:tree-contexts}. We note that the syntax for structured types is shared with the syntax for \Catt types, and will be careful to make it clear which syntax we are using when necessary.
\end{definition}

Each piece of structured syntax can be converted back into the base syntax of \Catt, using many of the constructions already introduced.

\begin{definition}
  Suppose \(\U : \Ctx \uplus \Tree\). Define \(\lfloor \U \rfloor\) to be \(\Gamma\) if \(\U = \Gamma\) for some context \(\Gamma\) or \(\lfloor T \rfloor\) if \(\U = T\) for some tree \(T\). Now, for a structured term \(s : \STerm_\U\), a structured type \(A : \SType_\U\), or a labelling \(L : S \to \U\), we define:
  \[ \lfloor s \rfloor : \Term_{\lfloor \U \rfloor} \qquad \lfloor A \rfloor : \Type_{\lfloor \U \rfloor} \qquad \lfloor L \rfloor : \arr {\lfloor S \rfloor} {\lfloor \ty(L) \rfloor} {\lfloor \U \rfloor} \]
  by the equations:
  \begin{align*}
    \lfloor \SPath(p) \rfloor &= \lfloor p \rfloor\\
    \lfloor \Inc_i(s) \rfloor &= \Sigma(\lfloor s \rfloor) \sub {\inc_{\lfloor T_i \rfloor}}&\text{if }s : \STerm_{[T_0,\dots,T_n]}\\
    \lfloor \SCoh S A L \rfloor &= \Coh {\lfloor S \rfloor} {\lfloor A \rfloor} {\id_{\lfloor S \rfloor}} \sub {\lfloor L \rfloor}\\
    \lfloor \SOther(t) \rfloor &= t\\[10pt]
    \lfloor \star \rfloor &= \star\\
    \lfloor \arr s A t \rfloor &= \arr {\lfloor s \rfloor} {\lfloor A \rfloor} {\lfloor t \rfloor}
  \end{align*}
  and by defining \(\lfloor L \rfloor\) similarly to term labellings except \(\lfloor L \rfloor = \langle \lfloor \ty(L) \rfloor, \lfloor L[0] \rfloor \rangle\) for labellings \(L : {\emp} \to {\U}\) from the singleton tree. We refer to \(\lfloor a \rfloor\), \(\lfloor A \rfloor\) and \(\lfloor L \rfloor\) as the term, type, or substitution generated by \(a\),\(A\), or \(L\).
\end{definition}

For any tree \(T\), there is an \emph{identity labelling} \(\id_T\) given by:
\[ \id_T(p) = \SPath(p) \qquad \ty(\id_T) = \star\]
The function \func{Catt.Tree.Structured.Properties}{id-label-to-sub} in the formalisation (see \module{Catt.Tree.Structured.Properties}) shows that:
\[\lfloor \id_T \rfloor = \id_{\lfloor T \rfloor}\]

The main motivation for introducing structured syntax was to be able to define a composition of labellings, which we do now by defining the application of a labelling to a structured term, structured type, or another labelling.

\begin{definition}
  Let \(L : T \to \U\) be a labelling (with \(\U : \Ctx \uplus \Tree\)). We define the application of \(L\) to a structured term \(s : \STerm_{T}\), a structured type \(A : \SType_T\), and a labelling \(M : S \to T\) to give:
  \[ s \sub L : \STerm_\U \qquad A \sub L : \SType_\U \qquad M \bullet L : S \to \U\]
  These definitions are given by mutual recursion:
  \begin{align*}
    \SPath(p) \sub L &= L(p)\\
    \Inc_i(s) \sub L &= s \sub {L_i}\\
    \SCoh S A M \sub L &= \SCoh S A {M \bullet L}\\
    \SOther(t) \sub L &= t \sub {\lfloor L \rfloor}\\[10pt]
    \star \sub L &= B\\
    (\arr s A t) \sub L &= \arr {s \sub L} {A \sub L} {t \sub L}\\[10pt]
    (M \bullet L)(p) &= M(p) \sub L\\
    \ty(M \bullet L) &= \ty(M) \sub L
  \end{align*}
  It can easily be seen that these definitions satisfy the computational properties given at the start of the section.
\end{definition}

The main theorem of this section is that the application of a labelling to a structured term is compatible with the map from structured syntax to \Catt syntax.

\begin{theorem}
  \label{thm:structured-main}
  For any labelling \(L : T \to \U\) and structured term \(s : \STerm_T\), structured type \(A : \SType_T\), or labelling \(M : S \to T\), we have:
  \[ \lfloor s \sub L \rfloor \equiv \lfloor s \rfloor \sub {\lfloor L \rfloor} \qquad \lfloor A \sub L \rfloor \equiv \lfloor A \rfloor \sub {\lfloor L \rfloor} \qquad \lfloor M \bullet L \rfloor \equiv \lfloor M \rfloor \bullet \lfloor L \rfloor\]
\end{theorem}
\begin{proof}
  We proceed by proving all statements by mutual induction. Suppose \(s : \STerm_T\) is a structured term. We split on the form of \(s\):
  \begin{itemize}
  \item Suppose \(s\) is of the form \(\SCoh S A M\). Then \(s \sub L\) is \(\SCoh S A {M \bullet L}\) and so the required statement follows from the inductive hypothesis for labellings.
  \item Suppose \(s\) is of the form \(\SOther(t)\). Then \(\lfloor s \sub L \rfloor \equiv \lfloor \SOther (t \sub {\lfloor L \rfloor}) \rfloor \equiv t \sub {\lfloor L \rfloor} \equiv \lfloor s \rfloor \sub {\lfloor L \rfloor}\).
  \item Suppose \(T = [T_0,\dots, T_n]\) and \(s\) is of the form \(\Inc_i(t)\). Then:
    \begin{align*}
      \lfloor \Inc_i(t) \rfloor \sub {\lfloor L \rfloor} &\equiv \Sigma(t)\sub {\inc_{\lfloor T_i \rfloor}} \sub {\unrestrict \lfloor L_0 \rfloor \vee \cdots \vee \unrestrict \lfloor L_n \rfloor}\\
                                                         &\equiv \Sigma(t)\sub {\inc_{\lfloor T_i \rfloor} \bullet (\unrestrict \lfloor L_0 \rfloor \vee \cdots \vee \unrestrict \lfloor L_n \rfloor)}\\
                                                         &\equiv \Sigma(t) \sub {\unrestrict \lfloor L_i \rfloor} &\text{by \cref{lem:wedge-sum-prop}}\\
                                                         &\equiv \lfloor t \rfloor \sub {\lfloor L_i \rfloor}\\
                                                         &\equiv \lfloor t \sub {L_i} \rfloor &\text{by inductive hypothesis}\\
                                                         &\equiv \lfloor \Inc_i(t) \sub L \rfloor
    \end{align*}
  \item Suppose \(s\) is of the form \(\SPath(p)\). Then if \(\lfloor p \rfloor\) is not a \(0\)-dimensional variable, then an argument similar to the preceding case can be made. If instead \(\lfloor p \rfloor\) is of the form \([k]\) and \(T = [T_0,\dots,T_n]\) then first suppose that \(k < n + 1\) such that \(\lfloor [k] \rfloor \equiv \fst(\lfloor T_k \rfloor) \sub {\inc_{\lfloor T_k \rfloor}}\). Then:
    \begin{align*}
      \lfloor [k] \rfloor \lfloor L \rfloor &\equiv \fst(\lfloor T_k \rfloor) \sub {\inc_{\lfloor T_k \rfloor}} \sub {\lfloor \unrestrict \lfloor L_0 \rfloor \vee \cdots \vee \unrestrict \lfloor L_n \rfloor \rfloor}\\
                                            &\equiv \fst(\lfloor T_k \rfloor) \sub {\unrestrict \lfloor L_k \rfloor}\\
      &= \lfloor L[k] \rfloor
    \end{align*}
    where the last equality follows from the labelling \(L_k\) having type component \(\ty(L_k) \equiv \arr {\lfloor L[k] \rfloor} {B} {\lfloor L[k+1] \rfloor}\). The case where \(k = n+1\) is similar to above using \(\snd(T_n)\) instead of \(\fst(T_k)\) (as there is no tree \(T_k\) in this case).
  \end{itemize}

  The case for structured types follows by a simple induction using the case for terms. We now consider the case for a label \(M : S \to T\). Suppose \(S = [S_0,\dots,S_n]\). Then:
  \begin{align*}
    \lfloor M \rfloor \bullet \lfloor L \rfloor &\equiv \left( \bigvee_i \unrestrict \lfloor M_i \rfloor  \right) \bullet \lfloor L \rfloor\\
                                                &\equiv \bigvee_i \unrestrict \lfloor M_i \rfloor \bullet \lfloor L \rfloor&\text{by \cref{lem:wedge-sum-prop}}\\
    &\equiv \bigvee_i \unrestrict \left(\lfloor M_i \rfloor \bullet \lfloor L \rfloor\right)\\
                                                &\equiv \bigvee_i \unrestrict \lfloor M_i \bullet L \rfloor&\text{by inductive hypothesis}\\
    &\equiv \lfloor M \bullet L \rfloor
  \end{align*}
  with the last line following from \((M \bullet L)_i\) and \(M_i \bullet L\) being the same labelling. This concludes all cases.
\end{proof}

Structured syntax is only used as computational aid for reasoning about the base syntax of \Catt, and therefore the desired notion of ``syntactic'' equality of structured syntax is syntactic equality of the underlying \Catt terms, that is we say \(s \equiv t\) for structured terms \(s\) and \(t\) exactly when \(\lfloor s \rfloor \equiv \lfloor t \rfloor\). On labellings \(L, M : T \to \U\) we can instead provide the equality:
\[ L \equiv M \iff \ty(L) \equiv \ty(M) \land \forall (p : \Path_T).\ L(p) \equiv L(p)\]
and by observing the proof of \cref{thm:structured-main}, we see that this equality implies equality of the generated substitutions.

It is therefore possible to derive many properties for this equality of structured terms simply by reducing all constructions used to the corresponding \Catt constructions, and using the corresponding result for the syntax of \Catt.

\begin{proposition}
  Composition of labellings is associative and has a left and right unit given by the identity labelling.
\end{proposition}
\begin{proof}
  Follows immediately from \cref{thm:structured-main}, the identity labelling generating the identity substitution, and the corresponding results for \Catt.
\end{proof}

Using this technique, every syntactic result about \Catt can be transported to structured syntax. Further, it is easy to prove that the equality relation is preserved by each constructor, for example if \(L \equiv M\) and \(A \equiv B\), then \(\SCoh S A L \equiv \SCoh A B M\).

To extend this, we redefine some of the constructions we have seen for \Catt in the previous sections, this time for structured terms.

\begin{definition}
  We define the suspension for a structured term \(a : \STerm_\U\), structured type \(A : \STerm_\U\), and restricted substitution for a labelling \(L : T \to \U\), giving structured term \(\Sigma(a) : \STerm_{\Sigma(\U)}\), structured type \(\Sigma(A) : \STerm_{\Sigma(\U)}\), and labelling \(\Sigma'(L) : T \to {\Sigma(\U)}\). These are all defined by mutual induction as follows:
  \begin{align*}
    \Sigma(a) &\equiv \Inc_0(a) &\text{if \(\U\) is a tree}\\
    \Sigma(\SCoh S A M) &\equiv \SCoh S A {\Sigma'(M)}&\text{if \(\U\) is a context}\\
    \Sigma(\SOther(t))&\equiv \SOther(\Sigma(t))\\[10pt]
    \Sigma(\star) &= \arr N \star S&\text{if \(\U\) is a context}\\
    \Sigma(\star) &= \arr {\SPath[0]} \star {\SPath[1]}&\text{otherwise}\\
    \Sigma(\arr s A t) &= \arr {\Sigma(s)} {\Sigma(A)} {\Sigma(t)}\\[10pt]
    \Sigma'(L)(p) &= \Sigma(L(p))\\
    \ty(\Sigma'(L)) &= \Sigma(\ty(L))
  \end{align*}
  We further define an unrestriction operation that takes a labelling of the form \(M : T \to \U\)  with \(\ty(M) \equiv \arr s A t\) and produces a labelling
  \[\unrestrict M : {\Sigma(T)} \to \U \equiv s\{M\}t : A\]
  This can be used to define the full suspension of a labelling as with \Catt substitutions by defining \(\Sigma(L)\) to be \(\unrestrict \Sigma'(L)\).
\end{definition}

A simple case analysis demonstrates that these constructions commute with \(\lfloor \_ \rfloor\). They therefore inherit the properties of the suspension on \Catt terms, types, and substitutions. We lastly recover wedge sums for structured syntax.

\begin{definition}
  We have seen that the wedge sum of trees \(S\) and \(T\) is given by \(S \doubleplus T\). Letting \(S = [S_0,\dots,S_m]\) and \(T = [T_0,\dots,T_n]\), we further define inclusion labellings:
  \[ \inc_S : S \to {S \doubleplus T} \qquad \inc_T : T \to {S \doubleplus T}\]
  by the equations:
  \begin{align*}
    \inc_S([k])&\equiv \SPath[k] & \inc_S(k :: p) &\equiv \SPath(k :: p) & \ty(\inc_S) &\equiv \star\\
    \inc_T([k])&\equiv \SPath[m + k] & \inc_T(k :: p) &\equiv \SPath (m + k :: p) & \ty(\inc_T) &\equiv \star
  \end{align*}
  and finally, we suppose \(L : S \to \U\) and \(M : T \to \U\) are labellings of the form:
  \[ L \equiv s_0\{L_0\}s_1\cdots s_n\{L_n\}t_0 : A \qquad M \equiv t_0\{M_0\}t_1\cdots t_n\{M_n\}t_{n+1} : A \]
  and define their concatenation to be the labelling:
  \[ s_0\{L_0\}s_1\cdots s_n\{L_n\}t_0\{M_0\}t_1\cdots t_n\{M_n\}t_{n+1} : A \]
  where \(L \doubleplus M : {S \doubleplus T} \to \U\).
\end{definition}

Many properties of these constructions among others are given in the formalisation module \module{Catt.Tree.Structured.Construct.Properties}. In particular, the diagrammatic notation for substitutions between wedge sums can be repurposed to define labellings, which will be used to define certain labellings in \cref{sec:insertion}.

It will be useful to be able to interpret all \Catt syntax as structured syntax. For terms such a mapping is trivially given by the \(\SOther\) constructor. For a type \(A\), a structured type \(\lceil A \rceil\) can be formed by a simple induction, applying the \(\SOther\) constructor to each term in the type. For substitutions, we give the following definition.

\begin{definition}
  Let \(\sigma : \lfloor S \rfloor \to_A \Gamma\) be a substitution. We then define the labelling:
  \[ \lceil \sigma \rceil : S \to \Gamma \]
  by \(\lceil \sigma \rceil(p) = \SOther(\lfloor p \rfloor \sub \sigma)\) and \(\ty(\lceil \sigma \rceil) = \lceil A \rceil\).
\end{definition}

This construction is an inverse to taking generating a substitution from a labelling.

\begin{proposition}
  Let \(\sigma : \lfloor S \rfloor \to_A \Gamma\) be a substitution. Then \(\lfloor \lceil \sigma \rceil \rfloor \equiv \sigma\). Further, for any labelling \(L : S \to \Gamma\), \(\lceil \lfloor L \rfloor \rceil \equiv L\).
\end{proposition}
\begin{proof}
  We note that every variable of \(\lfloor S \rfloor\) is given by \(\lfloor p \rfloor\) for some path \(p\). We then have the equality:
  \begin{equation*}
    \lfloor p \rfloor \sub {\lfloor \lceil \sigma \rceil \rfloor} \equiv \lfloor p \sub {\lceil \sigma \rceil} \rfloor \equiv \lfloor \SOther(\lfloor p \rfloor \sub \sigma) \rfloor \equiv \lfloor p \rfloor \sub \sigma
  \end{equation*}
  and so \(\sigma\) and \(\lfloor \lceil \sigma \rceil \rfloor\) have the same action on each variable and so are equal.

  Letting \(L : S \to \Gamma\) be a labelling. Then for any path \(p\):
  \[ \lceil \lfloor L \rfloor \rceil(p) \equiv \SOther(\lfloor p \rfloor \sub {\lfloor L \rfloor}) \equiv \SOther(\lfloor L(p) \rfloor) \]
  and so \(\lfloor \lceil \lfloor L \rfloor \rceil(p) \rfloor \equiv \lfloor L(p) \rfloor\). Therefore \(L \equiv \lceil \lfloor L \rfloor \rceil\) by definition.
\end{proof}

\subsection{Typing and equality}
\label{sec:typing-struct-terms}

Similarly to the definition of syntactic equality for structured syntax, we also want the equality rules for structured terms and structured types to be inherited from the equality relations on their generated terms, and so define:
\[ \U \vdash s = t \iff \lfloor \U \rfloor \vdash \lfloor s \rfloor = \lfloor t \rfloor \qquad \U \vdash A = B \iff \lfloor \U \rfloor \vdash \lfloor A \rfloor = \lfloor B \rfloor\]

For labellings, (definitional) equality can be defined similarly to the syntactic equality relation:
\[ \U \vdash L = M \iff \U \vdash \ty(L) = \ty(M) \land \forall (p : \Path_T).\ \U \vdash L(p) = L(p)\]
Using \cref{lem:wedge-typing}, it can be proven by a simple induction that equality of labellings (along with equality of their associated types) induces equality of the generated substitutions.

We also want the typing rules for \(s : \STerm_\U\) and \(A : \SType_\U\) to be inherited from the typing rules for \(\lfloor s \rfloor\) and \(\lfloor A \rfloor\). We reuse the notation for each typing judgement. For labellings, we introduce the following more natural typing judgement:

\begin{definition}
  For a labelling \(L : T \to \U\), where \(\U : \Ctx \uplus \Tree\), we define the judgement:
  \[ \U \vdash L : T \]
  to mean that the labelling \(L\) is well-formed. This judgement is generated by the following rule:
  \begin{mathpar}
    \inferrule{\U \vdash L[0] : \ty(L)\quad \cdots\quad \U\vdash L[n+1] : \ty(L)\\\U\vdash L_0 : T_0\quad \cdots\quad\U\vdash L_n : T_n}{\U \vdash L : [T_0,\dots,T_n]}
  \end{mathpar}
\end{definition}

Paths \(p\) can be equipped with a canonical structured type, \(\ty(p)\), as follows:
\begin{itemize}
\item For paths \([k]\), \(\ty([k]) = \star\),
\item For paths \(k :: p\) where \(p\) is a path, the type \(\ty(k :: p)\) is obtained by taking the type \(\ty(p)\), applying \(\Inc_k\) to each term, and replacing the \(\star\) type at its base by the type \(\arr {\SPath[k]} {\star} {\SPath[k+1]}\).
\end{itemize}
This can be used to prove that the identity labelling is well-formed.
\begin{proposition}
  Let \(S\) be a tree. Then \(S \vdash \id_S : S\).
\end{proposition}
\begin{proof}
  Let \(x\) be a list that indexes a subtree of \(S\), and define the labelling \(\mathsf{subtree}(x) : S^x \to x\) by \(\ty(\mathsf{subtree}(x)) = \ty(x \doubleplus [0])\) and \(\mathsf{subtree}(x)(p) = \SPath(x \doubleplus p)\).

  We then prove the more general result that \(S \vdash \mathsf{subtree}(x) : S^x\) for each \(x\), with the desired result following from the case \(x = \emp\). If \(S^x = \emp\), then the typing judgement follows from \(S \vdash S^x[0] : \ty(S^x[0])\).

  If \(S^x = [T_0, \dots, T_n]\) then we must show that \(S \vdash S^x[k] : \ty(S^x[0])\), which follows from the observation that \(\ty(S^x[0]) \equiv \ty(S^x[i])\) for any \(i\) as the definition does not use the last element of the path. We are also required to show that \(S \vdash S^x_i : T_i\), but \(T_i \equiv S^{x \doubleplus [i]}\) and \(S^x_i \equiv S^{x \doubleplus [i]}\), and so this follows from inductive hypothesis.
\end{proof}

From this typing judgement for labellings, one can obtain a derivation of the typing judgement for the generated substitution.

\begin{proposition}
  Let \(L : T \to \U\), and suppose \(\U \vdash L : T\) and \(\U \vdash \ty(L)\). Then:
  \[ \lfloor \U \rfloor \vdash \lfloor L \rfloor : \lfloor T \rfloor\]
\end{proposition}
\begin{proof}
  We induct on the tree \(T\), splitting into cases on whether it is empty. If it is, then by case analysis on the judgement for label typing we get:
  \[ \U \vdash L[0] : \ty(L) \]
  Then, \(\lfloor L \rfloor \equiv \langle \lfloor A \rfloor, \lfloor L[0] \rfloor \rangle\), and so the following derivation can be obtained:
  \[
    \begin{prooftree}
      \infer0{\U \vdash A}
      \infer1{\lfloor \U \rfloor \vdash \lfloor A \rfloor}
      \infer1{\lfloor \U \rfloor \vdash \langle \lfloor A \rfloor \rangle : \emptyset}
      \infer0{\U \vdash L[0] : A}
      \infer1{\lfloor \U \rfloor \vdash \lfloor L[0] \rfloor : \lfloor A \rfloor}
      \infer2{\lfloor \U \rfloor \vdash \langle \lfloor A \rfloor, \lfloor L[0] \rfloor \rangle : \lfloor \emp \rfloor}
    \end{prooftree}
  \]

  Suppose instead that \(T = [T_0,\dots,T_n]\), such that:
  \[ \lfloor L \rfloor \equiv \unrestrict \lfloor L_0 \rfloor \vee \cdots \vee \unrestrict \lfloor L_n \rfloor\]
  From \(\U \vdash L : T\), we obtain \(\U \vdash L_i : T_i\) for each \(i \in \{0,\dots,n\}\). We further obtain \(\U \vdash L[k] : \ty(L)\) for \(0 \leq k \leq n+1\) and so:
  \[\ty(L_i) \equiv \arr {L[i]} {\ty(L)} {L[i+1]}\]
  is well-formed and so by inductive hypothesis we have \(\lfloor \U \rfloor \vdash \lfloor L_i \rfloor : \lfloor T_i \rfloor\). We have for each \(i\) that \(\lfloor \ty(L) \rfloor\) is not the type \(\star\) and so the unrestriction \(\unrestrict \lfloor L_i \rfloor\) is well-formed. Furthermore, by construction of the unrestriction we have:
  \[ \fst(\lfloor T_i \rfloor) \sub {\lfloor L_i \rfloor} \equiv \lfloor L[i] \rfloor \qquad \snd(\lfloor T_i \rfloor) \sub {\lfloor L_i \rfloor} \equiv \lfloor L[i+ 1] \rfloor\]
  and so by \cref{lem:wedge-typing}, the wedge sums are well-formed, completing the proof.
\end{proof}

It can be shown that the reverse implication also holds: if \(\lfloor \U \rfloor \vdash \lfloor L \rfloor : \lfloor T \rfloor\) then \(\U \vdash L : T\). This follows as a corollary from the following proposition.

\begin{proposition}
  Let \(\sigma : \arr {\lfloor T \rfloor} A \Gamma\) be a substitution with \(\Gamma \vdash \sigma : \lfloor S \rfloor\). Then for any \(L : S \to T\) we have:
  \[T \vdash L : S \implies \Gamma \vdash L \bullet \lceil \sigma \rceil : S\]
  and hence \(\Gamma \vdash \lceil  \sigma \rceil : T\) follows from letting \(L\) be the identity labelling.
\end{proposition}
\begin{proof}
  Let \(S = [S_0, \dots, S_n]\) (where we allow this list to be empty). By the definition of the typing for a labelling, it suffices to show that for each \(0 \leq i \leq n\) and \(0 \leq k \leq n + 1\) that:
  \[ S \vdash L[k] \bullet \lceil \sigma \rceil : \ty(L) \sub {\lceil \sigma \rceil} \qquad S \vdash (L \bullet \lceil \sigma \rceil)_i : S_i\]
  The second typing judgement follows directly from inductive hypothesis, as \((L \bullet \lceil \sigma \rceil)_i \equiv L_i \bullet \lceil \sigma \rceil\). By definition of typing for structured terms, the first judgement requires us to prove that:
  \[ \lfloor S \rfloor \vdash \lfloor L[k] \bullet \lceil \sigma \rceil \rfloor : \lfloor \ty(L) \sub {\lceil \sigma \rceil} \rfloor\]
  which is equivalent to:
  \[ \lfloor  S \rfloor \vdash \lfloor L[k] \rfloor \sub \sigma : \lfloor \ty(L) \rfloor \sub \sigma\]
  and so follows from typing being preserved by substitution.
\end{proof}



By these results, many of the properties enjoyed by the typing judgements in \Cattr with a tame rule set \(\mathcal{R}\) also apply to the typing judgements for structured terms.

The module \module{Catt.Tree.Structured.Typing.Properties} also introduces many functions for constructing the typing judgements for structured syntax. One such function is \func{Catt.Tree.Structured.Typing.Properties}{TySCoh}, which represents the admissibility of the following rule:
\begin{equation}
  \label[rule]{rule:scoh}
  \inferrule{S \vdash \arr s A t \\ \U \vdash L : S \\ \U \vdash \ty(L) \\ (\lfloor S \rfloor, \Supp(s), \Supp(t)) \in \mathcal{O}}{\U \vdash \SCoh S {\arr s A t} L}
\end{equation}
In keeping with the theme of this section, one could define \(\Supp(s)\) as \(\Supp(\lfloor s \rfloor)\) for a structured term \(s : \STerm_\U\). However, we choose not to do this, instead giving a definition of support for structured syntax that leverages the extra information available in the syntax.

\begin{definition}
  For a path \(p : \Path_T\), a structured term \(s : \STerm_\U\), a structured type \(A : \SType_\U\), and a labelling \(L : S \to \U\), we define their supports \(\Supp(p)\), \(\Supp(s)\), \(\Supp(A)\), and \(\Supp(L)\) by mutual recursion:
  \begin{align*}
    \Supp([n]) &= \{\lfloor [0] \rfloor\}\\
    \Supp(k :: p) &= \Sigma(\Supp(p)) \sub {\inc_{T_k}} &\text{where }T = [T_1,\dots,T_n]\\[10pt]
    \Supp(\SPath(p)) &= \Supp(p)\\
    \Supp(\Inc_i(s)) &= \Sigma(\Supp(s)) \sub {\inc_{T_k}}&\text{where }T = [T_1,\dots,T_n]\\
    \Supp(\SCoh S A L) &= \Supp(L) \cup \Supp(\ty(L))\\
    \Supp(\SOther(t)) &= \Supp(t)\\[10pt]
    \Supp(\star) &= \emptyset\\
    \Supp(\arr s A t) &= \Supp(s) \cup \Supp(A) \cup \Supp(t)\\
    \Supp(L) &= \bigcup_{i=0}^{n+1} \Supp(L[i]) \cup \bigcup_{i=0}^n\Supp(L_i)
  \end{align*}
\end{definition}

We note that each of these support definitions is naturally downwards closed, and there is no need to apply a downwards closure operator as was necessary for the support of \Catt syntax. By some routine calculations given in the formalisation module \module{Catt.Tree.Structured.Support}, these support definitions are equivalent to taking the support of the generated piece of syntax. More precisely, the equations:
\begin{mathpar}
  \Supp(p) = \Supp(\lfloor p \rfloor) \and \Supp(s) = \Supp(\lfloor s \rfloor) \and \Supp(A) = \Supp(\lfloor A \rfloor) \and \Supp(L) \cup \Supp(\ty(L)) = \Supp(\lfloor L \rfloor)
\end{mathpar}
for path \(p\), structured term \(s\), structured type \(A\), and labelling \(L\).

By using this notion of support, we are able to avoid a lot of ``boilerplate'' proof. The above definition of support more closely resembles the format of structured terms, and without this definition, most proofs concerning the support of a structured term would begin by simplifying a variable set similar to \(\Supp(\lfloor s \rfloor)\) to one more similar to \(\Supp(s)\). Here, we instead give this equivalence proof once.

We end this section by giving alternative equality relations for labellings, which encapsulate the idea that a substitution is fully determined by where it sends locally maximal variables. These equalities are defined as follows for labellings \(L : T \to \U\) and \(M : T \to \U\):
\begin{align*}
  L \equiv^{\max} M &\iff \forall (p : \MaxPath_T).\ L(p) \equiv M(p)\\
  \U \vdash L =^{\max} M &\iff \forall (p : \MaxPath_T).\ L(p) \equiv M(p)
\end{align*}
and define two labels to be equal exactly when their action on maximal paths is equal. The following theorem gives conditions for when the standard equality equality relation can be recovered from these.

\begin{theorem}
  Let \(L : S \to \U\) and \(M : S \to \U\) be labellings. Then the following rules are admissible:
  \begin{mathpar}
    \inferrule{\U \vdash L : S\\ \U \vdash M : S \\ L \equiv^{\max} M}{\U \vdash L = M}\and
    \inferrule{\U \vdash L : S\\ \U \vdash M : S \\ L \equiv^{\max} M}{\U \vdash \ty(L) = \ty(M)}
  \end{mathpar}
  If the equality rule set \(\mathcal{R}\) satisfies the preservation and support conditions, then the rules above are still admissible with \(\U \vdash L =^{\max} M\) replacing the syntactic equalities.
\end{theorem}
\begin{proof}
  We prove the results for the syntactic equality, with the results for the definitional equality following similarly, but using the preservation property instead of uniqueness of typing. We proceed by induction on the tree \(S\), proving the admissibility of both rules simultaneously.

  First suppose that \(S = \emp\). Then the path \([0] : \Path_{\emp}\) is maximal and so \(\U \vdash L = M\) follows by the reflexivity of equality. The second rule follows from the uniqueness of typing, as we get \(\U \vdash L[0] : \ty(L)\) and \(\U \vdash M[0] : \ty(M)\) from the premises.

  Now suppose that \(S = [S_0,\dots,S_n]\). By inductive hypothesis, the following judgements hold for each \(i \in \{0,\dots,n\}\):
  \[ \U \vdash L_i = M_i \qquad \U \vdash \arr {L[i]} {\ty(L)} {L[i+1]} = \arr {M[i]} {\ty(M)} {M[i+1]}\]
  From the equalities on types, we immediately get that \(\U \vdash \ty(L) = \ty(M)\) as is required for the admissibility of the second rule, and also get that \(\U \vdash L[i] = M[i]\) for each \(0 \leq i \leq n+1\), which along with equality on (sub-)labellings above is sufficient to prove that:
  \[ \U \vdash L = M\]
  which witnesses the admissibility of the first rule.
\end{proof}

\subsection{Standard coherences}
\label{sec:standard-coherences}

In \cref{sec:background}, we gave a preliminary definition of standard coherences, a definition of a canonical coherence over a given pasting diagram. This diagram relies on inclusion substitutions from the boundary of a pasting diagram into its source and target variables, whose definition for ps-contexts can be unpleasant to work with.

In contrast, the \(n\)-boundary of a tree and its associated source and target inclusions have a natural definition by induction on the tree, where the source and target inclusions are given by labellings. We give this definition below.

\begin{definition}
  Given dimension \(n \in \mathbb{N}\) and \(T : \Tree\), we define the \emph{\(n\)-boundary} of the tree \(\bound n T : \Tree\) by induction on \(n\) and \(T\):
  \begin{equation*}
    \bound 0 T = \emp \qquad
    \bound {n + 1} {[T_0, \dots, T_n]} = [\bound n {T_0}, \dots , \bound n {T_n}]
  \end{equation*}
  We further define path-to-path functions \(\incbdpath n \epsilon T : \bound n T \to T\) for \(\epsilon \in \{-,+\}\) by induction:
  \begin{align*}
    \incbdpath 0 - T ([0]) &= [0]\\
    \incbdpath 0 + {[T_0, \dots, T_m]} ([0]) &= [m+1]\\
    \incbdpath {n+1} \epsilon {[T_0, \dots, T_m]} ([k]) &= [k]\\
    \incbdpath {n+1} \epsilon {[T_0,\dots, T_m]} (k :: p) &= [k :: \incbdpath {n+1} \epsilon {T_k} (p)]
  \end{align*}
  and then can define the \emph{source inclusion labelling} \(\incbd n + T : {\bound n T} \to T\) and \emph{target inclusion labelling} \(\incbd n + T : {\bound n T} \to T\) by:
  \[\incbd n \epsilon T(p) = \SPath(\incbdpath n \epsilon T(p)) \qquad \ty(\incbd n \epsilon T) = \star\]
  for each \(n\) and \(\epsilon \in \{-,+\}\).
\end{definition}

In the module \module{Catt.Tree.Boundary.Typing}, it is proven that:
\[ T \vdash \incbd n \epsilon T : \bound n T\]
for all trees \(T\), \(n \in \mathbb{N}\), and \(\epsilon \in \{-,+\}\).

In \cref{sec:background}, the source and target variable sets were defined to be support of the source and target inclusions. This can now be justified by the following lemma.

\begin{lemma}
  For a dimension \(n \in \mathbb{N}\), \(T : \Tree\), and \(\epsilon \in \{-,+\}\) we have:
  \[ \Supp(\incbd n \epsilon T) = \bdry n \epsilon T \]
\end{lemma}
\begin{proof}
  The proof is given by the function \func{Catt.Tree.Boundary.Support}{tree-inc-label-supp} in the formalisation module \module{Catt.Tree.Boundary.Support} and proceeds by induction on \(n\) and \(T\).
\end{proof}

This definition also allows simple inductive proofs that the boundary inclusions satisfy the globularity conditions, which we state in the following proposition. These proofs are given in the formalisation module \module{Catt.Tree.Boundary.Properties}.

\begin{proposition}
  \label{prop:bdry-glob}
  Let \(n \leq m\) and let \(T\) be a tree. Then:
  \[ \bound n {\bound m T} \equiv \bound n T\]
  Further, for \(\epsilon, \omega \in \{-,+\}\) we have:
  \[ \incbd n \epsilon {\bound m T} \bullet \incbd m \omega T \equiv \incbd n \epsilon T \]
  If instead \(n \geq \dep(T)\), then \(\bound n T \equiv T\) and \(\incbd n \epsilon T \equiv \id_T\).
\end{proposition}

Further, these constructions commute with suspension: \(\Sigma(\bound n T) \equiv \bound {n+1} {\Sigma(T)}\) and \(\Sigma(\incbd n \epsilon T) \equiv \incbd {n+1} \epsilon {\Sigma(T)}\) by definition.

We now recall the definitions of standard type, standard coherence, and standard term for a tree \(T\), which are given by mutual induction:
\begin{itemize}
\item The \emph{standard type}, \(\stdty T n\), is an \(n\)-dimensional type where each component of the type is given by the standard term over the appropriate boundary of the tree \(T\), and then included back into \(T\) by applying the inclusion labelling.
\item The \emph{standard coherence}, \(\stdcoh T n\), is the canonical dimension \(n\) coherence term over a tree \(T\). It is formed by a single coherence constructor over \(T\) with type given by the standard type, \(\stdty T n\).
\item The \emph{standard term}, \(\stdtm T n\), is a variation on the standard coherence which does not introduce unnecessary unary composites. If \(T\) is linear (and so represents a disc context), and \(n = \dep(T)\), then \(\stdtm T n\) is simply given by the unique maximal path in \(T\). Otherwise, it is given by the standard coherence \(\stdcoh T n\).
\end{itemize}

At the end of \cref{sec:background} it was stated that \(\Sigma(\stdtm T n) \equiv \stdtm {\Sigma(T)} {n + 1}\). Using this, the standard term can instead be defined by letting \(\stdtm \emp 0\) be \(\SPath([0])\), \(\stdtm {\Sigma(T)} {n+1}\) be \(\Sigma(\stdtm T n)\), and \(\stdtm T n\) be \(\stdcoh T n\) otherwise, which avoids the case split on the linearity of \(T\). We now define all three constructions formally using structured syntax.

\begin{definition}
  We define the \(n\)-dimensional \emph{standard type} over a tree \(T\) as a structured type \(\stdty T n : \SType_T\), and the \(n\)-dimensional \emph{standard coherence} and \emph{standard term} over a tree \(T\) as structured terms \(\stdcoh T n, \stdtm T n : \STerm_T\) by mutual induction:
  \begin{align*}
    \stdty T 0 &= \star\\
    \stdty T {n + 1} &= \arr {\stdtm {\bound n T} n \sub {\incbd {n + 1} - T}} {\stdty T n} {\stdtm {\bound n T} n \sub {\incbd {n+1} + T}}\\[10pt]
    \stdcoh T n &= \SCoh T {\stdty T n} {\id_T}\\[10pt]
    \stdtm T n &=
                 \begin{cases*}
                   \SPath([0])&if \(T = \emp\) and \(n = 0\)\\
                   \Inc_0(\stdtm {T_0} {n-1})&if \(n \neq 0\) and \(T = [T_0]\)\\
                   \stdcoh T n&\text{otherwise}
                 \end{cases*}
  \end{align*}
  when \(n = \dep(T)\), we call the standard coherence \(\stdcoh T n\) the \emph{standard composite} of \(T\).
\end{definition}

We can immediately show that these standard construct commute with suspension.

\begin{lemma}
  \label{lem:std-susp}
  For tree \(T\) and \(n \in \mathbb{N}\), \(\Sigma(\stdty T n) \equiv \stdty {\Sigma(T)} {n+1}\) and \(\Sigma(\stdcoh T n) \equiv \stdcoh {\Sigma(T)} {n+1}\).
\end{lemma}
\begin{proof}
  We first consider the standard type. The case for \(n = 0\) follows immediately, so we let \(n > 0\). We then get for \(\epsilon \in \{-,+\}\):
  \begin{align*}
    \Sigma\left(\stdtm {\bound {n-1} T} {n-1} \sub {\incbd {n-1} \epsilon T}\right) &\equiv \Sigma(\stdtm {\bound {n-1} T} {n-1}) \sub {\Sigma(\incbd{n-1} \epsilon T)}&\text{by functoriality of suspension}\\
                                                                         &\equiv \stdtm {\Sigma(\bound {n-1} T)} {n} \sub {\Sigma(\incbd{n-1} \epsilon T)}\\
    &\equiv \stdtm {\bound n {\Sigma(T)}} n \sub {\incbd n \epsilon {\Sigma(T)}}
  \end{align*}
  By inductive hypothesis \(\Sigma(\stdty T {n-1}) \equiv \stdty {\Sigma(T)} n\) and so
  \begin{align*}
    \Sigma(\stdty T n) &\equiv \arr {\Sigma\left(\stdtm {\bound {n-1} T} {n-1} \sub {\incbd {n-1} - T}\right)} {\Sigma(\stdty T {n-1})} {\Sigma\left(\stdtm {\bound {n-1} T} {n-1} \sub {\incbd {n-1} + T}\right)}\\
                       &\equiv \arr {\stdtm {\bound n {\Sigma(T)}} {n} \sub {\incbd n - {\Sigma(T)}}} {\stdty {\Sigma(T)} {n}} {\stdtm {\bound n {\Sigma(T)}} {n} \sub {\incbd n + {\Sigma(T)}}}\\
    &\equiv \stdty {\Sigma(T)} {n + 1}
  \end{align*}
  as required.

  For the standard coherence we have:
  \[ \Sigma(\stdcoh T n) \equiv \SCoh {\Sigma(T)} {\Sigma(\stdty T n)} {\Sigma(\id_T)} \equiv \SCoh {\Sigma(T)} {\stdty {\Sigma(T)} {n+1}} {\id_{\Sigma(T)}} \equiv \stdcoh {\Sigma(T)} {n+1}\]
  following from the case for types.
\end{proof}

To prove that the standard constructions are well typed, we give a couple of lemmas. The first concerns the support of the standard term and standard coherence.

\begin{lemma}
  \label{lem:std-supp}
  For a tree \(T\), dimension \(n \in \mathbb{N}\), and \(\epsilon \in \{-,+\}\), we have:
  \[ \Supp\left(\stdtm {\bound n T} n \sub {\incbd n \epsilon T}\right) = \bdry n \epsilon T \qquad \Supp\left(\stdcoh {\bound n T} n \sub {\incbd n \epsilon T}\right) = \bdry n \epsilon T\]
\end{lemma}
\begin{proof}
  The case for coherences follows from the definition and the equality
  \[\Supp(\incbd n \epsilon T) = \bdry n \epsilon T\]
  For the standard term, it suffices to consider cases where the standard term and standard coherence are not equal. If \(n = 0\), then \(\bound n T \equiv \emp\), and it suffices to prove that \(\Supp([m]) = \FV(\lfloor [m] \rfloor)\), but this is immediate because \(\Supp([m]) = \Supp(\lfloor [m] \rfloor)\) and \(\lfloor [m] \rfloor\) is a variable of type \(\star\) so its support is equal to its free variables.

  We therefore consider the case where \(n > 0\) and \(\len(\bound n T) = 1\). The only case where this happens is if \(\len(T) = 1\) too, so assume \(T \equiv [T_0]\)
  \begin{align*}
    \Supp\left(\stdtm {\bound n T} n \sub {\incbd n \epsilon T} \right) &= \Supp\left(\stdtm {\Sigma(\bound {n-1} {T_0})} n \sub {\Sigma\left(\incbd {n-1} \epsilon {T_0}\right)}  \right)\\
                                                                        &= \Supp\left(\Sigma\left( \stdtm {\bound {n-1} {T_0}} {n - 1} \right) \sub {\Sigma\left(\incbd {n-1} \epsilon {T_0}\right)}  \right)\\
                                                                        &= \Supp\left(\Sigma\left( \stdtm {\bound {n-1} {T_0}} {n - 1} \sub {\incbd {n-1} \epsilon {T_0}} \right) \right)\\
                                                                        &= \Sigma\left(\Supp\left( \stdtm {\bound {n-1} {T_0}} {n - 1} \sub {\incbd {n-1} \epsilon {T_0}} \right) \right)\\
                                                                        &= \Sigma\left( \bdry {n-1} \epsilon {T_0} \right)\\
                       &= \bdry n \epsilon T
  \end{align*}
  as required.
\end{proof}

The second lemma gives a globularity condition for the standard type.

\begin{lemma}
  \label{lem:std-type-glob}
  Let \(T\) be a tree. Then:
  \[ \stdty T n \equiv \stdty {\bound m T} n \sub {\incbd m \epsilon T}\]
  for \(n \leq m\) and \(\epsilon \in \{-,+\}\).
\end{lemma}
\begin{proof}
  We induct on \(n\). If \(n = 0\) then both sides of the equation are the type \(\star\). We therefore consider the case for \(n + 1\) and so we must prove:
  \begin{align*}
    \stdty T {n+1} &\equiv \arr {\stdtm {\bound n T} n \sub {\incbd n - T}} {\stdty T k} {\stdtm {\bound n T} n \sub {\incbd n + T}}\\
               &\equiv  \arr {\stdtm {\bound n {\bound m T}} n \sub {\incbd n - {\bound m T}} \sub {\incbd m \epsilon T}} {\stdty {\bound m T} n \sub {\incbd m \epsilon T}} {\stdtm {\bound n {\bound m T}} n \sub {\incbd n + {\bound m T}} \sub {\incbd m \epsilon T}}\\
    &\equiv \stdty {\bound m T} {n+1} \sub {\incbd m \epsilon T}
  \end{align*}
  The equality \({\stdty T n} \equiv {\stdty {\bound m T} n \sub {\incbd m \epsilon T}}\) follows by inductive hypothesis. Further, for \(\omega \in \{-,+\}\) we have by \cref{prop:bdry-glob}:
  \begin{align*}
    \stdtm {\bound n {\bound m T}} n \sub {\incbd n \omega {\bound m T}} \sub {\incbd n \epsilon T} &\equiv \stdtm {\bound n {\bound m T}} n \sub {\incbd n \omega {\bound m T} \bullet \incbd m \epsilon T} \\
    &\equiv \stdtm {\bound n T} n \sub {\incbd n - T}
  \end{align*}
  which completes the proof.
\end{proof}

We can now finally state and prove the typing properties of standard constructions.

\begin{proposition}
  \label{prop:standard-typing}
  Suppose that \(\mathcal{O}\) contains the standard operations. Then the following rules are admissible:
  \begin{mathpar}
    \inferrule{T : \Tree\\ n \in \mathbb{N}}{T \vdash \stdty T n}\and
    \inferrule{T : \Tree \\ n \neq 0\\ n \geq \dep(T)}{T \vdash \stdcoh T n : \stdty T n}\and
    \inferrule{T : \Tree \\ n \geq \dep(T)}{T \vdash \stdtm T n : \stdty T n}
  \end{mathpar}
\end{proposition}
\begin{proof}
  We prove that all three rules are admissible by mutual induction. First consider the cases for types. The case when \(n = 0\) is trivial, so we consider the case for \(n + 1\). We need to show that:
  \[ T \vdash \arr {\stdtm {\bound n T} n \sub {\incbd n - T}} {\stdty n T} {\stdtm {\bound n T} n \sub {\incbd n + T}}\]
  The inductive hypothesis on types gives that \(T \vdash \stdty n T\) and so we must show that:
  \[ T \vdash {\stdtm {\bound n T} n \sub {\incbd n \epsilon T}} : \stdty n T\]
  for \(\epsilon \in \{-,+\}\). By inductive hypothesis for terms, we have \(\bound n T \vdash \stdtm {\bound n T} n : \stdty {\bound n T} n\) as we have \(\dep(\bound n T) \leq n\). As \(T \vdash \incbd n \epsilon T : \bound n T\) we have that:
  \[ T \vdash {\stdtm {\bound n T} n \sub {\incbd n \epsilon T}} : \stdty {\bound n T} n \sub {\incbd n \epsilon T} \]
  and so by \cref{lem:std-type-glob}, this case is complete.

  For the standard coherence, we apply \cref{rule:scoh}, using the inductive hypothesis for types. To show that \((T, \src(\stdty T n), \tgt(\stdty T n)) \in \mathcal{O}\), we apply \cref{lem:std-supp}.

  For the standard term, like previous proofs it is sufficient to consider the cases where it is defined differently to the standard coherence. For \(n = 0\) we must have \(T = \emp\) by the condition on the depth of \(T\). Hence \(\stdtm T n \equiv [0]\) which is well-formed as has type \(\star \equiv \stdty T n\) as required.

  We now consider \(\stdtm {\Sigma(T)} {n+1} \equiv \Sigma (\stdtm T n)\). By inductive hypothesis on dimension, \(T \vdash \stdtm T n : \stdty T n\) and so we immediately have that:
  \[ \Sigma(T) \vdash \stdtm {\Sigma(T)} {n + 1} : \Sigma(\stdty T n)\]
  and so the proof is complete by \cref{lem:std-supp}.
\end{proof}

The equality relations we have seen so far make heavy use of disc contexts and associated terms and types. We therefore pause to consider the form of these as structured syntax and to relate them to the standard constructions presented in this section.

All disc contexts are the result of applying iterated suspensions to the singleton context, and so it follows that disc contexts correspond exactly to linear trees. By an abuse of notation we write:
\[ D^n = \Sigma^n(\emp)\]
As we further have that \(\Sigma(U^n) \equiv U^{n+1}\) for the sphere type \(U^n\), it can be proved for a simple induction that:
\[U^n \equiv \lfloor \stdty {D^n} n \rfloor\]
As we have already noted, the maximal dimension term \(d_n : \Term_{D^n}\) is given by \(\lfloor \stdtm {D^n} n \rfloor\). It is also equal to the unique maximal path, \(p^n = \Sigma^n[0]\), which is the list containing \(n+1\) zeros.

The only missing construction is an equivalent for the substitution from a disc context. From a structured term \(s : \STerm_\U\) of type \(A : \SType_\U\), there should be a labelling \(\{A,s\}\) from \(D^n\) to \(\U\). This however proves more challenging to define as trees and types have opposite inductive structure. For a labelling, it is natural to specify the lowest dimensional terms first and fill in higher dimensional terms by induction, though when deconstruction a type, we first receive the highest dimensional terms, only receiving the lower dimensional terms by further deconstructing the type.

To define the labelling \(\{A,t\}\), we define the extension of labelling from a linear tree, which allows us to add higher dimensional terms to the labelling, and use this to define the labelling from a linear tree.

\begin{definition}
  Let \(L : D^n \to \U\) be a labelling from a linear tree, and let \(s,t : \STerm_\U\) be structured terms. The \emph{extension} of \(L\) by \(s\) and \(t\), \(\ext(L,s,t)\), is defined inductively on \(n\) by:
  \begin{equation*}
    \ty(\ext(L,s,t)) = \ty(L) \qquad \ext(L,s,t) =
    \begin{cases*}
      L[0]\,\{t\}\,s &if \(n = 0\)\\
      L[0]\,\{\ext(L_0,s,t)\}\,L[1]&otherwise
    \end{cases*}
  \end{equation*}
  We then define the labelling \(\{A,t\}\) by induction on \(A\):
  \[ \{\star,t\} = (p \mapsto t) \qquad \{\arr s A t, u\} = \ext(\{A,s\},t,u) \qquad \ty(\{A,t\}) = \star\]
\end{definition}

These constructions all satisfy the expected typing judgements. More precisely the following inference rules are admissible:
\begin{mathpar}
  \inferrule{\U \vdash L : D^n\\ \U \vdash s : \stdty {D^n} n \sub L\\ \U \vdash t : \arr {p^n \sub L} {\stdty {D^n} n \sub L} {s}}{\U \vdash \ext(L,s,t) : D^{n+1}}\\
  \inferrule{\U \vdash A \\ \U \vdash t : A}{\U \vdash \{A,t\} : D^{\dim(A)}}
\end{mathpar}
The admissibility of the above rules is routine to verify.

Using these construction, we can recover structured term definitions of the unary composite of a (structured) term \(t\) of type \(A\) of dimension \(n\) as \( \stdcoh {D^n} n \sub {\{A,t\}}\) and can define the identity of the same term \(t\) as \(\stdcoh {D^n} {n+1} \sub {\{A,t\}}\). Therefore, the rules for disc removal and endo-coherence removal can be rephrased in terms of structured syntax to get the following rules:
\begin{mathpar}
  \inferrule{\U : \Ctx \uplus \Tree\\ \U \vdash A \\ \U \vdash t : A \\ \dim(A) = n > 0}{ \U \vdash \stdcoh {D^n} n \sub {\{A,t\}} = t}\textsc{dr'}\\
  \inferrule{\U : \Ctx \uplus \Tree\\ T : \Tree \\ L : \arr S \star \U\\ n = \dim(A)\\\\ T \vdash A \\ T \vdash s : A \\ \Supp(s) = \Var(T) \\ \U \vdash L : T}{\U \vdash \SCoh T {\arr s A s} L = \stdcoh {D^n} {n+1} \sub { \{A, s\} \bullet L}}\textsc{ecr'}
\end{mathpar}
which are admissible if the equality rule set \(\mathcal{R}\) has disc removal or endo-coherence removal respectively.

We end this section with two further results that can be proven in the presence of disc removal and endo-coherence removal. The first states that disc removal is sufficient (and necessary) to unify standard coherences and standard terms.

\begin{theorem}
  The tame equality rule set \(\mathcal{R}\) has disc removal if and only if the rule:
  \begin{mathpar}
    \inferrule{T : \Tree \\ n \in \mathbb{N}\\ n \geq \dep(T) > 0}{T \vdash \stdcoh T n = \stdtm T n}
  \end{mathpar}
  is admissible.
 \end{theorem}
\begin{proof}
  We note that \(\stdcoh T n\) and \(\stdtm T n\) only differ when \(T = D^n\). If \(\mathcal{R}\) has disc removal, then for each \(n \neq 0\) we have \(\stdcoh {D^n} n = \SPath(p^n) \equiv \stdtm {D^n} n\). Conversely, if \(\stdcoh T n = \stdtm T n\) when \(n > 0\) or \(\dep(T) > 0\), then \(\stdcoh {D^n} n = \stdtm {D^n} n\) for any \(n > 0\). Then as \(\mathcal{R}\) is tame, we can apply the substitution \(\{A,t\}\) to both sides of the equation to get the statement of disc removal.
\end{proof}

Lastly, under the presence of endo-coherence removal, the standard coherences \(\stdtm T n\) for which \(n > \dep(T)\) can be shown to be equal to identities.

\begin{theorem}
  Suppose the equality rule set \(\mathcal{R}\) has endo-coherence removal. Let \(T\) be a tree and suppose \(n \geq \dep(T)\). Then:
  \[ T \vdash \stdcoh T {n+1} = \stdcoh {D^n} {n+1} \sub {\{\stdty T n, \stdtm T n\}} \]
\end{theorem}
\begin{proof}
  The following chain of equalities hold:
  \begin{align*}
    \stdcoh T {n+1} &\equiv \SCoh T {\arr {\stdtm {\bound n T} n \sub {\incbd n T -}} {\stdty T n} {\stdtm {\bound n T} n \sub {\incbd n T +}}} {\id_S}\\
                    &\equiv \SCoh T {\arr {\stdtm T n} {\stdty T n} {\stdtm T n}} {\id_S}&\text{by \cref{prop:bdry-glob}}\\
                    &= \stdcoh {D^n} {n+1} \sub {\{\stdty T n, \stdtm T n\}}&\text{by \textsc{ecr'}}
  \end{align*}
  where \textsc{ecr'} can be applied as \(\Supp(\stdtm T n) = \Var(\lfloor T \rfloor)\) by \cref{lem:std-supp}.
\end{proof}

Due to these two theorems, every standard term \(\stdtm T n\) with \(n \geq \dep(T)\) is equal to either the unique variable of the singleton context (when \(n = \dep(T) = 0\)), a standard composite (when \(n = \dep(T) > 0\)) or an identity (when \(n > \dep(T)\)), hence completely classifying the well-formed standard terms.

\section{Insertion}
\label{sec:insertion}

We now introduce \emph{insertion}, the construction that powers the strictly associative behaviour of \Cattsua. Insertion incorporates part of the structure of an locally maximal argument term into the head coherence, simplifying the overall syntax of the term.

Consider the composite \(f * (g * h)\). This term has two locally maximal arguments, \(f\) and \(g \cdot h\), the second of which is a (standard) coherence. Insertion allows us to merge these two composites into one by ``inserting'' the pasting diagram of the inner coherence into the pasting diagram of the outer coherence. In the case above we will get that the term \(f * (g * h)\) is equal to the ternary composite \(f * g * h\), a term with a single coherence. As the term \((f * g) * h\) also reduces by insertion to the ternary composite, we see that both sides of the associator become equal under insertion. The action of insertion on these contexts is shown in \cref{fig:insertion}.

\begin{figure}
$$
\begin{aligned}
\begin{tikzpicture}
\node (x) at (0,0)  {$x$};
\node (y) at (1.5,0) {$y$};
\node (z) at (3,0) {$z$};
\draw [->] (x) to node [above, font=\small] {$f$} (y);
\draw [->] (y) to node [above, font=\small] {$g*h$} (z);
\begin{scope}[xshift=1.25cm, yshift=1.75cm, red]
%\draw [fill=red!10, draw=none] (1,0.05) ellipse (1.2cm and .6cm);
\draw [rounded corners, fill=red!7, draw=none] (-.25,-.35) rectangle +(2.5,1);
\node (x2) at (0,0)  {$x'$};
\node (y2) at (1,0) {$y'$};
\node (z2) at (2,0) {$z'$};
\draw [->] (x2) to node [above, font=\small] {$g$} (y2);
\draw [->] (y2) to node [above, font=\small] {$h$} (z2);
\end{scope}
\draw [->, thick, red] (2.25,1.25) to +(0,-.5);
\end{tikzpicture}
\end{aligned}
\quad\leadsto\quad
\begin{aligned}
\begin{tikzpicture}
\node (x) at (0,0)  {$x \vphantom'$};
\node [red] (y) at (1,0) {$x'$};
\node [red] (z) at (2,0) {$y'$};
\node [red] (w) at (3,0) {$z'$};
\begin{scope}[xshift=.5cm, yshift=1.5cm, red]
\draw [rounded corners, fill=white, draw=none] (-.25,-.35) rectangle +(2.5,1);
\end{scope}
\draw [->] (x) to node [above, font=\small] {$f$} (y);
\draw [->, red] (y) to node [above, font=\small] {$g$} (z);
\draw [->, red] (z) to node [above, font=\small] {$h$} (w);
\end{tikzpicture}
\end{aligned}
$$
\caption{\label{fig:insertion}
Insertion acting on the composite \(f * (g * h)\)}
\end{figure}

Insertion is an operation that is best understood with respect to trees instead of ps-contexts. Insertion merges the structure of two trees along a \emph{branch} of the first tree.

\begin{definition}
  Let \(S\) be a tree. A \emph{branch} of \(S\) is a non-empty list of natural numbers \(P\) which indexes a tree \(S^P\) which is linear. From each branch \(P\), a maximal path \(\bar P\) can be obtained by concatenating \(P\) with \(p^{\dep(S^P)}\), the unique maximal path of \(S^P\).

  For a branch \(P\), we further define the \emph{branch height}, \(\bh(P)\), to be one less than the length of \(P\) (noting that branches are non-empty lists), and the \emph{leaf height}, \(\lh(P)\), to be one less than the length of \(\bar P\), which is equal to the dimension of \(\lfloor \hat P \rfloor\).
\end{definition}
While each branch \(P\) uniquely determines a maximal path \(\bar P\), the converse does not hold. There may be multiple branches of a tree which correspond to the same maximal path. Consider the tree \(T = [[[[\emp],\emp],emp]]\). This has two distinct branches \(P = [0,0,0]\) and \(Q = [0,0,0,0]\) which both correspond to the maximal path \([0,0,0,0,0]\). We graphically depict these branches below by drawing them in blue.

\[ P = \begin{tikzpicture}[yscale=0.7,every node/.append style={scale=0.6},baseline=(x21.base)]
    \node [on grid] at (0,0) (x01) {$\bullet$};
    \node [on grid] at (0,1) (x11) {$\bullet$};
    \node [on grid] at (-0.5,2)(x21){$\bullet$};
    \node [on grid] at (0.5,2) (x22){$\bullet$};
    \node [on grid, blue] at (-0.9,3)(x31) {$\bullet$};
    \node [on grid] at (-0.1,3) (x32) {$\bullet$};
    \node [on grid, blue] at (-0.9,4)(x41) {$\bullet$};
    \begin{scope}[on background layer]
      \draw (x01.center) to (x11.center);
      \draw (x11.center) to (x21.center);
      \draw (x11.center) to (x22.center);
      \draw[blue,thick] (x21.center) to (x31.center);
      \draw (x21.center) to (x32.center);
      \draw[blue,thick] (x31.center) to (x41.center);
    \end{scope}
  \end{tikzpicture}
  \qquad
  Q = \begin{tikzpicture}[yscale=0.7,every node/.append style={scale=0.6},baseline=(x21.base)]
    \node [on grid] at (0,0) (x01) {$\bullet$};
    \node [on grid] at (0,1) (x11) {$\bullet$};
    \node [on grid] at (-0.5,2)(x21){$\bullet$};
    \node [on grid] at (0.5,2) (x22){$\bullet$};
    \node [on grid] at (-0.9,3)(x31) {$\bullet$};
    \node [on grid] at (-0.1,3) (x32) {$\bullet$};
    \node [on grid, blue] at (-0.9,4)(x41) {$\bullet$};
    \begin{scope}[on background layer]
      \draw (x01.center) to (x11.center);
      \draw (x11.center) to (x21.center);
      \draw (x11.center) to (x22.center);
      \draw (x21.center) to (x31.center);
      \draw (x21.center) to (x32.center);
      \draw[blue,thick] (x31.center) to (x41.center);
    \end{scope}
  \end{tikzpicture}
\]
While \(P\) and \(Q\) represent the same path, they have different branch heights: the branch height of \(P\) is \(0\) while the branch height of \(Q\) is \(1\). This will cause insertions along these two branches to proceed differently (though we will see later that if both insertions are valid then the results are equivalent\todo{cross ref}). The leaf height and branch height of the branch \(P\) is demonstrated in \cref{fig:leafheight}, where we also depict the trunk height of \(T\), which was defined in \cref{sec:trees}.

\begin{figure}
  \[
    \begin{tikzpicture}[xscale=1.4,every node/.append style={scale=0.85},baseline=(x21.base)]
    \node [on grid] at (0,0) (x01) {$\bullet$};
    \node [on grid] at (0,1) (x11) {$\bullet$};
    \node [on grid] at (-0.5,2)(x21){$\bullet$};
    \node [on grid] at (0.5,2) (x22){$\bullet$};
    \node [on grid, blue] at (-0.9,3)(x31) {$\bullet$};
    \node [on grid] at (-0.1,3) (x32) {$\bullet$};
    \node [on grid, blue] at (-0.9,4)(x41) {$\bullet$};
    \node [left=0 of x31.center ,on grid] {$T^P$};
    \node [right=0 of x41.center ,on grid] {$\bar P$};
    \begin{scope}[on background layer]
      \draw (x01.center) to (x11.center);
      \draw (x11.center) to (x21.center);
      \draw (x11.center) to (x22.center);
      \draw[blue,thick] (x21.center) to (x31.center);
      \draw (x21.center) to (x32.center);
      \draw[blue,thick] (x31.center) to (x41.center);
    \end{scope}
    \node [on grid] at (-0.7,1)(th) {};
    \draw [|->] (-0.7,0) to node [left] {$\th(T)$} (th.center);
    \draw [dotted,thick] (th) to (x11);
    \node [on grid] at (-1.5,2) (bh) {};
    \draw [|->] (-1.5,0) to node [left] {$\bh(P)$} (bh.center);
    \draw [dotted,thick] (bh) to (x21);
    \node [on grid] at (-2.3,4) (lh) {};
    \draw [|->] (-2.3,0) to node [left] {$\lh(P)$} (lh.center);
    \draw [dotted,thick] (lh) to (x41);
  \end{tikzpicture}
\]
\caption{\label{fig:leafheight} Leaf height, branch height and trunk height.}
\end{figure}

Let us again consider the tree \(S = [[\emp,\emp],\emp]\) from \cref{fig:tree-example}. This tree has three branches, corresponding to the maximal paths \([0,0,0]\), \([0,1,0]\), and \([1,0]\). We consider the action of insertion of three trees \(T_1,T_2,T_3\), given below, into branch \(P = [0,0]\), which corresponds to the first of these maximal paths.
\[T =
  \begin{tikzpicture}[yscale=0.7, every node/.style={scale=0.6},baseline=(x11.base)]
    \node [on grid] at (0,0) (x01) {$\bullet$};
    \node [on grid] at (0,1)(x11) {$\bullet$};
    \node [on grid] at (-0.5, 2) (x21) {$\bullet$};
    \node [on grid] at (0.5,2)(x22) {$\bullet$};
    \draw (x01.center) to (x11.center);
    \draw (x11.center) to (x21.center);
    \draw (x11.center) to (x22.center);
  \end{tikzpicture}
  \qquad
  T' = \begin{tikzpicture}[yscale=0.7, every node/.style={scale=0.6},baseline=(x11.base)]
    \node [on grid] at (0,0) (x01) {$\bullet$};
    \node [on grid] at (0,1)(x11) {$\bullet$};
    \draw (x01.center) to (x11.center);
    \path [draw=none] (-0.5,0) to (0.5,0);
  \end{tikzpicture}
  \qquad
  T'' = \begin{tikzpicture}[yscale=0.7, every node/.style={scale=0.6},baseline=(x21.base)]
    \node [on grid] at (0,1)(x11) {$\bullet$};
    \node [on grid] at (-0.5, 2) (x21) {$\bullet$};
    \node [on grid] at (0.5,2)(x22) {$\bullet$};
    \draw (x11.center) to (x21.center);
    \draw (x11.center) to (x22.center);
  \end{tikzpicture}
\]
We first consider the insertion of \(T\) into \(S\), which returns the inserted tree \(\insertion S P {T_1}\), where \(P\) is drawn in blue on the diagram.
\[ S = \begin{tikzpicture}[yscale=0.7, every node/.style={scale=0.6},baseline=(x11.base)]
    \node [on grid] at (0,0) (x01) {$\bullet$};
    \node [on grid] at (-0.5,1) (x11) {$\bullet$};
    \node [on grid, blue] at (-0.9, 2)(x21) {$\bullet$};
    \node [on grid] at (-0.1, 2)(x22) {$\bullet$};
    \node [on grid] at (0.5,1)(x12) {$\bullet$};
    \begin{scope}[on background layer]
    \draw (x01.center) to (x11.center);
    \draw (x01.center) to (x12.center);
    \draw[blue, thick] (x11.center) to (x21.center);
    \draw (x11.center) to (x22.center);
    \end{scope}
  \end{tikzpicture}
  \qquad
  T = \begin{tikzpicture}[yscale=0.7, every node/.style={scale=0.6},baseline=(x11.base), red]
    \node [on grid] at (0,0) (x01) {$\bullet$};
    \node [on grid] at (0,1) (x11) {$\bullet$};
    \node [on grid] at (-0.5, 2) (x21) {$\bullet$};
    \node [on grid] at (0.5,2)(x22) {$\bullet$};
    \draw (x01.center) to (x11.center);
    \draw (x11.center) to (x21.center);
    \draw (x11.center) to (x22.center);
  \end{tikzpicture}
  \qquad
  \insertion S P {T} = \begin{tikzpicture}[yscale=0.7, every node/.style={scale=0.6},baseline=(x11.base)]
    \node [on grid, red] at (0,0) (x01) {$\bullet$};
    \node [on grid, red] at (-0.5,1) (x11) {$\bullet$};
    \node [on grid, red] at (-0.9, 2)(x21) {$\bullet$};
    \node [on grid, red] at (-0.5, 2)(x22) {$\bullet$};
    \node [on grid] at (-0.1, 2)(x23) {$\bullet$};
    \node [on grid] at (0.5,1)(x12) {$\bullet$};
    \begin{scope}[on background layer]
    \draw [red] (x01.center) to (x11.center);
    \draw (x01.center) to (x12.center);
    \draw [red] (x11.center) to (x21.center);
    \draw [red] (x11.center) to (x22.center);
    \draw (x11.center) to (x23.center);
    \end{scope}
  \end{tikzpicture}
\]


In this case the structure of \(T\) is compatible with the point of insertion \(P\) and \(T\) can be inserted into \(S\), replacing the branch \(P\) with the appropriate part of \(T\), where this appropriate part is obtained by removing the trunk of \(T\).

We now consider the insertion of \(T'\) into \(S\). Despite \(T'\) having a lower depth than \(S\), it is still insertable, forming the following tree \(\insertion S P {T'}\).
\[ S = \begin{tikzpicture}[yscale=0.7, every node/.style={scale=0.6},baseline=(x11.base)]
    \node [on grid] at (0,0) (x01) {$\bullet$};
    \node [on grid] at (-0.5,1) (x11) {$\bullet$};
    \node [on grid, blue] at (-0.9, 2)(x21) {$\bullet$};
    \node [on grid] at (-0.1, 2)(x22) {$\bullet$};
    \node [on grid] at (0.5,1)(x12) {$\bullet$};
    \begin{scope}[on background layer]
    \draw (x01.center) to (x11.center);
    \draw (x01.center) to (x12.center);
    \draw[blue, thick] (x11.center) to (x21.center);
    \draw (x11.center) to (x22.center);
    \end{scope}
  \end{tikzpicture}
  \qquad
  T' = \begin{tikzpicture}[yscale=0.7, every node/.style={scale=0.6},baseline=(x11.base), red]
    \node [on grid] at (0,0) (x01) {$\bullet$};
    \node [on grid] at (0,1)(x11) {$\bullet$};
    \draw (x01.center) to (x11.center);
    \path [draw=none] (-0.5,0) to (0.5,0);
  \end{tikzpicture}
  \qquad
  \insertion S P {T'} = \begin{tikzpicture}[yscale=0.7, every node/.style={scale=0.6},baseline=(x11.base)]
    \node [on grid,red] at (0,0) (x01) {$\bullet$};
    \node [on grid,red] at (-0.5,1) (x11) {$\bullet$};
    \node [on grid] at (-0.5, 2)(x21) {$\bullet$};
    \node [on grid] at (0.5,1)(x12) {$\bullet$};
    \begin{scope}[on background layer]
    \draw [red] (x01.center) to (x11.center);
    \draw (x01.center) to (x12.center);
    \draw (x11.center) to (x21.center);
    \end{scope}
  \end{tikzpicture}
\]
Here, the branch \(P\) is replaced by a singleton tree, which is the remaining \(T'\) after removing its trunk. We note that this operation is the same as pruning the locally maximal variable \(\lfloor \bar P \rfloor\) from \(\lfloor T \rfloor\). We will see in \cref{sec:univ-prop-insert} that all instances of pruning can be represented as an instance of insertion.

When we consider the insertion of \(T''\) into \(S\), it is not clear how to proceed, as there is no ``corresponding part'' of \(T''\) to replace the branch \(P\) with. In the other two cases this is obtained by removing the trunk of the tree, but \(T''\) has no trunk to remove. In this case we say that the insertion is not possible to perform as \(\bh(P) > \th(T'')\), a condition necessary for insertion.

More generally we consider a (structured) coherence term \(\SCoh S A L : \STerm_\U\). To apply insertion to this term, we must first identify a branch \(P\) of \(S\) such that \(\bar P \sub L \equiv \stdcoh T {\lh(P)} \sub M\), that is there is a locally maximal argument of \(L\) which is a standard coherence. We then must construct the following data as part of the insertion operation:

\begin{itemize}
\item The \emph{inserted tree} \(\insertion S P T\), obtained by inserting \(T\) into \(S\) along the branch \(P\). We have already given some examples of this operation.
\item The \emph{interior labelling} \(\iota : T \to \insertion S P T\), the inclusion of \(T\) into a copy of \(T\) living in the inserted tree.
\item The \emph{exterior labelling} \(\kappa : S \to \insertion S P T\), which maps \(\bar P\) to standard coherence over the copy of \(T\), or more specifically \(\mathcal{C}_\Theta^{\lh(P)} \sub \iota\), and other maximal paths to their copy in the inserted tree.
\item The \emph{inserted labelling} \(\insertion L P M : \insertion S P T \to \U\), which collects the appropriate parts of \(L\) and \(M\).
\end{itemize}
Using this notation, insertion yields the following equality:
\[\Coh S A L = \Coh {\insertion S P T} {A \sub \kappa} {\insertion L P M}\]
These constructions can be assembled into the following diagram, where \(B\) is the type of \(\bar P\) and \(n = \lh(P)\):
% https://q.uiver.app/?q=WzAsNSxbMCwwLCJEX24iXSxbMSwwLCJcXERlbHRhIl0sWzAsMSwiXFxUaGV0YSJdLFsxLDEsIlxcaW5zZXJ0aW9uIFxcRGVsdGEgeCBcXFRoZXRhIl0sWzIsMiwiXFxHYW1tYSJdLFsxLDMsIlxca2FwcGEiXSxbMiwzLCJcXGlvdGEiLDJdLFswLDEsIlxce0EseFxcfSJdLFswLDIsIlxce1xcbWF0aGNhbHtVfV9cXFRoZXRhXm4sIFxcbWF0aGNhbHtDfV9cXFRoZXRhXm5cXH0iLDJdLFsxLDQsIlxcc2lnbWEiLDAseyJjdXJ2ZSI6LTN9XSxbMiw0LCJcXHRhdSIsMix7ImN1cnZlIjoyfV0sWzMsNCwiXFxpbnNlcnRpb24gXFxzaWdtYSB4IFxcdGF1IiwxXSxbMywwLCIiLDEseyJzdHlsZSI6eyJuYW1lIjoiY29ybmVyIn19XV0=
\[\begin{tikzcd}
    {D^n} & S \\
    T & {\insertion S P T} \\
    && \U
    \arrow["\kappa", from=1-2, to=2-2]
    \arrow["\iota"', from=2-1, to=2-2]
    \arrow["{\{B, \bar P\}}", from=1-1, to=1-2]
    \arrow["{\{\stdty T n, \stdcoh T n\}}"', from=1-1, to=2-1]
    \arrow["L", curve={height=-18pt}, from=1-2, to=3-3]
    \arrow["M"', curve={height=12pt}, from=2-1, to=3-3]
    \arrow["{\insertion L P M}"{description}, from=2-2, to=3-3]
    % \arrow["\lrcorner"{anchor=center, pos=0.125, rotate=180}, draw=none, from=2-2, to=1-1]
  \end{tikzcd}
\]
It will be proven in \cref{sec:univ-prop-insert} that the square above is cocartesian, and so \(\insertion S P T\) is the pushout of \(S\) and \(T\).

We now begin to define each of these constructions in turn. As we need a lot of data to perform an insertion, we will package it up to avoid repetition.

\begin{definition}
  An \emph{insertion point} is a triple \((S,P,T)\) such that \(S\) and \(T\) are trees and \(P\) is a branch of \(S\) with \(\bh(P) \leq \th(T)\) and \(\lh(S) \geq \dim(T)\).

  An \emph{insertion redex} is a sextuple \((S,P,T,\U,L,M)\) such that \((S,P,T)\) is an insertion point, \(L : S \to \U\) and \(M : T \to \U\) are labellings, and \(L(\bar P) \equiv \mathcal{C}_T^{\lh(P)}\sub M\).
\end{definition}

We can now define the insertion operation on trees.

\begin{definition}[Inserted tree]
  Let \((S,P,T)\) be an insertion point. Define the \emph{inserted tree} \(\insertion S P T\) by induction on the branch \(P\), noting that \(P\) is always non-empty.
    \begin{itemize}
  \item Suppose \(P = [k]\) and \(S = [S_0,\dots,S_k,\dots,S_n]\). Then:
    \[\insertion S P T = [S_0,\dots,S_{k-1}] \doubleplus T \doubleplus [S_{k+1},\dots,S_n]\]
  \item Suppose \(P = k :: Q\) and again \(S = [S_0,\dots,S_k,\dots,S_n]\). We note that \(Q\) is a branch of \(S_k\) and by the condition on trunk height of \(T\) we have \(T = \Sigma(T_0)\). Then:
    \[\insertion S P T = [S_0,\dots,S_{k-1},(\insertion {S_k} {Q} {T_0}),S_{k+1},\dots,S_n ] \]
  \end{itemize}
  We draw attention to the condition of the trunk height of \(T\) being at least the branch height of \(P\), which is necessary for the induction to proceed. We recall that a tree is identified with a list of trees, and that in the first case of insertion \(T\) is treated as a list, and in the second case \(\insertion {S_k} {Q} {T_0}\) is treated as a single tree which forms one of the subtrees of \(\insertion S P T\).
\end{definition}

We now proceed to define the interior and exterior labellings, which will be done using the diagrammatic notation introduced in \cref{sec:wedge-sums}.

\begin{definition}[Interior labelling]
  Given an insertion point \((S, P, T)\) we define the interior labelling \(\iota_{S,P,T} : T \to \insertion S P T\) by induction on~\(P\).

  \begin{itemize}
  \item When \(P = [k]\) and \(S = [S_0,\dots,S_k,\dots,S_n]\) we define \(\iota\) by \(\ty(\iota) = \star\) and:
    % https://q.uiver.app/?q=WzAsNixbMCwwLCJTXzBcXHZlZVxcZG90c1xcdmVlIFNfe2stMX0iXSxbNCwwLCJTX3trKzF9IFxcdmVlIFxcZG90cyBcXHZlZSBTX24iXSxbMiwwLCJUIl0sWzMsMCwiXFx2ZWUiXSxbMSwwLCJcXHZlZSJdLFsyLDIsIlQiXSxbNSwyLCJcXGlkIl1d
    \[\begin{tikzcd}[column sep=smaller,row sep=10pt]
        {[S_0,\dots,S_{k-1}]} & \doubleplus & T & \doubleplus & {[S_{k+1},\dots,S_n]} \\
        \\
        && T
        \arrow["\id"{font = \normalsize}, from=3-3, to=1-3]
      \end{tikzcd}
    \]

    \item When \(P = k :: Q\), \(S = [S_0,\dots,S_k,\dots,S_n]\), and \(T = [T_0]\) (by the trunk height condition) we define \(\iota\) by \(\ty(\iota) = \star\) and:
    % https://q.uiver.app/?q=WzAsNixbMCwwLCJcXGxmbG9vciBbU18xLFxcZG90cyxTX3trLTF9XSBcXHJmbG9vciJdLFs0LDAsIlxcbGZsb29yIFtTX3trKzF9LFxcZG90cyxTX25dIFxccmZsb29yIl0sWzIsMCwiXFxTaWdtYSBcXGxmbG9vciBcXGluc2VydGlvbiB7U19rfSB7UCd9IHtUXzF9IFxccmZsb29yIl0sWzMsMCwiXFx2ZWUiXSxbMSwwLCJcXHZlZSJdLFsyLDIsIlxcU2lnbWEgXFxsZmxvb3IgVF8xIFxccmZsb29yIl0sWzUsMiwiXFxTaWdtYSBcXGlvdGFfe1NfayxQJyxUXzF9Il1d
    \[\begin{tikzcd}[column sep=smaller, row sep=10pt]
        {[S_0,\dots,S_{k-1}]} & \vee & {\Sigma \insertion {S_k} {Q} {T_0}} & \vee & {[S_{k+1},\dots,S_n]} \\
        \\
        && {\Sigma T_0}
        \arrow["{\Sigma \iota_{S_k,Q,T_0}}"{font = \normalsize}, from=3-3, to=1-3]
      \end{tikzcd}
    \]
  \end{itemize}
We may drop the subscripts on \(\iota\) when they are easily inferred.
\end{definition}

\begin{definition}[Exterior labelling]
  Given an insertion point \((S, P, T)\), we define the exterior labelling \(\kappa_{S,P,T} : S \to \insertion S P T\) by induction on \(P\).

  \begin{itemize}
  \item When \(P = [k]\) and \(S = [S_0,\dots,S_k,\dots,S_n]\) we define \(\kappa\) by \(\ty(\kappa) = \star\) and:
    % https://q.uiver.app/?q=WzAsMTAsWzAsMCwiXFxsZmxvb3IgW1NfMSxcXGRvdHMsU197ay0xfV0gXFxyZmxvb3IiXSxbNCwwLCJcXGxmbG9vciBbU197aysxfSxcXGRvdHMsU19uXSBcXHJmbG9vciJdLFsyLDAsIlxcbGZsb29yIFQgXFxyZmxvb3IiXSxbMywwLCJcXHZlZSJdLFsxLDAsIlxcdmVlIl0sWzIsMiwiXFxTaWdtYSBcXGxmbG9vciBTX2sgXFxyZmxvb3IiXSxbMCwyLCJcXGxmbG9vciBbU18xLFxcZG90cyxTX3trLTF9XFxyZmxvb3IiXSxbMSwyLCJcXHZlZSJdLFszLDIsIlxcdmVlIl0sWzQsMiwiXFxsZmxvb3IgW1Nfe2srMX0sXFxkb3RzLFNfbl0gXFxyZmxvb3IiXSxbNSwyLCJcXHtcXG1hdGhjYWx7VX1fVF5uLCBcXG1hdGhjYWx7Q31fVF5uXFx9Il0sWzYsMCwiXFxpZCJdLFs5LDEsIlxcaWQiXV0=
    \[\begin{tikzcd}[column sep=smaller,row sep = 10pt]
        {[S_0,\dots,S_{k-1}]} & \doubleplus & {T} & \doubleplus & {[S_{k+1},\dots,S_n]} \\
        \\
        {[S_0,\dots,S_{k-1}]} & \vee & {\Sigma S_k} & \vee & {[S_{k+1},\dots,S_n]}
        \arrow["{\{\stdty T m, \stdcoh T m\}}"{font = \normalsize, pos=.4}, from=3-3, to=1-3]
        \arrow["\id"{font = \normalsize}, from=3-1, to=1-1]
        \arrow["\id"{font = \normalsize}, from=3-5, to=1-5]
      \end{tikzcd}\]
    Where we note that by the condition of \(P\) being a branch we have that \(S_k\) is linear and so \(\Sigma \lfloor S_k \rfloor\) is a some disc \(D^m\) where \(m = \dep(S_k) + 1\).

    \item When \(P = k :: Q\), \(S = [S_0,\dots,S_k,\dots,S_n]\), and \(T = [T_0]\) (by the trunk height condition) we define \(\kappa\) by \(\ty(\kappa) = \star\) and:
    % https://q.uiver.app/?q=WzAsMTAsWzAsMCwiXFxsZmxvb3IgW1NfMSxcXGRvdHMsU197ay0xfV0gXFxyZmxvb3IiXSxbNCwwLCJcXGxmbG9vciBbU197aysxfSxcXGRvdHMsU19uXSBcXHJmbG9vciJdLFsyLDAsIlxcU2lnbWEgXFxsZmxvb3IgXFxpbnNlcnRpb24ge1Nfa30ge1AnfSB7VF8xfSBcXHJmbG9vciJdLFszLDAsIlxcdmVlIl0sWzEsMCwiXFx2ZWUiXSxbMiwyLCJcXFNpZ21hIFxcbGZsb29yIFNfayBcXHJmbG9vciJdLFswLDIsIlxcbGZsb29yIFtTXzEsXFxkb3RzLFNfe2stMX1cXHJmbG9vciJdLFsxLDIsIlxcdmVlIl0sWzMsMiwiXFx2ZWUiXSxbNCwyLCJcXGxmbG9vciBbU197aysxfSxcXGRvdHMsU19uXSBcXHJmbG9vciJdLFs1LDIsIlxcU2lnbWEgXFxrYXBwYV97U19rLFAnLFRfMX0iXSxbNiwwLCJcXGlkIl0sWzksMSwiXFxpZCJdXQ==
    \[\begin{tikzcd}[column sep=smaller, row sep = 10pt]
        {[S_0,\dots,S_{k-1}]} & \vee & {\Sigma \insertion {S_k} {Q} {T_0}} & \vee & {[S_{k+1},\dots,S_n]} \\
        \\
        {[S_0,\dots,S_{k-1}]} & \vee & {\Sigma S_k} & \vee & {[S_{k+1},\dots,S_n]}
        \arrow["{\Sigma \kappa_{S_k,Q,T_0}}"{font=\normalsize}, from=3-3, to=1-3]
        \arrow["\id"{font=\normalsize}, from=3-1, to=1-1]
        \arrow["\id"{font=\normalsize}, from=3-5, to=1-5]
      \end{tikzcd}\]
  \end{itemize}
Again the subscripts on \(\kappa\) may be dropped where they can be inferred.
\end{definition}

Lastly we define the inserted labelling, the labelling out of the inserted tree.

\begin{definition}[Inserted labelling]
  Given an insertion point \((S, P, T)\) with \(L : S \to \U\) and \(M : T \to \U\), we define the \emph{inserted labelling} \(\insertion L P M : {\insertion S P T} \to \U\). Let
  \[ S = [S_0,\dots,S_n] \qquad L = s_0 \{L_0\}s_1 \cdots \{L_n\}s_{n+1} : A\]
  and then proceed by induction on \(P\).

  \begin{itemize}
    \item Let \(P = [k]\), and
    \[ T = [T_0,\dots,T_m] \qquad M = t_0\{M_0\}t_1 \cdots \{M_m\}t_{m+1} : B\]
    Then define \(\insertion L {[k]} M\) to be:
    \[s_0\{L_0\}s_1 \cdots \{L_{k-1}\}t_0\{M_0\}t_1\cdots \{M_m\}t_{m+1}\{L_{k+1}\}s_{k+2}\cdots \{L_n\}s_{n+1} : A\]

    \item Suppose \(P = k :: Q\) so that
    \[T = [T_0] \qquad M = t_0\{M_0\}t_1 : B\]
    Define \(\insertion L P M\) as:
    \[s_0\{L_0\}s_1\cdots \{L_{k-1}\}t_0\{\insertion {L_k} {Q} {M_0}\}t_1\{L_{k+1}\}s_{k+2} \cdots \{L_n\}s_{n+1} : A\]
  \end{itemize}
\end{definition}

The now proceed to prove that each of these constructions used to generate insertion is well-formed. We begin with the following small lemma.

\begin{lemma}
  \label{lem:inserted-label-lem}
  Let \((S,P,T,U,L,M)\) be an insertion redex. If we further suppose that \(\U \vdash L : S\) and \(\U \vdash M : T\), then:
  \[ \U \vdash \arr {L[k]} {\ty(L)} {L[k+1]} = \arr {M[0]} {\ty(M)} {M[m+1]}\]
  where \(k\) is the first element of \(P\) (as \(P\) is non-empty) and \(T\) has length \(m\).
\end{lemma}
\begin{proof}
  From the insertion redex, we have \(L(\bar P) \equiv \stdcoh T {\lh(P)} \sub M\). By assumption, \(P\) is of the form \(k :: p\), where \(p\) is a path and \(S = [S_0,\dots,S_n]\) and so
  \[\SPath(\bar P) \equiv  \Inc_k(\SPath(p)) \]
  and so supposing that \(S_k \vdash \SPath(p) : A\) (as every path is well-formed), we can obtain:
  \[\U \vdash \SPath(\bar P) \sub L : \Sigma(A) \sub {\inc_k} \sub L\]
  By \cref{prop:prop:standard-typing}, \(\U \vdash \stdcoh T {\lh(P)} \sub M : \stdty T {\lh(P)} \sub M\). Therefore by uniqueness of types (using the syntactic equality from the insertion redex), we have:
  \[ \U \vdash \Sigma(A) \sub {\inc_k \bullet L} = \stdty T {\lh(P)} \sub M\]
  By truncating both sides of of this equality \(\lh(P) - 1\) times we get:
  \[ \U \vdash \Sigma(\star) \sub {\inc_k \bullet L} = \stdty T 1 \sub M\]
  which after expanding definitions on both sides gives the required equality.
\end{proof}

The typing properties of each of the constructions involved in insertion are given in the following proposition.
\begin{proposition}
  Let \((S,P,T)\) be an insertion point. Then:
  \[\insertion S P T \vdash \iota_{S,P,T} : T \qquad \insertion S P T \vdash \kappa_{S,P,T} : S\]
  If we further have \(\U \vdash L : S\) and \(\U \vdash M : S\) with \(L(\bar P) \equiv \stdcoh T {\lh(P)} \sub M\) then:
  \[ \U \vdash \insertion L P M : \insertion S P T\]
\end{proposition}
\begin{proof}
  The labellings \(\iota\) and \(\kappa\) are formed using constructions that have already been shown to be well-formed. We therefore focus on the typing judgement for the inserted labelling. As in the definition of the inserted labelling, we let
  \[ S = [S_0,\dots,S_n] \qquad L = s_0 \{L_0\}s_1 \cdots \{L_n\}s_{n+1} : A\]
  By inspection of the typing derivation \(\U \vdash L : S\) we have that \(\U \vdash s_i : A\) and \(\U \vdash L_i : S_i\) for each \(i\).

  We then proceed by induction on \(P\).
  \begin{itemize}
  \item Let \(P = [k]\) and
    \[ T = [T_0,\dots,T_m] \qquad M = t_0\{M_0\}t_1 \cdots \{M_m\}t_{m+1} : B\]
    By \(\U \vdash M : T\), we have that \(\U \vdash t_i : B\) and \(\U \vdash M_i : T_i\) for each \(i\). Applying \cref{lem:inserted-label-lem}, we have \(\U \vdash A = B\), \(\U \vdash s_k = t_0\), and \(\U \vdash s_{k+1} = t_{m+1}\). Therefore by applying the conversion rule, \(\U \vdash t_i : A\). To complete this case, we must show that for each \(i\):
    \[ \U \vdash (\insertion L P M)_i : (\insertion S P T)_i\]
    For most \(i\) this is trivial, however there is a subtlety for \(i = k-1\) that \((\insertion L P M)_{k-1} \not\equiv L_{k-1}\), as:
    \[\ty((\insertion L P M)_{k-1}) \equiv \arr {s_{k-1}} A {t_0} \not\equiv \arr {s_{k-1}} A {s_k} \equiv \ty(L_{k-1})\]
    However, the equality \(\U \vdash s_k = t_0\) means that these two types are definitionally equal, and so the required typing derivation follows from \(\U \vdash L_{k-1} : S_k\). A similar argument is needed to prove that \(\U \vdash L_{k+1} : S_{k+1}\), completing this case.
  \item Suppose \(P = k :: Q\) so that
    \[T = [T_0] \qquad M = t_0\{M_0\}t_1 : B\]
    with \(\U \vdash M_0 : T_0\) and \(\U \vdash t_i : B\) for \(i \in \{0,1\}\). Then:
    \begin{align*}
      L_k(\bar{Q}) &\equiv L(\bar P)\\
                    &\equiv \stdcoh T {\lh(P)} \sub M\\
                    &\equiv \Sigma \left(\stdcoh {T_0} {\lh(Q)}\right) \sub M\\
                    &\equiv \stdcoh {T_0} {\lh(Q)} \sub {M_0}
    \end{align*}
    and so by inductive hypothesis, we have \(\U \vdash\insertion {L_k} {Q} {M_0} : \insertion {S_k} {Q} {T_0}\). Then by a similar argument to above it can be shown that \(\insertion L P M\) is well-formed.
  \end{itemize}
  Hence, \(\U \vdash \insertion L P M : \insertion S P T\) for all branches \(P\).
\end{proof}

\subsection{Universal property of insertion}
\label{sec:univ-prop-insert}

As stated in the previous section, the constructions involved in insertion arise as a pushout square. In this section, we prove this result, which we state below:

\begin{theorem}
  \label{thm:univ-prop}
  Let \((S,P,T)\) be an insertion point. Then the following commutative square of \Cattr is cocartesian:
\[\begin{tikzcd}[column sep = large, row sep = large]
    {D^n} & \lfloor S \rfloor \\
    \lfloor T \rfloor & {\lfloor \insertion S P T \rfloor}
    \arrow["\lfloor \kappa \rfloor", from=1-2, to=2-2]
    \arrow["\lfloor \iota \rfloor"', from=2-1, to=2-2]
    \arrow["{\{\ty(\lfloor \bar P \rfloor), \lfloor \bar P \rfloor\}}", from=1-1, to=1-2]
    \arrow["{\{\lfloor \stdty T {\lh(P)} \rfloor, \lfloor \stdcoh T {\lh(P)} \rfloor\}}"', from=1-1, to=2-1]
    \arrow["\lrcorner"{anchor=center, pos=0.125, rotate=180}, draw=none, from=2-2, to=1-1]
  \end{tikzcd}
\]
The context \(\lfloor \insertion S P T \rfloor\) is the pushout of \(\lfloor S \rfloor\) and \(\lfloor T \rfloor\) along the maps that send the maximal variable of \(D^n\) to the locally maximal variable corresponding to the branch \(P\) and the standard coherence of over \(T\) of dimension equal to the leaf height of \(P\).
\end{theorem}

This theorem allows an intuitive understanding of the insertion operation; The insertion \(\insertion S P T\) is the result of taking the disjoint union of \(S\) and \(T\) and gluing the locally maximal variable of \(S\) corresponding to the path to the composite of \(T\). The original motivation for insertion was to take a term where one of the locally maximal arguments was a standard composition and flatten the structure, which aligns with the intuition given by the universal property.

\begin{remark}
  As contexts have an interpretation as freely generated \(\infty\)-categories, and the category of \(\infty\)-categories is cocomplete, there is an \(\infty\)-category pushout of this square. It however may be surprising that this pushout is freely generated and happens to be freely generated by a pasting diagram.
\end{remark}

We work towards \cref{thm:univ-prop} by introducing a couple of lemmas. These lemmas will mostly be proven by deferring to the formalisation, using the machinery of structured terms introduced in \cref{sec:structured-terms} to simplify the computations involved. We first show that the square is commutative, while also justifying the description of the external labelling given at the start of the section.

\begin{lemma}
  \label{lem:iota-kappa-comm}
  Let \((S,P,T)\) be an insertion point. Then \(\kappa(\bar P) \equiv \stdcoh T {\lh(P)} \sub \iota\).
\end{lemma}
\begin{proof}
  See \func{Catt.Tree.Insertion.Properties}{-branch-path} in \module{Catt.Tree.Insertion.Properties}.
\end{proof}

We next state two factorisation properties for the internal and external labellings.

\begin{lemma}
  \label{lem:ins-comm-max}
  For insertion redex \((S,P,T,\U,L,M)\), the following hold:
  \[ \iota_{S,P,T} \circ (\insertion L P M) \equiv M \qquad \kappa_{S,P,T} \circ (\insertion L PM) \equiv^{\mathsf{max}} L \]
  Hence the maps \(L\) and \(M\) factor through the labellings \(\kappa\) and \(\iota\) repsectively.
\end{lemma}
\begin{proof}
  See \func{Catt.Tree.Insertion.Properties}{-comm} and \func{Catt.Tree.Insertion.Properties}{-comm} in \module{Catt.Tree.Insertion.Properties}.
\end{proof}

We can now proceed with the proof of \cref{thm:univ-prop}.

\begin{proof}[Proof of \cref{thm:univ-prop}]
  Let \((S,P,T)\) be an insertion point. We must first show that the candidate pushout square is in fact commutative, for which it is sufficient to show:
  \[ \{\ty(\bar P), \bar P\} \bullet \kappa \equiv^{\max} \{\stdty T {\lh(P)}, \stdcoh T {\lh(P)}\} \bullet \iota \]
  which follows from \cref{lem:iota-kappa-comm}. To prove that this square is cocartesian, we take two substitutions \(\sigma : \lfloor S \rfloor \to \Gamma\) and \(\tau : \lfloor T \rfloor \to \Gamma\) such that the following diagram is commutative:
  \[
    \begin{tikzcd}[column sep = large, row sep = large]
      {D^n} & \lfloor S \rfloor \\
      \lfloor T \rfloor & {\lfloor \insertion S P T \rfloor}\\
      && \Gamma
      \arrow["\lfloor \kappa \rfloor", from=1-2, to=2-2]
      \arrow["\lfloor \iota \rfloor"', from=2-1, to=2-2]
      \arrow["{\{\ty(\lfloor \bar P \rfloor), \lfloor \bar P \rfloor\}}", from=1-1, to=1-2]
      \arrow["{\{\lfloor \stdty T n \rfloor, \lfloor \stdcoh T n \rfloor\}}"', from=1-1, to=2-1]
      \arrow["\sigma", curve={height=-18pt}, from=1-2, to=3-3]
      \arrow["\tau"', curve={height=12pt}, from=2-1, to=3-3]
    \end{tikzcd}
  \]
  We therefore have that \(\lceil \sigma \rceil\) is a labelling \(S \to \Gamma\) and \(\lceil \tau \rceil\) is a labelling \(T \to \Gamma\) with
  \[\Gamma \vdash \lceil \sigma \rceil(\bar P) = \stdcoh T {\lh(P)} \sub{\lceil \tau \rceil}\]
  To apply \cref{lem:ins-comm-max}, we need this to be a syntactic equality. We therefore define \(M  =\lceil \tau \rceil\) and \(L\) to be given by:
  \[ L(p) =
    \begin{cases*}
      \stdcoh T {\lh(P)} \sub M &if \(p = \bar P\)\\
      \lceil \sigma \rceil(p)&otherwise
    \end{cases*}
  \]
  by the equality above, \(L\) is well formed and \(\lfloor L \rfloor = \sigma\). We then get a well-formed map \(\lfloor \insertion L P M \rfloor\) from \(\lfloor \insertion S P T \rfloor\) to \(\Gamma\) such that the following diagram is commutative by \cref{lem:ins-comm-max}:
  \[
    \begin{tikzcd}[column sep = large, row sep = large]
      {D^n} & \lfloor S \rfloor \\
      \lfloor T \rfloor & {\lfloor \insertion S P T \rfloor}\\
      && \Gamma
      \arrow["\lfloor \kappa \rfloor", from=1-2, to=2-2]
      \arrow["\lfloor \iota \rfloor"', from=2-1, to=2-2]
      \arrow["{\{\ty(\lfloor \bar P \rfloor), \lfloor \bar P \rfloor\}}", from=1-1, to=1-2]
      \arrow["{\{\lfloor \stdty T n \rfloor, \lfloor \stdcoh T n \rfloor\}}"', from=1-1, to=2-1]
      \arrow["\lfloor \sigma \rfloor", curve={height=-18pt}, from=1-2, to=3-3]
      \arrow["\lfloor M \rfloor"', curve={height=12pt}, from=2-1, to=3-3]
      \arrow["\lfloor \insertion L P M \rfloor"{description}, from=2-2, to=3-3]
    \end{tikzcd}
  \]
  Finally, the uniqueness of this morphism follows from the observation that every path of \(\insertion S P T\) is either of the form \(\iota(p)\) for some \(p : \Path_T\) or \(\kappa(q)\) for some \(q: \Path_S\).
\end{proof}

\todo[inline]{Pruning contained}

\subsection{The insertion rule}
\label{sec:insertion-rule}

\todo[inline]{Give equality rule}
\todo[inline]{Prove properties}

\subsection{Further properties}
\label{sec:further-properties}

\todo[inline]{Confluence properties for insertion}
\todo[inline]{End with standard coherences being preserved}



\chapter{Semistrict variants of \Catt}
\label{cha:cattstrict}

The type theories \Cattsu, a type theory for strictly unital \(\infty\)-categories, and \Cattsua, a type theory for strictly associative and unital \(\infty\)-categories, can finally be introduced in this chapter, where we will define both theories and explore some of the metatheory and properties of each type theory in detail.

The results in this chapter will heavily depend on the theory developed in the previous chapters. Both type theories will be defined as instances of \Cattr, which was introduced in \cref{sec:catt-with-equality}, and much of the initial metatheory can be immediately derived by demonstrating that the equality rule sets that generate \Cattsu and \Cattsua satisfy the various conditions given in \cref{sec:ruleset}. The theory \Cattsu is primarily generated by pruning, which was introduced in \cref{sec:pruning}, and the theory \Cattsua depends on the insertion operation, which was introduced in \cref{sec:insertion}.

\cref{sec:cattsu} will introduce and define the \Cattsu, and \cref{sec:cattsua} will do the same for \Cattsua. The main contribution of the sections is to give normalisation algorithms for their respective theories, giving a notion of computation to the equality rules given so far. A normalisation algorithm is a function \(\N : \Term_\Gamma \to \Term_\Gamma\) with the following properties:
\begin{itemize}
\item For any term \(t : \Term_\Gamma\), \(\Gamma \vdash \N(t) = t\).
\item For any \(s, t : \Term_\Gamma\) with \(\Gamma \vdash s = t\), \(\N(s) \equiv \N(t)\).
\end{itemize}
The term \(\N(t)\) is called the \emph{normal form} of \(t\). Such an algorithm allows equality of two term \(s\) and \(t\) to be decided by taking the normal form of each term and checking if they are syntactically equal. Normalisation can be extended to types and substitutions in a natural way.

In \cref{sec:cattsu,sec:cattsua}, the normalisation algorithm is defined by giving a reduction relation on syntax of the type theory, which we show to be terminating, meaning that there is no infinite reduction sequence and confluent, meaning that any two reduction paths converge to a common reduct. The normal form of a term can then be obtained by reducing it until there are no further reductions possible. In \cref{sec:reduction}, these notions are recalled, and we demonstrate that the resulting normalisation algorthm satisfies the two properties stated above. This section also introduces a method for obtaining a reduction scheme from an arbitrary equality rule set \(\mathcal{R}\).

Such a normalisation procedure allows a type checking algorithm can be implemented, creating an interpreter for the language. This allows us to write larger terms, and it can be automatically verified whether they are well-formed. In \cref{sec:towards-nbe}, we introduce our implementation of \Catt, \Cattsu, and \Cattsua, written in rust. This implementation supports features such as implicit arguments to terms, implicit suspension, and native support for trees and tree labellings. We will explain how the tool can be used, and use it to give larger examples of \Cattsua terms, including proofs of Eckmann-Hilton (see \cref{fig:eh}) and its higher dimensional coherence condition, the Syllepsis.

The implementation uses an approach closer to normalisation by evaluation for type-checking terms in the theory. \cref{sec:towards-nbe} explores this algorithm and presents some perspectives on applying normalisation by evaluation to semistrict versions of \Catt. The correctness of the tool is still dependent on the metatheoretic results derived using reduction schemes.

\todo[inline]{Describe further sections}
\todo[inline]{Include models section?}


\section{Reduction}
\label{sec:reduction}

Reduction is a method for defining computation for a type theory. For each term, a number of reductions can be applied to it, representing the various computations that could be applied to the term. Computation can then be run on a term by repeatedly searching for positions in the term that admit a reduction, known as \emph{redexes}, and applying this reduction, until no more redexes exist in the term. When a term admits no reductions we call it a \emph{normal form}.

\begin{definition}
  A \emph{reduction scheme} is given by a relation \(s \red t\) on terms. The relation \(\red^{*}\) is defined to be the reflexive transitive closure of \(\red\), and so \(s \red^* t\) exactly when there is some chain
  \[s \equiv u_0 \red \cdots \red u_k \equiv t\]
  for \(k \in \mathbb{N}\) (which could be \(0\) with \(s \equiv t\)) and terms \(u_i\) for \(i < k\). Further define \(\red^{\mathsf{rts}}\) to be the reflexive symmetric transitive closure of \(\red\).

  When a term \(s\) admits no reductions, that is there is no \(t\) such that \(s \red t\), we say it is in \emph{normal form}.
\end{definition}

If we have an equality rule set \(\mathcal{R}\) (see \cref{sec:ruleset}) that generates \Cattr, a reduction scheme can be defined on \(\mathcal{R}\) modifying the rules for equality to remove the reflexivity, symmetry, and transitivity constructors and ensure that reductions do not happen ``in parallel''.

\begin{definition}
  Let \(\mathcal{R}\) be an equality rule set. Define the reduction scheme \(\redr\) on well-formed terms, well-formed substitutions, and well-formed types to be generated by the rules in \cref{fig:reduction}. When it is clear which equality rule set is being used, we may simply write \(s \red t\) instead of \(s \redr t\).
\end{definition}

\begin{figure}[h]
  \centering
  \begin{mathpar}
    \inferrule{(\Gamma, s, t) \in \mathcal{R}}{s \redr t}\textsc{rule} \and
    \inferrule{A \redr B}{\Coh \Delta A \sigma \redr \Coh \Delta B \sigma}\textsc{cell} \and
    \inferrule{\sigma \redr \tau}{\Coh \Delta A \sigma = \Coh \Delta A \tau}\textsc{arg} \\
    \inferrule{s \redr s'}{\arr s A t \redr \arr {s'} A t}\and
    \inferrule{t \redr t'}{\arr s A t \redr \arr s A {t'}}\and
    \inferrule{A \redr A'}{\arr s A t \redr \arr s {A'} t}\\
    \inferrule{\sigma \redr \tau}{\langle \sigma, s \rangle \redr \langle \tau, s \rangle}\and
    \inferrule{s \redr t}{\langle \sigma, s \rangle \redr \langle \sigma, t \rangle}
  \end{mathpar}
  \caption[Reduction rules]{Rules for \(\rightsquigarrow_{\mathcal{R}}\)}
  \label{fig:reduction}
\end{figure}

The rules for reduction are set up so that each reduction \(s \redr t\) corresponds to the application of exactly one rule from \(\mathcal{R}\) at a single point in the term. Given a coherence \(\Coh \Delta A \sigma\), we call reductions generated by the \textsc{cell} rule \emph{cell reductions} and reductions generated by the \textsc{arg} rule \emph{argument reductions}. Reductions generated by \textsc{rule} will be named by the rule in \(\mathcal{R}\) that was used. For example a reduction generated by \textsc{rule} applied with an instance of pruning will be called a pruning reduction.

We highlight that our reduction scheme \(\redr\) is only defined between well-formed pieces of syntax. As this reduction will be used with rule sets \(\mathcal{R}\) which satisfy the preservation condition, there will be no additional burden of checking that typing is preserved while applying reductions. Therefore, we can prove that the reflexive symmetric transitive closure of reduction, \(\redrts\), is the same relation as equality on well-formed terms, given the similarity between the rules for reduction and the rules for equality.

\begin{proposition}
  \label{prop:red-is-eq}
  Let \(\mathcal{R}\) be a rule set satisfying the preservation, support, and substitution conditions (such that the generated equality preserves typing). Letting \(\redrts\) be the reflexive symmetric transitive closure of \(\redr\), we get:
  \begin{align*}
    \Gamma \vdash s = t &\iff s \redrts t \\
    \intertext{for \(s,t : \Term_\Gamma\) such that \(\Gamma \vdash s : A\) and \(\Gamma \vdash t : A\) for some \(A : \Type_\Gamma\)}
    \Gamma \vdash A = B &\iff A \redrts B \\
    \intertext{for \(A,B : \Type_\Gamma\) such that \(\Gamma \vdash A\) and \(\Gamma \vdash B\)}
    \Gamma \vdash \sigma = \tau &\iff \sigma \redrts \tau
  \end{align*}
  for \(\sigma, \tau : \arr \Delta \star \Gamma\) such that \(\Gamma \vdash \sigma : \Delta\) and \(\Gamma \vdash \tau : \Delta\).
\end{proposition}
\begin{proof}
  Each direction can be proved separately by a mutual induction on the derivation in the premise. For the right to left direction, it suffices to show that the single step reduction (\(\redr\)) is contained in the equality, as equality is an equivalence relation by construction.
\end{proof}

Just as the preservation condition on a rule set \(\mathcal{R}\) allows us to deduce that the reduction preserves typing, the substitution condition can be used to prove that the reduction in preserved by application of substitution.

\begin{proposition}
  \label{prop:red-sub}
  Suppose \(\mathcal{R}\) satisfies the substitution condition and let \(\sigma : \Delta \to \Gamma\) be a well-formed substitution. Then:
  \begin{align*}
    s \redr t &\implies s \sub \sigma \redr t \sub \sigma \\
    A \redr B &\implies A \sub \sigma \redr B \sub \sigma \\
    \tau \redr \mu &\implies \tau \bullet \sigma \redr \mu \bullet \sigma
  \end{align*}
  for well-formed terms \(s,t\), well-formed types \(A,B\), and well-formed substitutions \(\tau\) and \(\mu\). Furthermore, if \(\sigma \redr \tau\), then:
  \[ s \sub \sigma \redr^* s \sub \tau \qquad A \sub \sigma \redr^* A \sub \tau \qquad \mu \bullet \sigma \redr^* \mu \bullet \tau\]
  for term \(s\), type \(A\), and substitution \(\mu\).
\end{proposition}
\begin{proof}
  The first part by a simple induction on the reduction in the premise. The second holds by a mutual induction on the term \(s\), type \(A\), and substitution \(\mu\).
\end{proof}

\subsection{Termination}
\label{sec:termination}

In order to obtain a normal form of each term of the theory, we preform reductions on a term until no more can be applied. This can only be done if we know that this will eventually result in a normal form, a property known as \emph{strong termination}.

\begin{definition}
  A reduction relation \(\red\) is \emph{strongly terminating} if there is no infinite sequence of reductions:
  \[ s_0 \red s_1 \red s_2 \red \cdots \]
  For such a reduction, applying reductions will always eventually reach a normal form.
\end{definition}

Demonstrating that the reduction schemes defined in \cref{sec:cattsu,sec:cattsua} will be non-trivial, as each reduction adds new constructions to the term, which could themselves admit reductions. Suppose we have the following reduction due to endo-coherence removal (see \cref{sec:ecr}):
\[ \Coh \Delta {\arr s A s} \sigma \red \id(A \sub \sigma,s \sub \sigma) \]
The identity term was not present in the premise of the reduction, and the term \(s \sub \sigma\) is newly created by the reduction, and could itself admit any number of reductions.

To prove termination, we will exploit that although each reduction creates new subterms, these subterms are all of a lower dimension that the dimension of the term that is being reduced. In the example above, the dimension of \(\Coh \Delta {\arr s A s} \sigma\) is greater than the dimension of the term \(s\), and so the reduction has still made progress towards a normal form by decreasing the complexity of the term in dimension \(\dim(A)+1\), even though it may introduce arbitrary complexity at \(\dim(A)\) and below.

To this end we define the following notion of complexity for each class of syntax, which assigns an ordinal number to each term, which we its \emph{syntactic complexity}. As the ordinal numbers are well-founded, we aim to prove that our reduction is terminating by proving that each single-step reduction reduces the complexity of the term. To define syntactic complexity, we will need to use ordinal numbers up to \(\omega^\omega\). We will also need a construction known as the natural sum of ordinals, \(\alpha \+ \beta\), which is associative, commutative, and strictly monotone in both of its arguments~\cite{lipparini16_infin_natur_sum}.

\begin{definition}
  For all terms \(t\), types \(A\), and substitutions \(\sigma\), the \emph{syntactic complexity} \(\sc(t)\), \(\sc(A)\), and \(\sc(\sigma)\) are mutually defined as follows:
  \begin{itemize}
  \item For types:
    \[ \sc(\star) = 0 \qquad \sc(\arr s A t) = \sc(s) \+ \sc(A) \+ \sc(t)\]
  \item For substitutions we have:
    \[\sc(\langle t_0, \dots, t_n \rangle) = \bighash_{i=0}^n t_i\]
  \item For terms, we have \(\sc(x) = 0\) for variables \(x\).

  If \(\Coh \Delta A \sigma\) is an identity then:
    \begin{align*}
    &\sc(\Coh \Delta A \sigma) = \omega^{\dim(A)} \+ \sc(\sigma)\\
      \intertext{Otherwise:}
    &\sc(\Coh \Delta A \sigma) = 2\omega^{\dim(A)} \+ \sc(\sigma)
    \end{align*}
  \end{itemize}
\end{definition}

The syntactic complexity is given as an ordinal to leverage known results, though it should be noted that ordinals below \(\omega^\omega\) can be represented by a lists of natural numbers ordered lexicographically and under this interpretation the syntactic complexity effectively computes the number of coherences at each dimension. Therefore removing a coherence of dimension \(n\) reduces the complexity, even if we add arbitrary complexity at lower dimensions. Syntactic complexity also treats identities in a special way, as these play a special role in blocking reduction for the theories we will present.

The syntactic complexity does not account for the type in a coherence, as this is difficult to encode. Instead of showing that all reductions reduce syntactic complexity, we instead show that all reduction which are not cell reduction (reductions that have the rule marked \textsc{cell} in their derivation) reduce syntactic complexity and deduce that a hypothetical infinite reduction sequence must only consist of cell reductions after a finite number of steps, and then appeal to an induction on dimension.

\begin{lemma}
  \label{lem:termination-lem}
  Let \(\mathcal{R}\) be an equality set, and suppose that:
  \[ \sc(s) > \sc(t) \]
  for all \((\Gamma,s,t) \in \mathcal{R}\). Then for all reductions \(s \redr t\) we have \(\sc(s) \geq \sc(t)\) with the inequality strict when the reduction is not a cell reduction.
\end{lemma}
\begin{proof}
  A simple induction on the reduction \(s \redr t\) immediately gives a proof of the lemma, using the properties of the natural sum \(a \+ b\).
\end{proof}

\begin{corollary}
  \label{cor:strong-term}
  Let \(\mathcal{R}\) be an equality set with \( \sc(s) > \sc(t) \) for all \((\Gamma,s,t) \in \mathcal{R}\). Then \(\redr\) is strongly terminating.
\end{corollary}
\begin{proof}
  We proceed by induction on the dimension.
  Suppose there is an infinite reduction sequence, starting with a \(k\)-dimensional term:
  \[ s_0 \red s_1 \red s_2 \red \cdots\]
  Then by assumption, only finitely many of these reductions do not use the cell rule, as otherwise by \cref{lem:termination-lem} we would obtain an infinite chain of ordinals
  \[ \sc(s_0) \geq \sc(s_1) \geq \sc(s_2) \geq \cdots\]
  where infinitely many of these inequalities are strict. Therefore there is an \(n\) such that:
  \[ s_n \leadsto s_{n+1} \leadsto \cdots\]
  are all cell reductions. Each of these reductions reduces one of finitely many subterms of \(s_n\), and each of these subterms has dimension less than \(k\), so by inductive hypothesis, none of these subterms can be reduced infinitely often, contradicting the existence of an infinite reduction sequence.
\end{proof}

We can immediately prove that disc removal reduces syntactic complexity.

\begin{proposition}
  \label{prop:disc-rem-sc}
  Let \(s \red t\) be an instance of disc removal. Then \(\sc(s) > \sc(t)\).
\end{proposition}
\begin{proof}
  We must have \(s \equiv \Coh {D^n} {\wk(U^n)} {\{A,t\}}\) for some \(n\) and \(A\). Then:
  \begin{align*}
    \sc(s) &= \sc(\Coh {D^n} {\wk(U^n)} {\{A,t\}})\\
           &= 2\omega^n \+ \sc(\{A,t\})\\
           &> \sc(\{A,t\})\\
           &\geq \sc(t)
  \end{align*}
  where the last inequality holds by a simple induction on the dimension of \(A\).
\end{proof}

We note that as stated so far the reduction:
\[ \id(A,s) \red \id(A,s)\]
is a valid instance of endo-coherence removal for type \(A\) and term \(s\), which will break termination. We therefore let \(\ecr'\) be the equality rule set obtained by removing all triples \((\Gamma,s,t)\) from \(\ecr\) where \(s\) is already an identity. We justify replacing \ecr by \ecr' with the following lemma.

\begin{lemma}
  \label{lem:always-ecr}
  The following reduction holds, even when the left-hand side is an identity:
  \[\Coh \Delta {\arr s A s} \sigma \red_{\ecr'}^* \id(A\sub \sigma,s\sub\sigma)\]
\end{lemma}
\begin{proof}
  If \(\Coh \Delta {\arr s A s} \sigma\) is not an identity then it can reduced by endo-coherence removal. Otherwise we have \(\Delta = D^n\) for some \(n\), \(s \equiv d_n\), \(A \equiv \wk(U^n)\), and \(\sigma \equiv \{B,t\}\) for some \(B\) and \(t\) and so:
  \[\id(A\sub \sigma,s \sub \sigma) \equiv \id(\wk(U^n)\sub{\{B,t\}}, d_n \sub {\{B,t\}}) \equiv \id(B,t) \]
It follows that the reduction is trivial.
\end{proof}

It can then be proven that the reductions in this set reduce syntactic complexity.

\begin{proposition}
  \label{prop:ecr-sc}
  Let \(s \red t\) be an instance of endo-coherence removal. If \(s\) is not an identity then \(\sc(s) > \sc(t)\).
\end{proposition}
\begin{proof}
  As \(s \red t\) is an instance of endo-coherence removal, we must have \(s \equiv \Coh \Delta {\arr u A u} \sigma\) and \(t \equiv \id(A \sub \sigma, u \sub \sigma)\). Further, \(s\) is not an identity and so:
  \begin{align*}
    \sc(s) &= \sc(\Coh \Delta {\arr u A u} \sigma)\\
           &= 2\omega^{\dim(A) + 1} \+ \sc(\sigma)\\
           &\geq 2\omega^{\dim(A) + 1}\\
           &< \omega^{\dim(A) + 1} \+ \sc(A \sub \sigma) \+ \sc(u \sub \sigma)
            &= \sc(\id(A \sub \sigma, u \sub \sigma)) \\
           &= \sc(t)
  \end{align*}
  where the last inequality holds as \(\sc(A \sub \sigma) \+ \sc(u \sub \sigma) < \omega^{\dim(A) + 1}\) due to both \(A \sub \sigma\) and \(u \sub \sigma\) having the same dimension as \(\dim(A)\), meaning that their syntactic complexities are strictly bounded by \(\omega^{\dim(A) + 1}\).
\end{proof}

\subsection{Confluence}
\label{sec:confluence}

Another crucial property of reduction schemes is \emph{confluence}. A term \(s\) may have any number of redexes and could reduce to distinct terms \(t\) and \(u\). Confluence states that both the terms \(t\) and \(u\) must reduce to some common term, hence allowing us to apply reductions to a term in any order.

\begin{definition}
  Let \(\red\) be a reduction scheme. It is \emph{(globally) confluent} if for all terms \(s\),\(t\), and \(u\) with \(s \red^* t\) and \(s \red^* u\), there is a term \(v\) such that \(t \red^* v\) and \(t \red^* v\). This can be assembled into the following diagram:
  \[
    \begin{tikzcd}
      & s \\
      t && u \\
      & v
      \arrow["{*}", squiggly, from=1-2, to=2-3]
      \arrow["{*}"', squiggly, from=1-2, to=2-1]
      \arrow["{*}"', squiggly, from=2-1, to=3-2]
      \arrow["{*}", squiggly, from=2-3, to=3-2]
    \end{tikzcd}
  \]
  and hence is sometimes called the diamond property for \(\red^*\).
\end{definition}

From global confluence, it is clear that if \(s \redrts t\), where \(\redrts\) is the reflexive symmetric transitive closure of \(\redr\), then there is \(u\) with \(s \redr^* u\) and \(t \redr^* u\). It is sometimes simpler to show that the following weaker confluence property holds:
\begin{definition}
  Let \(\red\) be a reduction scheme. It is \emph{locally confluent} if given \(s \red t\) and \(s \red u\) there exists a term \(v\) such that:
  \[
    \begin{tikzcd}
      & s \\
      t && u \\
      & v
      \arrow["", squiggly, from=1-2, to=2-3]
      \arrow[""', squiggly, from=1-2, to=2-1]
      \arrow["{*}"', squiggly, from=2-1, to=3-2]
      \arrow["{*}", squiggly, from=2-3, to=3-2]
    \end{tikzcd}
  \]
  that is \(t \red^* v\) and \(u \red^* v\).
\end{definition}

Global confluence trivially implies local confluence. If we further know that the reduction scheme \(\red\) is strongly terminating then local confluence is sufficient to show global confluence.

\begin{lemma}[Newman's lemma \cite{newman1942theories}]
  \label{lem:newman}
  Let \(\red\) be strongly terminating and locally confluent. Then \(\red\) is globally confluent.
\end{lemma}

Local confluence for the reduction schemes of the type theories \Cattsu and \Cattsua will be proved using \emph{critical pair analysis}. A critical pair is a pair of distinct reductions which apply to the same term. When analysing the critical pairs of our semistrict type theories, we will encounter terms that are structurally similar, but differ on lower dimensional subterms up to equality. We define this precisely.

\begin{definition}
  Let \(\mathcal{R}\) be an equality rule set. For \(n \in \mathbb{N}\), define the \emph{bounded equality set} \(\mathcal{R}_n\) as:
  \[ \mathcal{R}_n = \left\{ (\Gamma, s, t) \in \mathcal{R} \mid \dim(s) = \dim(t) < n \right\}\]
  Let the \emph{bounded equality relation} \(s =_n t\) be the equality generated by the set \(\mathcal{R}_n\).
\end{definition}

This is used to prove the following lemma, which implies that for a critical pair \(t \leftsquigarrow s \rightsquigarrow u\) it is not necessary to find a common reduct of \(t\) and \(u\), but simply find reducts \(t'\) and \(u'\) of \(t\) and \(u\) such that \(t' =_{\dim(s)} u'\).

\begin{lemma}
  \label{lem:conf-strat}
  Let \(\mathcal{R}\) be a tame equality rule set which satisfies the preservation and support conditions, and further assume that \(\redr\) is strongly terminating. Suppose the following diagram can be formed:
  % https://q.uiver.app/#q=WzAsNixbMiwwLCJzIl0sWzAsMSwidCJdLFs0LDEsInUiXSxbMSwyLCJ0JyJdLFszLDIsInUnIl0sWzIsMiwiPV97XFxkaW0ocyl9Il0sWzAsMiwiIiwwLHsic3R5bGUiOnsiYm9keSI6eyJuYW1lIjoic3F1aWdnbHkifX19XSxbMCwxLCIiLDIseyJzdHlsZSI6eyJib2R5Ijp7Im5hbWUiOiJzcXVpZ2dseSJ9fX1dLFsxLDMsIioiLDIseyJzdHlsZSI6eyJib2R5Ijp7Im5hbWUiOiJzcXVpZ2dseSJ9fX1dLFsyLDQsIioiLDAseyJzdHlsZSI6eyJib2R5Ijp7Im5hbWUiOiJzcXVpZ2dseSJ9fX1dXQ==
  \[
    \begin{tikzcd}[column sep=tiny]
      && s \\
      t &&&& u \\
      & {t'} & {\mathclap{=_{\dim(s)}}} & {u'}
      \arrow[squiggly, from=1-3, to=2-5]
      \arrow[squiggly, from=1-3, to=2-1]
      \arrow["{*}"', squiggly, from=2-1, to=3-2]
      \arrow["{*}", squiggly, from=2-5, to=3-4]
    \end{tikzcd}
  \]
  for all critical pairs \(t \leftsquigarrow_{\mathcal{R}} s \redr u\) such that \(s \redr t\) is derived using \textsc{rule}.

  Then \(\redr\) is confluent.
\end{lemma}
\begin{proof}
  By \cref{lem:newman}, it suffices to show local confluence. We proceed by strong induction on \(n\) and \(s\), proving that all critical pairs \(t \leftsquigarrow_{\mathcal{R}_n} s \red_{\mathcal{R}_n} u\) have a common reduct, assuming that all critical pairs \(t \leftsquigarrow_{\mathcal{R}_m} s' \red_{\mathcal{R}_m} u\) have a common reduct, where \(s'\) is a subterm of \(s\) or \(m < n\). We justify this induction principle by noting that for all subterms \(s'\) of \(s\) we have \(\dim(s') \leq \dim(s)\).

We now consider critical pair \(t \leftsquigarrow_{\mathcal{R}_n} s \red_{\mathcal{R}_n} u\). We first suppose that \(s \red_{\mathcal{R}_n} t\) is derived from \textsc{rule}. Then, by definition of the set \(\mathcal{R}_n\), we must have that \(n > \dim(s)\). By the assumption of the lemma, there exist \(t'\) and \(u'\) with \(t' =_{\dim(s)} u'\) and \(t \redr^* t'\) and \(u \redr^*\). As \(n > \dim(s)\), we further have that \(t \red_{\mathcal{R}_n}^* t'\) and \(u \red_{\mathcal{R}_n}^* u'\).

By \cref{prop:red-is-eq}, \(t' \red_{\mathcal{R}_n}^{\mathsf{rts}} u'\), and so as \(\red_{\mathcal{R}_n}\) is confluent by inductive hypothesis on dimension we have \(v\) such that \(t' \red_{\mathcal{R}_n}^* v \leftsquigarrow_{\mathcal{R}_n}^* u'\). The following diagram can therefore be formed, where all the reductions are \(\mathcal{R}_n\) reductions:
\[
  \begin{tikzcd}[column sep=tiny]
    && s \\
    t &&&& u \\
    & {t'} && {u'} \\
    && v
    \arrow[squiggly, from=1-3, to=2-5]
    \arrow[squiggly, from=1-3, to=2-1]
    \arrow["{*}"', squiggly, from=2-1, to=3-2]
    \arrow["{*}", squiggly, from=2-5, to=3-4]
    \arrow["{*}"', squiggly, from=3-2, to=4-3]
    \arrow["{*}", squiggly, from=3-4, to=4-3]
  \end{tikzcd}
\]

If \(s \red_{\mathcal{R}_n} u\) was derived from \textsc{rule}, then finding a reduct can be found similarly to the first case by symmetry. We therefore consider the cases where neither \(s \red t\) or \(s \red u\) are derived using \textsc{rule}. Both reductions must be either cell or argument reductions, and so each reduces some subterm of \(s\). If they reduce distinct subterms of \(s\), then a common reduct \(v\) can be formed by applying both reductions to \(s\). Otherwise, both reductions act on the same subterm of \(s\), and a common reduct can be found by applying the inductive hypothesis for subterms.
\end{proof}

Once termination and confluence have been proven, a normalisation function can be defined, which repeatedly applies reductions until no more can be applied.

\begin{lemma}
  Suppose that \(\red\) is strongly terminating and confluent. Then every term \(s\) reduces to a unique normal form \(\N(s)\). Furthermore, if \(s \red^{\mathsf{rts}} t\), then \(\N(s) \equiv \N(t)\).
\end{lemma}
\begin{proof}
  By termination, repeatedly reducing a term will reach a normal form. Suppose a term \(s\) has two normal forms \(t\) and \(u\) such that there are reduction sequences \(s \red^* t\) and \(s \red^* u\). Then by confluence there must be a term \(v\) with \(t \red^* v\) and \(u \red^* u\). However, \(t\) and \(u\) are normal forms and so admit no reductions, so \(t \equiv v \equiv u\) as required.

  Suppose \(s \red^{\mathsf{rts}} t\). Then there are terms \(s_i\) such that:
  \[ s \equiv s_0 \rightsquigarrow^* s_1 \leftsquigarrow^* s_2 \rightsquigarrow^* \cdots \leftsquigarrow^* s_k \equiv t\]
  Now we must have \(\N(s_i) \equiv \N(s_{i+1})\) for each \(i\) as if \(s_i \rightsquigarrow^* s_{i+1}\) then both \(\N(s_i)\) and \(\N(s_{i+1})\) are normal forms of \(s_i\) and if \(s_i \leftsquigarrow^* s_{i+1}\) then both are normal forms of \(s_{i+1}\). Therefore \(\N(s)\) and \(\N(t)\) are syntactically equal as required.
\end{proof}
\begin{corollary}
  Let \(\mathcal{R}\) be tame and satisfy the preservation and support properties. Further suppose that \(\redr\) is strongly terminating and confluent, and it is decidable whether a term admits a reduction. Then the equality \(s = t\) is decidable.
\end{corollary}
\begin{proof}
  By \cref{prop:red-is-eq}, \(s = t\) if and only if \(s \red^{\mathsf{rts}} t\). By the above lemma, \(s \red^{\mathsf{rts}} t\) if and only if \(\N(s) \equiv \N(t)\). As syntactic equality is clearly decidable, and normal forms can be computed, equality is also decidable.
\end{proof}

We note that for an arbitrary rule set \(\mathcal{R}\), it may not be decidable whether a specific term \(s\) admits a reduction, but for the rule sets introduced in \cref{sec:cattsu,sec:cattsua}, it will be easy to mechanically check whether any reduction applies to a term \(s\).

\section{\Cattsu}
\label{sec:cattsu}

We are finally ready to define \Cattsu, the type theory for strictly unital \(\infty\)-categories. \Cattsu is a variant of \Cattr for which the equality is built from three classes of equalities:
\begin{itemize}
\item Pruning: The pruning operation was introduced in \cref{sec:pruning}. Pruning is the key operation in \Cattsu and drives the strict unitality of the theory. The operation ``prunes'' identity that appear as locally maximal arguments to other terms, simplifying the overall structure of a term by removing unnecessary units.
\item Endo-coherence removal: This operation was introduced in \cref{sec:ecr}. Endo-coherence removal converts ``fake identities'', terms which are morally identities yet have the wrong syntactic form, into true identities. These converted identities can then be further removed from terms by pruning.
\item Disc removal: Disc removal was the running example from \cref{sec:catt-with-equality}, and removes unary composites from the theory. Commonly after pruning, a composite is reduced to a unary composite, for which disc removal is necessary to complete the simplification of the term.
\end{itemize}
In this section we will prove that \Cattsu is a type theory satisfying many standard meta-theoretic properties by combining results from previous chapters. We also give a reduction scheme for \Cattsu and show that this is strongly terminating and confluent.

\begin{example}
  Suppose we have terms \(f : \arr x \star y\), \(g : \arr y \star z\), \(h : \arr x \star z\), and \(\alpha : f * g \to h\) in some context \(\Gamma\). We can then consider the term:
  \[ \Coh {(x : *), (y : *), (f : \arr x \star y), (z : \star), (g : \arr y \star z)} {f * g \to f * g} {\langle x,y,f,z, g \rangle} * \alpha\]
  which consists of an endo-coherence composed with the variable \(\alpha\). This then reduces as follows:
  \begin{align*}
    &\phantom{{}\red{}}\Coh {(x : *), (y : *), (f : \arr x \star y), (z : \star), (g : \arr y \star z)} {f * g \to f * g} {\langle f, g \rangle} * \alpha\\
    &\red \id(\arr x \star z, f * g) * \alpha&\text{by endo-coherence removal}\\
    &\red \Coh {D^2} {\wk(U^2)} {\langle x,z,f*g,h,\alpha \rangle}&\text{by pruning}\\
    &\red \alpha &\text{by disc removal}
  \end{align*}
  and so uses all three reductions to fully simplify to a variable.
\end{example}

We define \Cattsu by the following equality rule set.

\begin{definition}
  Define the equality rule set \su for \Cattsu by:
  \[ \su = \dr \cup \prune \cup \ecr\]
  \Cattsu is then the variant of \Cattr where \(\mathcal{R} = \su\).
\end{definition}

When it is not specified, we will assume that the operation set \(\mathcal{O}\) is given by the regular operation set \(\Reg\).

\begin{theorem}
  The rule set \su is tame and satisfies the support and preservation conditions.
\end{theorem}
\begin{proof}
  By \cref{prop:dr-weak,prop:dr-susp,prop:dr-sub}, disc removal satisfies the weakening, suspension, and \(\su\)-substitution conditions. Endo-coherence removal and pruning satisfy the same conditions by \cref{prop:ecr-props,prop:prune-tame}. As these conditions are closed under unions, the set \su must also satisfy the weakening, suspension, and substitution conditions, and hence is tame.

  We now use the proof strategy introduced in \cref{sec:further-theories} to prove that \su satisfies the support condition. Firstly, by \cref{lem:supp-sat-conds} we know that \(\su_{\mathsf{s}}\) is also tame. Disc removal then satisfies the \(\su_{\mathsf{s}}\)-support condition by \cref{prop:dr-supp}. The same condition is satisfied by endo-coherence removal (\cref{item:ecr-supp}) and pruning (\cref{prop:prune-supp}) and so \(\su\) satisfies the \(\su_{\mathsf{s}}\)-support condition. By \cref{lem:proof-strat-supp}, \su satisfies the support condition.

  Lastly, \su satisfies the \su-preservation condition as it is satisfied by disc removal (\cref{prop:dr-preserve}), endo-coherence removal (\cref{item:ecr-preserve}), and pruning (\cref{prop:prune-preserve}) and is closed under unions of rule sets.
\end{proof}

From this theorem it can be deduced that weakening, suspension, and applications of substitution are well-formed. Furthermore, equality in \Cattsu preserves the support of a term and preserves typing judgements. Such results are found in \cref{sec:ruleset}.

Before giving normalisation results for \Cattsu, we recall the Eckmann-Hilton argument (\cref{fig:eh}) and give the definition of the term giving this equivalence. First let \(\Delta\) be the ps-context given by:
\begin{alignat*}{2}
  \Delta = D^2 \wedge D^2 = &(x : *),\\
                            &(y : *),&\ &(f : x \to y),\\
                            &&&(g : x \to y),(a : f \to g),\\
                            &(z : *),&&(h : x \to y),\\
                            &&&(j : x \to y),(b : h \to j)
\end{alignat*}
which is given by the diagram:
\[
  \begin{tikzcd}
    \bullet & \bullet & \bullet
    \arrow[""{name=0, anchor=center, inner sep=0}, "g", curve={height=-18pt}, from=1-1, to=1-2]
    \arrow[""{name=1, anchor=center, inner sep=0}, "f"', curve={height=18pt}, from=1-1, to=1-2]
    \arrow[""{name=2, anchor=center, inner sep=0}, "h"', curve={height=18pt}, from=1-2, to=1-3]
    \arrow[""{name=3, anchor=center, inner sep=0}, "i", curve={height=-18pt}, from=1-2, to=1-3]
    \arrow["a"', shorten <=5pt, shorten >=5pt, Rightarrow, from=1, to=0]
    \arrow["b"', shorten <=5pt, shorten >=5pt, Rightarrow, from=2, to=3]
  \end{tikzcd}
\]
The following term can be formed, which is similar to an interchange move, and changes the order in which two whiskered terms are composed:
\[ \mathsf{swap} = \Coh {\Delta} {(a *_0 j) *_1 (g *_0 b) \to (f *_0 b) *_1 (a *_0 h)} {\id_\Delta}\]
Then given a context \(\Gamma\) with terms \(x : *\) and \(\alpha,\beta : \id(x) \to \id(x)\), the following term, the Eckmann-Hilton term, can be formed:
\[ \mathsf{EH}_{\alpha,\beta} = \mathsf{swap} \sub{\langle x,x,\id(x),\id(x),\alpha, x,\id(x),\id(x),\beta \rangle}\]
In \Cattsu, this term can be typed as follows:
\[ \Gamma \vdash \mathsf{EH}_{\alpha,beta} : \alpha *_1 \beta \to \beta *_1 \alpha\]
and so witnesses the Eckmann-Hilton argument.

We note that there is a clear inverse of the Eckmann Hilton term, which immediately gives rise to two morphisms \(\alpha *_1 \beta \to \beta *_1 \alpha\): the original term \(\mathsf{EH}_{\alpha,\beta}\) and the term \(\mathsf{EH}_{\beta,\alpha}^{-1}\). These two terms manoeuvre  \(\alpha\) and \(\beta\) round eachother in opposite directions, and are not in general equivalent.

However, we can instead apply Eckmann-Hilton to terms \(\phi\) and \(\psi\) of type \(\id^2(x) \to \id^(x)\), which is done by suspending the Eckmann-Hilton term. By an abuse of notation we define this term to be (only giving the locally maximal arguments of the substitution):
\[\mathsf{EH}_{\phi,\psi} = \Sigma(\mathsf{swap}) \sub{\langle \phi, \psi \rangle}\]
In this case, the extra dimension gives enough freedom to give an equivalence between the resulting two terms \(\phi *_2 \psi \to \psi *_2 \phi\) which is called the \emph{syllepsis} and has the type:
\[ \mathsf{Syl}_{\phi,\psi} : \mathsf{EH}_{\phi,\psi} \to \mathsf{EH}^{-1}_{\psi,\phi}\]
To define this term, a similar approach to the approach used for Eckmann-Hilton of giving a single coherence containing a more complex type and a substitution containing multiple identity terms, and letting the \Cattsu reduction simplify the type to the required one. We delay defining this term until \cref{sec:towards-nbe}, where the implementation presented in this section can be used to check that the resulting term is well-formed.

\subsection{Normalisation for \Cattsu}
\label{sec:reduction-cattsu}

Following \cref{sec:reduction} we aim to give a normalisation algorithm for \Cattsu by exhibiting a strongly terminating and confluent reduction scheme.

The reduction scheme \(\red_{\su}\) cannot be used directly because the reduction generated from \ecr is not terminating, as it allows identities to reduce to identities. Even after replacing the equality rule set \ecr by \ecr', the equality set obtained by removing these trivial identity to identity reductions from \ecr, the generated reduction is still non-terminating. Consider the term \(\id(\arr t A t,\id(A,t))\) for some term \(t\) of type \(A\). Then the following reduction sequence can be formed:
\[ \id(\arr t A t,\id(A,t)) \red \Coh {D^n} {\id(\wk(U^n), d_n) \to \id(\wk(U^n), d_n)} {\{A,t\}} \red \id(\arr t A t, \id(A,t)) \]
where \(n = \dim(A)\), the first reduction is by pruning, and the second reduction is by endo-coherence removal. We therefore choose to also restrict the pruning equality rule set to not apply when the head term is an identity, obtaining the set \prune'. We can now define the reduction scheme for \Cattsu.

\begin{definition}
  Define the reduction \(\red_{\su'}\) to be the reduction generated by the equality rule set \(\su'\) where
  \[ \su' = \dr \cup \prune' \cup \ecr'\]
  where \ecr' is the endo-coherence removal set without identity to identity equalities and \prune' is the pruning set restricted to the triples where the left hand side term is not an identity.
\end{definition}

The reduction \(\red_{\su'}\) applies equality rules from \Cattsu when the redex is not identity, effectively forcing identities to be normal forms of the theory. As applying a substitution to or suspending a non-identity term cannot result in an identity, it is clear that \su' is tame. Strong termination for \(\red_{\su'}\) can now be proven using \cref{cor:strong-term}, by showing that all rules reduce the syntactic complexity of terms.

\begin{proposition}
  Let \(s \red t\) be an instance of pruning. If \(s\) is not an identity then \(\sc(s) > \sc(t)\).
\end{proposition}
\begin{proof}
  The reduction \(s \red t\) is an instance of pruning, and so there must be Dyck word \(\mathcal{D} : \Dyck_0\), and peak \(p : \Peak_{\mathcal{D}}\) such that
  \[s \equiv \Coh {\lfloor \mathcal{D} \rfloor} {A} {\sigma} \qquad t \equiv \Coh {\lfloor \mathcal{D} \sslash p \rfloor} {A \sub {\pi_p}} {\sigma \sslash p}\]
  where \(s\) is not an identity and \(\lfloor p \rfloor \sub \sigma\) is. We then have \(\sc(s) = \sc(\sigma)\) and \(\sc(t) = \sc(\sigma \sslash p)\), but \(\sigma \sslash p\) is simply \(\sigma\) with two terms removed, one of which is known to be a coherence, and so \(\sc(s) > \sc(t)\).
\end{proof}
\begin{corollary}
  The reduction \(\red_{\su'}\) is strongly terminating.
\end{corollary}
\begin{proof}
  By \cref{cor:strong-term}, it suffices to show that each rule of \(\su'\) reduces syntactic complexity, which follows from the preceding proposition and \cref{prop:ecr-sc,prop:disc-rem-sc}.
\end{proof}

By \cref{prop:red-is-eq}, we know that the reflexive symmetric transitive closure of \(\red_{\su'}\) is the equality relation generated by \su'. We therefore prove that this agrees with the equality relation from \Cattsu.

\begin{proposition}
  The type theories generated from \su and \su' are equivalent. Terms are equal or well-formed in one theory exactly when they are equal or well-formed in the other, and similar properties hold for types and substitutions.
\end{proposition}
\begin{proof}
  We use \cref{lem:subset-lem} for both directions. Since \(\su' \subseteq \su\), we are only required to show that if \((\Gamma, s, t) \in \su\) with \(\Gamma \vdash_\su s : A\) for some \(A : \Type_\Gamma\) then
  \[ \Gamma \vdash_{\su'} s = t\]
  If \((\Gamma,s,t) \in \su'\), then the equality follows from the \textsc{rule} constructor. Otherwise, \(s\) must be an identity and the rule is an instance of endo-coherence removal or pruning. Suppose \(s\) reduces to \(t\) by endo-coherence removal. Then \(s \equiv \id(A,u)\) and
  \[t \equiv \id(\wk(U^n) \sub {\{A,u\}}, d_n \sub \{A,u\}) \equiv \id(A,u) \equiv s\]
  and so the equality holds by reflexivity.

  Now assume \(s\) reduces by pruning to \(t\). Letting \(s \equiv \id(A,u)\) and \(n = \dim(A)\), we get:
  \begin{align*}
    t &\equiv \Coh {\lfloor \mathcal{D}^n \sslash p^n \rfloor} {\arr {d_n} {\wk(U^n)} {d_n} \sub {\pi_{p^n}}} {\{A,u\} \sslash p} \\
      &= \id(\wk(U^n) \sub {\pi_{p^n}} \sub {\{A,u\} \sslash p^n}, d_n \sub {\pi_{p^n}} {\{A,u\} \sslash p^n})&\text{by endo-coherence removal}\\
      &\equiv \id(\wk(U^n),d_n) \sub {\pi_{p^n} \bullet \{A,u\} \sslash p^n}\\
      &= \id(\wk(U^n),d_n) \sub {\{A,u\}}&\text{by \cref{prop:prune-ty}}\\
      &\equiv \id(\wk(U^n) \sub {\{A,u\}}, d_n \sub {\{A,u\}})\\
    &\equiv \id(A,u)
  \end{align*}
  and so the equality holds as required.
\end{proof}

We therefore have that two terms \(s\) and \(t\) are equal in \Cattsu if and only if \(s \red_{\su'}^{\mathsf{rts}} t\). To demonstrate normalisation, it therefore remains to show that the reduction scheme is confluent, for which we employ the strategy introduced in \cref{lem:conf-strat}.

\begin{theorem}
  The reduction \(\red_{\su'}\) is confluent.
\end{theorem}
\begin{proof}
  By \cref{lem:conf-strat} it is sufficient to show that for all \(t \leftsquigarrow s \rightsquigarrow u\) with \(s \rightsquigarrow t\) being a reduction derived from \textsc{rule}, that the following diagram can be formed:
    \[
    \begin{tikzcd}[column sep=tiny]
      && s \\
      t &&&& u \\
      & {t'} & {\mathclap{=_{\dim(s)}}} & {u'}
      \arrow[squiggly, from=1-3, to=2-5]
      \arrow[squiggly, from=1-3, to=2-1]
      \arrow["{*}"', squiggly, from=2-1, to=3-2]
      \arrow["{*}", squiggly, from=2-5, to=3-4]
    \end{tikzcd}
  \]
  We therefore begin by case splitting on the reduction \(s \red t\), ignoring cases where both reductions are identical and ignoring cases which follow by symmetry of other cases.

  \textbf{Disc removal:} Suppose \(s \red t\) is a disc removal reduction. Then \(s \equiv \Coh {D^n} {\wk(U^n)} {\{A,t\}}\). We now split on the reduction \(s \red u\). We immediately know that \(s \red u\) cannot be an endo-coherence removal reduction, as \(s\) is not an endo-coherence. It also cannot be a cell reduction as \(wk(U^n)\) only contains variables and so is in normal form.

  Let \(s \red u\) be an argument reduction. It must therefore be generated by a reduction on \(\{A,t\}\). If it is a reduction generated by \(A \red A'\) then \(u \red t\) by endo-coherence removal and so we are done. Otherwise it is generated by \(t \red t'\) and so \(t\) and \(u\) both reduce by disc removal to \(t'\).

  The only remaining case is where \(s \red u\) is an instance of pruning, which forces \(t \equiv \id(B,a)\) for some \(B\) and \(a\). As \(s\) is well-formed, we must have \(n > 0\) and so \(A \equiv \arr b {A'} c\). Therefore:
  \begin{align*}
    u &\equiv \Coh {\lfloor \mathcal{D}^{n} \sslash p \rfloor} {\wk(U^n) \sub {\pi_{p}}} {\{A,\id(B,a)\} \sslash p}\\
      &\equiv \Coh {D^{n-1}} {\wk(U^n) \sub {\{\arr {d_{n-1}} {\wk(U^{n-1})} {d_{n-1}}, \id(\wk(U^{n-1}), d_{n-1})\} \}}} {\{A',b\}}&\text{by \cref{prop:prune-disc}}\\
      &\equiv \Coh {D^{n-1}} {\arr {d_{n-1}} {\wk(U^{n-1})} {d_{n-1}}} {\{A',b\}}\\
    &\equiv \id(A',b)
  \end{align*}
  Now as \(s\) is well-formed we have \(\Gamma \vdash \{A,\id(B,a)\} : D^n\) and so by \cref{lem:disc-typing}, \(\Gamma \vdash \id(B,a) : A\) and hence by \cref{cor:id-typing} and uniqueness of typing:
  \[ \arr a {B} a = A \equiv \arr b {A'} c\]
  and so \(a = b\) and \(B = A'\) and hence \(s \equiv \id(A', b) = \id(B,a) \equiv t\). Finally, since \(\dim(a) = \dim(B) < \dim(s)\), we get \(t =_{\dim(s)} u\) as required.

  \textbf{Endo coherence removal:} Suppose \(s \red t\) is an endo-coherence removal reduction. Then:
  \[ s \equiv \Coh {\Delta} {\arr a A a} {\sigma} \red \id(A \sub \sigma, a \sub \sigma) \equiv t\]
  with \(s\) not being an identity.
  We now split on the reduction \(s \red u\). First consider when it is an argument reduction generated by \(\sigma \red \tau\). Then by \cref{prop:red-sub} \(t \equiv \id(A \sub \sigma, a \sub \sigma) \red^* \id(A \sub \tau, a \sub \tau)\). By endo-coherence removal \(u \red \id(A \sub \tau, a \sub \tau)\), completing this case.

  Now suppose the reduction \(s \red u\) is an instance of cell reduction. If it is generated from a reduction \(A \red B\) then by \cref{prop:red-sub}, \(t \red \id(B \sub \sigma, a \sub \sigma)\) and by endo-coherence removal:
  \[u \equiv \Coh \Delta {\arr a B a} \sigma \red \id(B \sub \sigma, a \sub \sigma)\]
  We now consider when the reduction is generated by \(\arr a A a \red \arr b A a\), with the case where it is generated by \(\arr a A a \red \arr a A b\) following symmetrically. We consider the reductions sequence  from \(u\):
  \begin{align*}
    u &\equiv \Coh \Delta {\arr b A a} {\sigma} \\
      &\red \Coh \Delta {\arr b A b} \sigma &\text{by cell reduction}\\
    &\red \id(A\sub \sigma,b\sub \sigma) &\text{by endo-coherence removal}
  \end{align*}
  Again by \cref{prop:red-sub}, \(t \equiv \id(A\sub\sigma,a\sub\sigma) \red \id(A\sub\sigma,b\sub\sigma)\), completing the case.

  Lastly, we consider when \(s \red u\) is a pruning reduction. We suppose \(\Delta = \lfloor \mathcal{D} \rfloor\) and that the pruning is generated from peak \(p : \mathcal{D}\). Then:
  \[ u \equiv \Coh {\lfloor \mathcal{D} \sslash p \rfloor} {(\arr a A a) \sub {\pi_p}} {\sigma \sslash p}\]
  Then:
  \begin{align*}
    u &\red \id(A \sub {\pi_p} \sub {\sigma\sslash p},a \sub {\pi_p} \sub {\sigma\sslash p})&\text{by \cref{lem:always-ecr}}\\
      &\equiv \id(A,a) \sub {\pi_p \bullet \sigma \sslash p} \\
    &=_{\dim(s)} \id(A,a) \sub \sigma
  \end{align*}
  where the last (bounded) equality is by \cref{prop:prune-ty} and by noting that \(\dim(A) = \dim(a) < \dim(s)\).

  \textbf{Pruning:} Let \(s \red t\) be a reduction by pruning with
  \[ s \equiv \Coh {\lfloor \mathcal{D} \rfloor} A \sigma\]
  for some \(\mathcal{D} : \Dyck_0\) with peak \(p : \Peak_{\mathcal{D}}\) such that \(\lfloor p \rfloor \sub \sigma\) is an identity. Then:
  \[ t \equiv \Coh {\lfloor \mathcal{D} \sslash p \rfloor} {A \sub {\pi_p}} {\sigma \sslash p}\]
  We now split on the reduction \(s \red u\). First suppose it is given by an argument reduction \(\sigma \red \tau\). Identities do not admit head reductions, meaning \(\lfloor p \rfloor \sub \tau\) is still an identity. Therefore pruning can be applied to \(u\) to get:
  \[ u \red \Coh {\lfloor \mathcal{D} \sslash p \rfloor} {A \sub {\pi_p}} {\tau \sslash p}\]
  Now \(\sigma \sslash p\) is simply \(\sigma\) with two terms removed, and so \(\sigma \sslash p \red^* \tau \sslash p\), meaning \(t\) reduces to the same term as \(u\).

  If \(s \red u\) is a cell reduction \(A \red B\), then pruning can be applied to \(u\) immediately to get the term:
  \[\Coh {\lfloor \mathcal{D} \sslash p \rfloor} {B \sub {\pi_p}} {\sigma \sslash p}\]
  but \(t\) also reduces to this term by \cref{prop:red-sub}.

  Finally, let \(s \red u\) be a second pruning reduction, at a different peak \(q : \Peak_{\mathcal{D}}\). By \cref{prop:prune-conf}, there is a common reduct:
  \[ \Coh {\lfloor (\mathcal{D} \sslash p) \sslash q_p \rfloor} {A \sub {\pi_p} \sub{\pi_{q_p}}} {(\sigma \sslash p) \sslash q_p} \]
  which both reduce to by pruning if \(\lfloor q_p \rfloor\) and \(\lfloor p_q \rfloor\) are identities. However:
  \[\lfloor q_p \rfloor \equiv \lfloor q \rfloor \sub {\pi_p}\]
  and \(\lfloor q \rfloor\) must be an identity for \(s \red u\) to be a valid instance of pruning. Therefore, as identities are preserved by application of substitution, \(\lfloor  q_p \rfloor\) is an identity. Similarly \(\lfloor p_q \rfloor\) is an identity, and so both \(t\) and \(u\) reduce to the term above.

  Any remaining cases follow by symmetry, completing the proof.
\end{proof}

\subsection{Disc trivalisation}
\label{sec:properties-cattsu}

We take a brief moment to explore the theory \Cattsu in its entirety. For this section we will further assume that we take the set of operations \(\mathcal{O}\) to be the regular operations.

We begin by proving a property of terms over disc contexts, which we call \emph{disc trivialisation}. This is the following structure theorem: in a disc context \(D^n\), every term is either a variable, or the iterated identity on a variable, up to definitional equality. Restricting to those terms \(t : \Term_{D^n}\) that are full, that is \(\supp(t) = \Var{D^n}\), then there is exactly one term (up to definitional equality) at each dimension \(k \geq n\). Hence, the type theory \Cattsu trivialises disc contexts.

\todo[inline]{Link to other paper}

We now state and prove disc trivialisation, recalling the definition of an iterated canonical identity from \cref{def:canonical-id}.

\begin{theorem}[Disc trivialisation]
  Suppose \(D^n \vdash t : A\) in \Cattsu. Then \(t\) is equal to an iterated canonical identity on a variable, that is \(t = \id^k(x)\) for some variable \(x \in \Var(D^n)\) and \(k \in \mathbb{N}\).
\end{theorem}
\begin{proof}
  Without loss of generality, we may assume that \(t\) is in \Cattsu normal form, and proceed to prove that \(t\) is an iterated canonical identity. We proceed by induction on subterms of the term \(t\). If \(t\) is a variable then we are done. Otherwise, we assume \(t\) is a coherence term \(\Coh \Delta U \sigma\).

  We now show that \(\Delta\) must be a disc context by contradiction. We therefore assume that \(\Delta\) is not a disc, and hence \(t\) is not an identity. By induction on subterms, we must have that each term in \(\sigma\) is an iterated canonical identity on a variable. No locally maximal argument of can be an identity, as otherwise pruning could be performed and \(t\) would not be in normal form, and so every locally maximal argument is a variable. Suppose there is some variable \(x\) such that \(x \sub\sigma\) is an identity, and let \(x\) be be a variable of maximal dimension with this property. As \(x\) cannot be locally maximal, there must either be the source or target of a variable \(y\), but this variable \(y\) must be sent to a variable of \(D^n\), which cannot have an identity as its source or target. Therefore the substitution \(\sigma\) is variable to variable.

  We now let \(\Gamma\) be the smallest ps-context prefix of \(\Delta\) such that \(\Gamma\) is not a disc. We must have:
  \[ \Gamma \equiv D^k, (y : A), (f : \arr x A y)\]
  where \(D^k \vdash_{\mathsf{ps}} x : A\). Furthermore, the last rule used in this derivation must be \textsc{psd}, as if it were \textsc{pse} or \textsc{pss} then \(k = \dim(A)\) and \(\Gamma \equiv D^{k+1}\), breaking the assumption that \(\Gamma\) is not a disc. Therefore \(D^k \vdash_{\mathsf{ps}} g : \arr w A x\) for some variables \(g\) and \(x\). However, now \(g \sub \sigma\), \(x \sub \sigma\), and \(f \sub \sigma\) are variables of \(D^n\) such that \(\tgt(g \sub \sigma) \equiv x \sub \sigma \equiv \src(f \sub \sigma)\). No such variables exist in \(D^n\) and so we reach a contradiction. We therefore deduce that \(\Delta\) is a disc \(D^n\) for some \(n\).

  Now \(t \equiv \Coh {D^n} {\arr u A v} \sigma\) and so by induction on subterms, \(u\) and \(v\) are equal to iterated canonical identities. We now split on whether \(t\) is a composition or equivalence. If it is a composition then \(\Supp(u) = \bdry {n-1} - {D^n}\) and \(\Supp(v) = \bdry {n-1} + {D^n}\) and therefore neither \(u\) or \(v\) are identities (as then \(A\) would have the same support as \(u\) or \(v\) respectively) and so \(u = d_{n-1}^-\) and \(v = d_{n-1}^*\), but this makes \(t\) a disc removal redex, and so \(t\) is not in normal form.

  We therefore assume that \(t\) is an equivalence and \(u\) and \(v\) are full. Then \(u\) and \(v\) must be iterated identities on \(d_n\), and must have the same dimension and so are syntactically equal. To avoid \(t\) being an endo-coherence removal redex, it must be an identity \(\id(B,s)\). Now, \(s \equiv \id^k(x)\) for some variable \(x\) (as \(s\) is a subterm of \(t\)), and so if \(k = 0\) then \(\ty(s) \equiv d_{n-1}^- \to d_{n-1}^+\) and if \(k > 0\) then \(\ty(s) \equiv \id^{k-1}(x) \to \id^{k-1}(x)\). In either case, \(\ty(s)\) is in normal form, and so since \(B\) is also a normal form and \(\Gamma \vdash s : B\) (by the well-typing of \(t\) and \cref{cor:id-typing}), we have \(B \equiv \ty(s)\) and so \(t \equiv \id(s) \equiv \id^{k+1}(x)\) as required.
\end{proof}

\todo[inline]{Isos of ps contexts}


\section{\Cattsua}
\label{sec:cattsua}

\section{Towards normalisation by evaluation}
\label{sec:towards-nbe}

\todo[inline]{Explain implementation in depth}

\section{Models}
\label{sec:models}

\todo[inline]{Define models}

\todo[inline]{Give free models as yoneda embedding}
\todo[inline]{Can view contexts as \(\infty\)-categories}

\subsection{Rehydration for Pasting diagram}
\label{sec:rehydration}

\todo[inline]{Can give conservativity result}
\todo[inline]{Support is pasting diagram}
\todo[inline]{Define rehydration, giving general structure}

\todo[inline]{Semistrictness is property}

\todo[inline]{Functors of models?}

\subsection{Towards generalised rehydration}
\label{sec:towards-gener-rehydr}

\todo[inline]{Explain original motivation}

\todo[inline]{Explain connection to equivalence}

\todo[inline]{Same structure as for pasting diagrams}
\todo[inline]{Need to form normalisers}
\todo[inline]{core problem with rehydration}


\paragraph{Rehydration by dimension}

\paragraph{Rehydration by cylinders}

\section{Further theories}
\label{sec:further-theories}

\todo[inline]{Generalised insertion}

\todo[inline]{Endo-coherence removal variation?}

\todo[inline]{Missing equation from grey categories}

\todo[inline]{Interchange and generalised pasting diagrams}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% References:
%%

\printbibliography

\end{document}
