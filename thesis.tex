\documentclass[techreport]{cam-thesis}

\usepackage{packages}
\usepackage{macros}
\addbibresource{thesis.bib}

\title{A type-theoretic approach to semistrict higher categories}

%% The full name of the author (e.g.: James Smith):
\author{Alex Rice}

%% College affiliation:
\college{Darwin College}

%% College shield:
\collegeshield{CollegeShields/Darwin}

%% Submission date [optional]:
\submissiondate{TODO}

%% Declaration date:
\date{TODO}

%% PDF meta-info:
\subjectline{Computer Science}
\keywords{category theory, higher category theory, type theory}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Abstract:
%%
\abstract{%
  Abstract to go here...
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Acknowledgements:
%%
\acknowledgements{%
  My acknowledgements ...
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Contents:
%%
\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Title page, abstract, declaration etc.:
%% -    the title page (is automatically omitted in the technical report mode).
\frontmatter{}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Thesis body:
%%
\chapter{Introduction}
Things to go in introduction:
\begin{itemize}
\item Motivation for higher categories
\item Motivation for semistrictness
\item Introduce 3 classes of coherences
\item Ideas of semistrictness
\item Existing 3-dimensional semistrictness results
\item Link to graphical ideas
\item Story behind Catt - HoTT - Brunerei
\item Link to Grothedieck higher cats
\end{itemize}

\chapter{Background}
\label{sec:background}

We begin with an overview of the important concepts required for the rest of the thesis. Throughout, we will assume knowledge of various basic concepts from computer science, as well as a basic knowledge of category theory (including functor categories, presheafs, and (co)limits) and type theory. The following sections introduce a form of globular higher categories and give a definition of the type theory \Catt, close to the original definition.

This section additionally serves as a place to introduce the various syntax and notation which will be used throughout the rest of the thesis.

\section{Higher categories}
\label{sec:higher-categories}

A higher category is a generalisation of the ordinary notion of a category to allow higher dimensional structure. This manifests in the form of allowing arrows or morphisms to have their source or target be another morphism instead of an object. More precisely, higher categories are equipped with the notion of an \(n\)-cell, where an \((n+1)\)-cell has source and target \(n\)-cells, and \(0\)-cells play the role of objects in an ordinary category. There are many differing definitions of higher categories (see \cite{leinster2001survey}), some of which use different shapes of cell. In this thesis, we will study globular higher categories, in particular those defined by the type theory \Catt~\cite{finster2017type}, which are known to be equivalent to a definition of \citeauthor{maltsiniotis2010grothendieck}~\cite{maltsiniotis2010grothendieck} based off an earlier definition by \citeauthor{PursuingStacks}~\cite{PursuingStacks}, which we introduce in \cref{sec:weak}.

The role of objects is played by \(0\)-cells, with \(1\)-cells as the morphisms between these objects. For \(0\)-cells \(x\) and \(y\), a \(1\)-cell \(f\) with source \(x\) and target \(y\) will be drawn as:
\[
  \begin{tikzcd}
    x & y
    \arrow["f", from=1-1, to=1-2]
  \end{tikzcd}
\]
or may be written as \(f: x \to y\). Two cells are \emph{parallel} if they have the same source and target. Between any two parallel \(n\)-cells \(f\) and \(g\), we have a set of \((n+1)\)-cells between them. A \(2\)-cell \(\alpha : f \to g\) may be drawn as:
\[
  \begin{tikzcd}
    x & y
    \arrow[""{name=0, anchor=center, inner sep=0}, "f", curve={height=-12pt}, from=1-1, to=1-2]
    \arrow[""{name=1, anchor=center, inner sep=0}, "g"', curve={height=12pt}, from=1-1, to=1-2]
    \arrow["\alpha", shorten <=3pt, shorten >=3pt, Rightarrow, from=1, to=0]
  \end{tikzcd}
\]
and a \(3\)-cell \(\gamma\) between parallel \(2\)-cells \(\alpha\) and \(\beta\) could be could be drawn as:
\[
  \begin{tikzcd}
    x && y
    \arrow[""{name=0, anchor=center, inner sep=0}, "f", curve={height=-15pt}, from=1-1, to=1-3]
    \arrow[""{name=1, anchor=center, inner sep=0}, "g"', curve={height=15pt}, from=1-1, to=1-3]
    \arrow[""{name=2, anchor=center, inner sep=0}, "\alpha", shift left=4, shorten <=3pt, shorten >=3pt, Rightarrow, from=1, to=0]
    \arrow[""{name=3, anchor=center, inner sep=0}, "\beta"', shift right=4, shorten <=3pt, shorten >=3pt, Rightarrow, from=1, to=0]
    \arrow["\gamma", shorten <=4pt, shorten >=4pt, Rightarrow, nfold=3, from=2, to=3]
  \end{tikzcd}
\]

Just as in ordinary \(1\)-category theory, we expect to be able to compose morphisms. For \(1\)-cells, nothing has changed, given \(1\)-cells \(f: x \to y\) and \(g : y \to z\) we form the composition \(f * g\):
\[
  \begin{tikzcd}
    x & y & z
    \arrow[from=1-1, to=1-2, "f"]
    \arrow[from=1-2, to=1-3, "g"]
  \end{tikzcd}
\]
which has source \(x\) and target \(z\). We pause here to note that composition will be given in ``diagrammatic order'' throughout the whole thesis, which is the opposite of the order of function composition but the same as the order of the arrows if drawn head to tail. This is chosen as it will be common for us to draw higher dimensional arrows in a diagram, and rare for us to consider categories where the higher arrows are given by functions. In an attempt to avoid confusion, we use an asterisk (\(*\)) to represent composition of arrows or cells in a higher category, and will use a circle (\(\circ\)) only for function composition.

In two dimensions, there is no longer a singular composition operation. For \(2\)-cells \(\alpha : f \to g\) and \(\beta : g \to h\), the composite \(\alpha *_1 \beta\) can be formed as before:
% https://q.uiver.app/#q=WzAsMixbMCwwLCJcXGJ1bGxldCJdLFsyLDAsIlxcYnVsbGV0Il0sWzAsMSwiZiIsMCx7ImN1cnZlIjotNH1dLFswLDEsImgiLDIseyJjdXJ2ZSI6NH1dLFswLDEsImciLDFdLFsyLDQsIlxcYWxwaGEiLDAseyJzaG9ydGVuIjp7InNvdXJjZSI6MjAsInRhcmdldCI6MjB9fV0sWzQsMywiXFxiZXRhIiwwLHsic2hvcnRlbiI6eyJzb3VyY2UiOjIwLCJ0YXJnZXQiOjIwfX1dXQ==
\[
  \begin{tikzcd}
    x && y
    \arrow[""{name=0, anchor=center, inner sep=0}, "f"', curve={height=24pt}, from=1-1, to=1-3]
    \arrow[""{name=1, anchor=center, inner sep=0}, "h", curve={height=-24pt}, from=1-1, to=1-3]
    \arrow[""{name=2, anchor=center, inner sep=0}, "g"{description}, from=1-1, to=1-3]
    \arrow["\alpha", shorten <=3pt, shorten >=3pt, Rightarrow, from=0, to=2]
    \arrow["\beta", shorten <=3pt, shorten >=3pt, Rightarrow, from=2, to=1]
  \end{tikzcd}
\]

We refer to this composition as \emph{vertical composition}. We can also compose cells \(\alpha\) and \(\beta\) in the following way:

% https://q.uiver.app/#q=WzAsMyxbMCwwLCJ4Il0sWzEsMCwieSJdLFsyLDAsInoiXSxbMCwxLCIiLDAseyJjdXJ2ZSI6LTN9XSxbMCwxLCIiLDIseyJjdXJ2ZSI6M31dLFsxLDIsIiIsMix7ImN1cnZlIjotM31dLFsxLDIsIiIsMix7ImN1cnZlIjozfV0sWzMsNCwiXFxhbHBoYSIsMCx7InNob3J0ZW4iOnsic291cmNlIjoyMCwidGFyZ2V0IjoyMH19XSxbNSw2LCJcXGJldGEiLDAseyJzaG9ydGVuIjp7InNvdXJjZSI6MjAsInRhcmdldCI6MjB9fV1d
\[
  \begin{tikzcd}
    x & y & z
    \arrow[""{name=0, anchor=center, inner sep=0}, "g", curve={height=-18pt}, from=1-1, to=1-2]
    \arrow[""{name=1, anchor=center, inner sep=0}, "f"', curve={height=18pt}, from=1-1, to=1-2]
    \arrow[""{name=2, anchor=center, inner sep=0}, "i", curve={height=-18pt}, from=1-2, to=1-3]
    \arrow[""{name=3, anchor=center, inner sep=0}, "h"', curve={height=18pt}, from=1-2, to=1-3]
    \arrow["\alpha", shorten <=5pt, shorten >=5pt, Rightarrow, from=1, to=0]
    \arrow["\beta", shorten <=5pt, shorten >=5pt, Rightarrow, from=3, to=2]
  \end{tikzcd}
\]

This composition is called the \emph{horizontal composition}, and is written \(\alpha *_0 \beta\). The subscript refers to the dimension of the shared boundary in the composition, with the \(1\)-cell \(g\) being the shared boundary in the vertical composition example and the \(0\)-cell \(y\) being the shared boundary in the horizontal composition example. The dimension of this shared boundary is the \emph{codimension} of the composition.

This pattern continues with \(3\)-cells, which can be composed at codimension \(0\), \(1\), or \(2\), as below:

% https://q.uiver.app/#q=WzAsNyxbMiwwLCJcXGJ1bGxldCJdLFswLDAsIlxcYnVsbGV0Il0sWzMsMCwiXFxidWxsZXQiXSxbNSwwLCJcXGJ1bGxldCJdLFs2LDAsIlxcYnVsbGV0Il0sWzcsMCwiXFxidWxsZXQiXSxbOCwwLCJcXGJ1bGxldCJdLFsxLDAsIiIsMCx7ImN1cnZlIjotM31dLFsxLDAsIiIsMix7ImN1cnZlIjozfV0sWzIsMywiIiwwLHsiY3VydmUiOi00fV0sWzIsMywiIiwyLHsiY3VydmUiOjR9XSxbMiwzXSxbNCw1LCIiLDAseyJjdXJ2ZSI6LTN9XSxbNCw1LCIiLDIseyJjdXJ2ZSI6M31dLFs1LDYsIiIsMix7ImN1cnZlIjotM31dLFs1LDYsIiIsMix7ImN1cnZlIjozfV0sWzgsNywiIiwyLHsib2Zmc2V0IjotNSwic2hvcnRlbiI6eyJzb3VyY2UiOjIwLCJ0YXJnZXQiOjIwfX1dLFs4LDcsIiIsMCx7Im9mZnNldCI6NSwic2hvcnRlbiI6eyJzb3VyY2UiOjIwLCJ0YXJnZXQiOjIwfX1dLFs4LDcsIiIsMix7InNob3J0ZW4iOnsic291cmNlIjoyMCwidGFyZ2V0IjoyMH19XSxbMTAsMTEsIiIsMix7Im9mZnNldCI6LTQsInNob3J0ZW4iOnsic291cmNlIjoyMCwidGFyZ2V0IjoyMH19XSxbMTAsMTEsIiIsMCx7Im9mZnNldCI6NCwic2hvcnRlbiI6eyJzb3VyY2UiOjIwLCJ0YXJnZXQiOjIwfX1dLFsxMSw5LCIiLDEseyJvZmZzZXQiOi00LCJzaG9ydGVuIjp7InNvdXJjZSI6MjAsInRhcmdldCI6MjB9fV0sWzExLDksIiIsMSx7Im9mZnNldCI6NCwic2hvcnRlbiI6eyJzb3VyY2UiOjIwLCJ0YXJnZXQiOjIwfX1dLFsxMywxMiwiIiwyLHsib2Zmc2V0IjotMywic2hvcnRlbiI6eyJzb3VyY2UiOjIwLCJ0YXJnZXQiOjIwfX1dLFsxMywxMiwiIiwwLHsib2Zmc2V0IjozLCJzaG9ydGVuIjp7InNvdXJjZSI6MjAsInRhcmdldCI6MjB9fV0sWzE1LDE0LCIiLDIseyJvZmZzZXQiOi0zLCJzaG9ydGVuIjp7InNvdXJjZSI6MjAsInRhcmdldCI6MjB9fV0sWzE1LDE0LCIiLDAseyJvZmZzZXQiOjMsInNob3J0ZW4iOnsic291cmNlIjoyMCwidGFyZ2V0IjoyMH19XSxbMTYsMTgsIlxcZ2FtbWEiLDAseyJzaG9ydGVuIjp7InNvdXJjZSI6MjAsInRhcmdldCI6MjB9fV0sWzE4LDE3LCJcXGRlbHRhIiwwLHsic2hvcnRlbiI6eyJzb3VyY2UiOjIwLCJ0YXJnZXQiOjIwfX1dLFsyMSwyMiwiXFxnYW1tYSIsMCx7InNob3J0ZW4iOnsic291cmNlIjoyMCwidGFyZ2V0IjoyMH19XSxbMTksMjAsIlxcZGVsdGEiLDAseyJzaG9ydGVuIjp7InNvdXJjZSI6MjAsInRhcmdldCI6MjB9fV0sWzIzLDI0LCJcXGdhbW1hIiwwLHsic2hvcnRlbiI6eyJzb3VyY2UiOjIwLCJ0YXJnZXQiOjIwfX1dLFsyNSwyNiwiXFxkZWx0YSIsMCx7InNob3J0ZW4iOnsic291cmNlIjoyMCwidGFyZ2V0IjoyMH19XV0=
\[
  \begin{tikzcd}
    \bullet && \bullet & \bullet && \bullet & \bullet & \bullet & \bullet
    \arrow[""{name=0, anchor=center, inner sep=0}, curve={height=-18pt}, from=1-1, to=1-3]
    \arrow[""{name=1, anchor=center, inner sep=0}, curve={height=18pt}, from=1-1, to=1-3]
    \arrow[""{name=2, anchor=center, inner sep=0}, curve={height=-24pt}, from=1-4, to=1-6]
    \arrow[""{name=3, anchor=center, inner sep=0}, curve={height=24pt}, from=1-4, to=1-6]
    \arrow[""{name=4, anchor=center, inner sep=0}, from=1-4, to=1-6]
    \arrow[""{name=5, anchor=center, inner sep=0}, curve={height=-18pt}, from=1-7, to=1-8]
    \arrow[""{name=6, anchor=center, inner sep=0}, curve={height=18pt}, from=1-7, to=1-8]
    \arrow[""{name=7, anchor=center, inner sep=0}, curve={height=-18pt}, from=1-8, to=1-9]
    \arrow[""{name=8, anchor=center, inner sep=0}, curve={height=18pt}, from=1-8, to=1-9]
    \arrow[""{name=9, anchor=center, inner sep=0}, shift left=5, shorten <=5pt, shorten >=5pt, Rightarrow, from=1, to=0]
    \arrow[""{name=10, anchor=center, inner sep=0}, shift right=5, shorten <=5pt, shorten >=5pt, Rightarrow, from=1, to=0]
    \arrow[""{name=11, anchor=center, inner sep=0}, shorten <=5pt, shorten >=5pt, Rightarrow, from=1, to=0]
    \arrow[""{name=12, anchor=center, inner sep=0}, shift left=4, shorten <=3pt, shorten >=3pt, Rightarrow, from=3, to=4]
    \arrow[""{name=13, anchor=center, inner sep=0}, shift right=4, shorten <=3pt, shorten >=3pt, Rightarrow, from=3, to=4]
    \arrow[""{name=14, anchor=center, inner sep=0}, shift left=4, shorten <=3pt, shorten >=3pt, Rightarrow, from=4, to=2]
    \arrow[""{name=15, anchor=center, inner sep=0}, shift right=4, shorten <=3pt, shorten >=3pt, Rightarrow, from=4, to=2]
    \arrow[""{name=16, anchor=center, inner sep=0}, shift left=3, shorten <=5pt, shorten >=5pt, Rightarrow, from=6, to=5]
    \arrow[""{name=17, anchor=center, inner sep=0}, shift right=3, shorten <=5pt, shorten >=5pt, Rightarrow, from=6, to=5]
    \arrow[""{name=18, anchor=center, inner sep=0}, shift left=3, shorten <=5pt, shorten >=5pt, Rightarrow, from=8, to=7]
    \arrow[""{name=19, anchor=center, inner sep=0}, shift right=3, shorten <=5pt, shorten >=5pt, Rightarrow, from=8, to=7]
    \arrow["\gamma", shorten <=2pt, shorten >=2pt, Rightarrow, nfold=3, from=9, to=11]
    \arrow["\delta", shorten <=2pt, shorten >=2pt, Rightarrow, nfold=3, from=11, to=10]
    \arrow["\gamma", shorten <=3pt, shorten >=3pt, Rightarrow, nfold=3, from=14, to=15]
    \arrow["\delta", shorten <=3pt, shorten >=3pt, Rightarrow, nfold=3, from=12, to=13]
    \arrow["\gamma", shorten <=2pt, shorten >=2pt, Rightarrow, nfold=3, from=16, to=17]
    \arrow["\delta", shorten <=2pt, shorten >=2pt, Rightarrow, nfold=3, from=18, to=19]
  \end{tikzcd}
\]

For every \(n\)-cell \(x\), there is an \((n+1)\)-cell \(\id(x) : x \to x\), called the \emph{identity morphism}.

As with 1-categories, \(\infty\)-categories need to satisfy certain equalities, which fall into 3 groups: associativity, unitality, and interchange. The associativity laws are the same as for 1-categories, only now a law is needed for each composition (every dimension and codimension).

Unitality is again similar to the case for 1-categories, except we again need unitality laws for each composition. We note that for lower codimension compositions, an iterated identity is needed. For example given a \(2\)-cell \(\alpha : f \to g\), the appropriate equation for left unitality of horizontal composition is:
\[ \id(\id(x)) *_0 \alpha = \alpha \]
In general for a unit to be cancelled, it must be iterated a number of times equal to the difference between the dimension and codimension of the composition.

Interchange laws do not appear in 1-categories, and specify how compositions of different dimensions interact. The first interchange law states that for suitable \(2\)-cells \(\alpha\), \(\beta\), \(\gamma\), and \(\delta\), that:
\[ (\alpha *_0 \gamma) *_1 (\beta *_0 \delta) = (\alpha *_1 \beta) *_0 ()\]
This can be diagrammatically depicted as:
\newsavebox{\innertop}
\savebox{\innertop}{
  \adjustbox{scale=0.8}{\begin{tikzcd}[ampersand replacement=\&,column sep=small]
    \bullet \& \bullet \& \bullet
    \arrow[""{name=0, anchor=center, inner sep=0}, curve={height=-12pt}, from=1-1, to=1-2]
    \arrow[""{name=1, anchor=center, inner sep=0}, curve={height=12pt}, from=1-1, to=1-2]
    \arrow[""{name=2, anchor=center, inner sep=0}, curve={height=-12pt}, from=1-2, to=1-3]
    \arrow[""{name=3, anchor=center, inner sep=0}, curve={height=12pt}, from=1-2, to=1-3]
    \arrow["\alpha", shorten <=3pt, shorten >=3pt, Rightarrow, from=1, to=0]
    \arrow["\gamma", shorten <=3pt, shorten >=3pt, Rightarrow, from=3, to=2]
  \end{tikzcd}}}
\newsavebox{\innerbot}
\savebox{\innerbot}{
  \adjustbox{scale=0.8}{\begin{tikzcd}[ampersand replacement=\&,column sep=small]
    \bullet \& \bullet \& \bullet
    \arrow[""{name=0, anchor=center, inner sep=0}, curve={height=-12pt}, from=1-1, to=1-2]
    \arrow[""{name=1, anchor=center, inner sep=0}, curve={height=12pt}, from=1-1, to=1-2]
    \arrow[""{name=2, anchor=center, inner sep=0}, curve={height=-12pt}, from=1-2, to=1-3]
    \arrow[""{name=3, anchor=center, inner sep=0}, curve={height=12pt}, from=1-2, to=1-3]
    \arrow["\beta", shorten <=3pt, shorten >=3pt, Rightarrow, from=1, to=0]
    \arrow["\delta", shorten <=3pt, shorten >=3pt, Rightarrow, from=3, to=2]
  \end{tikzcd}}}
\newsavebox{\innerleft}
\savebox{\innerleft}{
  \adjustbox{scale=1}{\begin{tikzcd}[ampersand replacement=\&,column sep=small,cramped]
    \bullet \& \bullet
    \arrow[""{name=0, anchor=center, inner sep=0}, controls=+(80:0.7) and +(100:0.7),, from=1-1, to=1-2]
    \arrow[""{name=1, anchor=center, inner sep=0}, curve={height=0}, from=1-1, to=1-2]
    \arrow[""{name=2, anchor=center, inner sep=0}, controls=+(100:-0.7) and +(80:-0.7),, from=1-1, to=1-2]
    \arrow["\alpha", shorten <=3pt, shorten >=3pt, Rightarrow, from=2, to=1]
    \arrow["\beta", shorten <=3pt, shorten >=3pt, Rightarrow, from=1, to=0]
  \end{tikzcd}}}
\newsavebox{\innerright}
\savebox{\innerright}{
  \adjustbox{scale=1}{\begin{tikzcd}[ampersand replacement=\&,column sep=small,cramped]
    \bullet \& \bullet
    \arrow[""{name=0, anchor=center, inner sep=0}, controls=+(80:0.7) and +(100:0.7), from=1-1, to=1-2]
    \arrow[""{name=1, anchor=center, inner sep=0}, curve={height=0}, from=1-1, to=1-2]
    \arrow[""{name=2, anchor=center, inner sep=0}, controls=+(100:-0.7) and +(80:-0.7),, from=1-1, to=1-2]
    \arrow["\gamma", shorten <=3pt, shorten >=3pt, Rightarrow, from=2, to=1]
    \arrow["\delta", shorten <=3pt, shorten >=3pt, Rightarrow, from=1, to=0]
  \end{tikzcd}}}
\[
  \begin{tikzcd}[column sep=small]
    \bullet &&&&& \bullet & {=} & \bullet &&& \bullet &&& \bullet
    \arrow[""{name=0, anchor=center, inner sep=0}, from=1-1, to=1-6]
    \arrow[""{name=1, anchor=center, inner sep=0}, draw=none, controls=+(90:2) and +(90:2), from=1-1, to=1-6]
    \arrow[""{name=2, anchor=center, inner sep=0}, draw=none, controls=+(90:-2) and +(90:-2), from=1-1, to=1-6]
    \arrow[""{name=4, anchor=center, inner sep=0}, draw=none, controls=+(80:1.5) and +(100:1.5), from=1-8, to=1-11]
    \arrow[""{name=5, anchor=center, inner sep=0}, draw=none, controls=+(100:-1.5) and +(80:-1.5), from=1-8, to=1-11]
    \arrow[""{name=6, anchor=center, inner sep=0}, draw=none, controls=+(80:1.5) and +(100:1.5), from=1-11, to=1-14]
    \arrow[""{name=8, anchor=center, inner sep=0}, draw=none, controls=+(100:-1.5) and +(80:-1.5), from=1-11, to=1-14]
    \arrow["\usebox{\innertop}"{description, inner sep = 0,xshift = -1.2pt}, shorten <=4pt, shorten >=4pt, Rightarrow, from=2, to=0]
    \arrow["\usebox{\innerbot}"{description, inner sep = 0,xshift = -1.2pt}, shorten <=4pt, shorten >=4pt, Rightarrow, from=0, to=1]
    \arrow[""{name=1, anchor=center, inner sep=0}, controls=+(90:2) and +(90:2), from=1-1, to=1-6]
    \arrow[""{name=2, anchor=center, inner sep=0}, controls=+(90:-2) and +(90:-2), from=1-1, to=1-6]
    \arrow["\usebox{\innerleft}"{description, inner sep = 0,xshift = -1.3pt}, shorten <=2pt, shorten >=2pt, Rightarrow, from=5, to=4]
    \arrow["\usebox{\innerright}"{description, inner sep = 0,xshift = -1.3pt}, shorten <=2pt, shorten >=2pt, Rightarrow, from=8, to=6]
    \arrow[controls=+(80:1.5) and +(100:1.5), from=1-8, to=1-11]
    \arrow[controls=+(100:-1.5) and +(80:-1.5), from=1-8, to=1-11]
    \arrow[controls=+(80:1.5) and +(100:1.5), from=1-11, to=1-14]
    \arrow[controls=+(100:-1.5) and +(80:-1.5), from=1-11, to=1-14]
  \end{tikzcd}
\]

There are also interchange laws for the interaction of composition and identities; A composition of two identities is the same as an identity on the composition of the underlying cells.


The \(\infty\)-categories that we study in this thesis will be globular, meaning that their cells form a globular set. A globular set can be seen as natural extension of the data of a category, whose data can be arranged into the following diagram:
% https://q.uiver.app/#q=WzAsMixbMCwwLCJZIl0sWzEsMCwiWCJdLFswLDEsInMiLDAseyJvZmZzZXQiOi0xfV0sWzAsMSwidCIsMix7Im9mZnNldCI6MX1dXQ==
\[
  \begin{tikzcd}
    M & O
    \arrow["s", shift left, from=1-1, to=1-2]
    \arrow["t"', shift right, from=1-1, to=1-2]
  \end{tikzcd}
\]
where \(O\) is a set of objects, \(M\) is a set of all morphisms, and \(s\) and \(t\) are functions assigning each morphism to its source and target object respectively. \(2\)-cells can be added to this diagram in a natural way:

% https://q.uiver.app/#q=WzAsMyxbMSwwLCJDXzEiXSxbMiwwLCJDXzAiXSxbMCwwLCJDXzIiXSxbMCwxLCJzXzAiLDAseyJvZmZzZXQiOi0xfV0sWzAsMSwidF8wIiwyLHsib2Zmc2V0IjoxfV0sWzIsMCwic18xIiwwLHsib2Zmc2V0IjotMX1dLFsyLDAsInRfMSIsMix7Im9mZnNldCI6MX1dXQ==
\[
  \begin{tikzcd}
    {C_2} & {C_1} & {C_0}
    \arrow["{s_0}", shift left, from=1-2, to=1-3]
    \arrow["{t_0}"', shift right, from=1-2, to=1-3]
    \arrow["{s_1}", shift left, from=1-1, to=1-2]
    \arrow["{t_1}"', shift right, from=1-1, to=1-2]
  \end{tikzcd}
\]
In a globular set, the source and target of any cell must be parallel, meaning they share the same source and target. This condition is imposed by \emph{globularity conditions}. Adding these and iterating the process leads to the following definition.

\begin{definition}
  The category of globes \(\mathbf{G}\) has objects given by the natural numbers and morphisms generated from \(\mathbf{s}_n, \mathbf{t}_n : n \to n + 1\) quotiented by the \emph{globularity conditions}:
  \begin{align*}
    \mathbf{s}_{n+1} \circ \mathbf{s}_n &= \mathbf{t}_{n+1} \circ \mathbf{s}_n\\
    \mathbf{s}_{n+1} \circ \mathbf{t}_n &= \mathbf{t}_{n+1} \circ \mathbf{t}_n
  \end{align*}

The category of globular sets \(\mathbf{Glob}\), is the presheaf category \([\mathbf{G}, \mathbf{Set}]\).
 \end{definition}

Unwrapping this definition, a globular set \(G\) consists of sets \(G(n)\) for each \(n \in \mathbb{N}\), with source and target maps \(s_n, t_n : G(n+1) \to G(n)\), forming the following diagram:
\[
  \begin{tikzcd}
    \cdots & {G(3)} & {G(2)} & {G(1)} & {G(0)}
    \arrow["{s_0}", shift left, from=1-4, to=1-5]
    \arrow["{t_0}"', shift right, from=1-4, to=1-5]
    \arrow["{s_1}", shift left, from=1-3, to=1-4]
    \arrow["{t_1}"', shift right, from=1-3, to=1-4]
    \arrow["{t_2}"', shift right, from=1-2, to=1-3]
    \arrow["{s_2}", shift left, from=1-2, to=1-3]
    \arrow[shift right, from=1-1, to=1-2]
    \arrow[shift left, from=1-1, to=1-2]
  \end{tikzcd}
\]
and satisfying the globularity conditions. A morphism of globular sets \(F : G \to H\) is a collection of functions \(G(n) \to H(n)\) which commute with source and target maps.

Given a globular set \(G\), we will call the elements of \(G(n)\) the \(n\)-cells and write \(f : x \to y\) for an \((n+1)\)-cell \(f\) where \(s_n(f) = x\) and \(t_n(f) = y\). We further define the \(n\)-boundary operators \(\delta_n^-\) and \(\delta_n^+\) which take the source or target respectively of a \((n+k)\)-cell \(k\) times, returning an \(n\)-cell.

\begin{example}
  \label{ex:disc}
  The \(n\)-disc \(D^n\) is a finite globular set given by \(Y(n)\), where \(Y\) is the Yoneda functor \(\mathbf{G} \to \mathbf{Glob}\). \(D^n\), has no \(k\)-cells for \(k > n\), a single \(n\)-cell \(d_n\), and two \(m\)-cells \(d_m^-\) and \(d_m^+\) for \(m < n\). Every \((m+1)\)-cell of \(D^n\) has source \(d_m^-\) and target \(d_m^+\). The first few discs are depicted in \cref{fig:discs}. The Yoneda lemma tells us that a map of globular sets \(D^n \to G\) is the same as an \(n\)-cell of \(G\). For an \(n\)-cell \(x\) of \(G\), we let \(\{x\}\) be the unique map \(D^n \to G\) which sends \(d_n\) to \(x\).
\end{example}

\begin{figure}[h]
  \centering
  \begin{tabular}{P{3cm} P{3cm} P{3cm} P{3cm}}
    \(D^0\)&\(D^1\)&\(D^2\)&\(D^3\)\\
    {\begin{tikzcd}
        d_0
      \end{tikzcd}
    }&{\begin{tikzcd}[ampersand replacement=\&]
        d_0^- \& d_0^+
        \arrow[from=1-1, to=1-2, "d_1"]
      \end{tikzcd}
       }&{\begin{tikzcd}[ampersand replacement=\&]
           d_0^- \& d_0^+
           \arrow[""{name=0, anchor=center, inner sep=0}, "d_1^+", curve={height=-18pt}, from=1-1, to=1-2]
           \arrow[""{name=1, anchor=center, inner sep=0}, "d_1^-"', curve={height=18pt}, from=1-1, to=1-2]
           \arrow["d_2", shorten <=3pt, shorten >=3pt, Rightarrow, from=1, to=0]
         \end{tikzcd}
          }&{\begin{tikzcd}[ampersand replacement=\&]
              d_0^- \&\& d_0^+
              \arrow[""{name=0, anchor=center, inner sep=0}, "d_1^+", curve={height=-25pt}, from=1-1, to=1-3]
              \arrow[""{name=1, anchor=center, inner sep=0}, "d_1^-"', curve={height=25pt}, from=1-1, to=1-3]
              \arrow[""{name=2, anchor=center, inner sep=0}, "d_2^-", shift left=12pt,Rightarrow, shorten <=5pt, shorten >=5pt, from=1,to=0]
              \arrow[""{name=3, anchor=center, inner sep=0}, "d_2^+"', shift right=12pt,Rightarrow, shorten <=5pt, shorten >=5pt, from=1,to=0]
              \arrow["d_3", Rightarrow, nfold = 3, shorten <=3pt, shorten >=3pt,from=2,to=3]
            \end{tikzcd}}
  \end{tabular}
  \caption{The first disc globular sets}
  \label{fig:discs}
\end{figure}

\begin{remark}
  Globular sets are not the only natural extension of the data of a 1-category. The form of this data in a definition of a higher category is referred to as the \emph{shape} of the cells. Notable alternatives to globular sets include simplicial sets, opetopic sets, and cubical sets.
\end{remark}\todo{Could put some references in here}

We can now give the definition of a (strict) \(\infty\)-category.

\begin{definition}
  A (strict) \(\infty\)-category is a globular set \(G\) with operations:
  \begin{itemize}
  \item For \(m < n\), a composition \(*_m\) taking \(n\)-cells \(f\) and \(g\) with \(\delta_m^+(f) = \delta_m^-(g)\) and giving an \(n\)-cell \(f *_m g\) with:
    \begin{align*}
      s(f *_m g) &= \begin{cases*}
        s(f)&\text{if \(m = n - 1\)}\\
        s(f) *_m s(g)&\text{otherwise}
      \end{cases*}\\
      t(f *_m g) &= \begin{cases*}
        t(g)&\text{if \(m = n - 1\)}\\
        t(f) *_m t(g)&\text{otherwise}
      \end{cases*}
    \end{align*}
  \item For \(n\)-cell \(x\), an identity \((n+1)\)-cell \(\id(x) : x \to x\).
  \end{itemize}
  and satisfying equalities:
  \begin{itemize}
  \item Associativity: Given \(m < n\) and \(n\)-cells \(f\), \(g\), and \(h\) with \(\delta_m^+(f) = \delta_m^-(g)\) and \(\delta_m^+(g) = \delta_m^-(h)\):
    \[ (f *_m g) *_m h = f *_m (g *_m h) \]
  \item Unitality: Given \(m < n\) and \(n\)-cell \(f\):
    \begin{align*}
      \id^{n-m}(\delta_m^-(f)) *_m f &= f\\
      f *_m \id^{n-m}(\delta_m^+(f)) &= f
    \end{align*}
  \item Composition interchange: If \(o < m < n\) and \(\alpha\), \(\beta\), \(\gamma\), and \(\delta\) be \(n\)-cells with
    \[\delta_m^+(\alpha) = \delta_m^-(\beta)\qquad
      \delta_m^+(\gamma) = \delta_m^-(\delta)\qquad
      \delta_o^+(\alpha) = \delta_o^-(\gamma)\]
    then:
    \[(\alpha *_o \gamma) *_m (\beta *_o \delta) = (\alpha *_m \beta) *_o (\gamma *_m \delta)\]
  \item Identity interchange: Let \(m < n\) and \(f\) and \(g\) be \(n\)-cells with \(\delta_m^+(f) = \delta_m^-(g)\). Then:
    \[\id(f) *_m \id(g) = \id(f *_m g)\]
  \end{itemize}
  A morphism of \(\infty\) categories is a morphism of the underlying globular sets which preserves composition and identities.
\end{definition}

There is a clear forgetful functor from the category of strict infinity categories to the category of globular sets, which has a left adjoint given by taking the free strict infinity category over a globular set.

We end this section with an example of a non-trivial application of the axioms of an infinity category, known as the Eckmann-Hilton argument. The argument show's that any two scalars (morphisms from the identity to the identity) commute.

\begin{proposition}[Eckmann-Hilton]
  \label{prop:eh}
  Let \(x\) be an \(n\)-cell in an \(\infty\)-category and let \(\alpha\) and \(\beta\) be \((n+2)\)-cells with source and target \(\id(x)\). Then \(\alpha *_{n+1} \beta = \beta *_{n+1} \alpha\).
\end{proposition}
\begin{proof}
  The cells \(\alpha\) and \(\beta\) can be manoeuvred around each other as follows:
  \begin{align*}
    &\phantom{{}={}} \alpha *_{n+1} \beta \\
    &= (\alpha *_n i) *_{n+1} (i *_n \beta)&\text{Unitality}\\
    &= (\alpha *_{n+1} i) *_n (i *_{n+1} \beta)&\text{Interchange}\\
    &= \alpha *_n \beta &\text{Unitality}\\
    &= (i *_{n+1} \alpha) *_n (\beta *_{n+1} i)&\text{Unitality}\\
    &= (i *_n \beta) *_{n+1} (\alpha *_n i)&\text{Interchange}\\
    &= \beta *_{n+1} \alpha&\text{Unitality}
  \end{align*}
  Where \(i = \id(\id(x))\).
\end{proof}

We give a more graphical representation of the proof in \cref{fig:eh}. In this proof the \(\alpha\) is moved to the left of \(\beta\), though we equally could have moved it round the right, and the choice made was arbitrary.

\newsavebox{\ehalpha}
\savebox{\ehalpha}{\adjustbox{scale=0.8}{
  \begin{tikzcd}[ampersand replacement=\&,column sep=small,cramped]
    \bullet \& \bullet \& \bullet
    \arrow[""{name=0, anchor=center, inner sep=0}, curve={height=-10pt}, from=1-1, to=1-2]
    \arrow[""{name=1, anchor=center, inner sep=0}, curve={height=10pt}, from=1-1, to=1-2]
    \arrow[""{name=2, anchor=center, inner sep=0}, curve={height=-10pt}, from=1-2, to=1-3]
    \arrow[""{name=3, anchor=center, inner sep=0}, curve={height=10pt}, from=1-2, to=1-3]
    \arrow["\alpha"', color={rgb,255:red,0;green,24;blue,204}, shorten <=3pt, shorten >=3pt, Rightarrow, from=1, to=0]
    \arrow["\id"', shorten <=3pt, shorten >=3pt, Rightarrow, from=3, to=2]
  \end{tikzcd}}}
\newsavebox{\ehbeta}
\savebox{\ehbeta}{\adjustbox{scale=0.8}{
  \begin{tikzcd}[ampersand replacement=\&,column sep=small,cramped]
    \bullet \& \bullet \& \bullet
    \arrow[""{name=0, anchor=center, inner sep=0}, curve={height=-10pt}, from=1-1, to=1-2]
    \arrow[""{name=1, anchor=center, inner sep=0}, curve={height=10pt}, from=1-1, to=1-2]
    \arrow[""{name=2, anchor=center, inner sep=0}, curve={height=-10pt}, from=1-2, to=1-3]
    \arrow[""{name=3, anchor=center, inner sep=0}, curve={height=10pt}, from=1-2, to=1-3]
    \arrow["\id"',  shorten <=3pt, shorten >=3pt, Rightarrow, from=1, to=0]
    \arrow["\beta"', color={rgb,255:red,204;green,0;blue,14}, shorten <=3pt, shorten >=3pt, Rightarrow, from=3, to=2]
  \end{tikzcd}}}
\newsavebox{\ehlefttop}
\savebox{\ehlefttop}{
  \adjustbox{scale=1}{\begin{tikzcd}[ampersand replacement=\&,column sep=small,cramped]
     \bullet \& \bullet
     \arrow[""{name=0, anchor=center, inner sep=0}, controls=+(80:0.7) and +(100:0.7),, from=1-1, to=1-2]
     \arrow[""{name=1, anchor=center, inner sep=0}, curve={height=0}, from=1-1, to=1-2]
     \arrow[""{name=2, anchor=center, inner sep=0}, controls=+(100:-0.7) and +(80:-0.7),, from=1-1, to=1-2]
     \arrow["\alpha", color= blue, shorten <=3pt, shorten >=3pt, Rightarrow, from=2, to=1]
     \arrow["\id", shorten <=3pt, shorten >=3pt, Rightarrow, from=1, to=0]
   \end{tikzcd}}}
\newsavebox{\ehrighttop}
\savebox{\ehrighttop}{
  \adjustbox{scale=1}{\begin{tikzcd}[ampersand replacement=\&,column sep=small,cramped]
    \bullet \& \bullet
    \arrow[""{name=0, anchor=center, inner sep=0}, controls=+(80:0.7) and +(100:0.7), from=1-1, to=1-2]
    \arrow[""{name=1, anchor=center, inner sep=0}, curve={height=0}, from=1-1, to=1-2]
    \arrow[""{name=2, anchor=center, inner sep=0}, controls=+(100:-0.7) and +(80:-0.7),, from=1-1, to=1-2]
    \arrow["\id", shorten <=3pt, shorten >=3pt, Rightarrow, from=2, to=1]
    \arrow["\beta", color=red, shorten <=3pt, shorten >=3pt, Rightarrow, from=1, to=0]
  \end{tikzcd}}}
\newsavebox{\ehleftbot}
\savebox{\ehleftbot}{
  \adjustbox{scale=1}{\begin{tikzcd}[ampersand replacement=\&,column sep=small,cramped]
    \bullet \& \bullet
    \arrow[""{name=0, anchor=center, inner sep=0}, controls=+(80:0.7) and +(100:0.7),, from=1-1, to=1-2]
    \arrow[""{name=1, anchor=center, inner sep=0}, curve={height=0}, from=1-1, to=1-2]
    \arrow[""{name=2, anchor=center, inner sep=0}, controls=+(100:-0.7) and +(80:-0.7),, from=1-1, to=1-2]
    \arrow["\id", shorten <=3pt, shorten >=3pt, Rightarrow, from=2, to=1]
    \arrow["\alpha", color=blue, shorten <=3pt, shorten >=3pt, Rightarrow, from=1, to=0]
  \end{tikzcd}}}
\newsavebox{\ehrightbot}
\savebox{\ehrightbot}{
  \adjustbox{scale=1}{\begin{tikzcd}[ampersand replacement=\&,column sep=small,cramped]
    \bullet \& \bullet
    \arrow[""{name=0, anchor=center, inner sep=0}, controls=+(80:0.7) and +(100:0.7), from=1-1, to=1-2]
    \arrow[""{name=1, anchor=center, inner sep=0}, curve={height=0}, from=1-1, to=1-2]
    \arrow[""{name=2, anchor=center, inner sep=0}, controls=+(100:-0.7) and +(80:-0.7),, from=1-1, to=1-2]
    \arrow["\beta", color=red, shorten <=3pt, shorten >=3pt, Rightarrow, from=2, to=1]
    \arrow["\id", shorten <=3pt, shorten >=3pt, Rightarrow, from=1, to=0]
  \end{tikzcd}}}

\begin{figure}[h]
  \centering

  \[
    \begin{tikzcd}[ampersand replacement=\&,column sep=small]
      \bullet \&\& \bullet \& = \& \bullet \&\&\&\&\& \bullet \& = \& \bullet \&\&\& \bullet \&\&\& \bullet \\
      \\
      \&\&\&\&\&\&\&\&\&\&\&\&\&\& = \\
      \\
      \bullet \&\& \bullet \& = \& \bullet \&\&\&\&\& \bullet \& = \& \bullet \&\&\& \bullet \&\&\& \bullet
      \arrow[""{name=0, anchor=center, inner sep=0}, "\id", curve={height=-24pt}, from=1-1, to=1-3]
      \arrow[""{name=1, anchor=center, inner sep=0}, "\id"', curve={height=24pt}, from=1-1, to=1-3]
      \arrow[""{name=2, anchor=center, inner sep=0}, "\id"{description}, from=1-1, to=1-3]
      \arrow[""{name=3, anchor=center, inner sep=0}, draw=none, controls=+(90:1.8) and +(90:1.8), from=1-5, to=1-10]
      \arrow[""{name=4, anchor=center, inner sep=0}, draw=none, controls=+(90:-1.8) and +(90:-1.8), from=1-5, to=1-10]
      \arrow[""{name=5, anchor=center, inner sep=0}, from=1-5, to=1-10]
      \arrow[""{name=6, anchor=center, inner sep=0}, draw=none, controls=+(90:1.8) and +(90:1.8), from=5-5, to=5-10]
      \arrow[""{name=7, anchor=center, inner sep=0}, draw=none, controls=+(90:-1.8) and +(90:-1.8), from=5-5, to=5-10]
      \arrow[""{name=8, anchor=center, inner sep=0}, from=5-5, to=5-10]
      \arrow[""{name=9, anchor=center, inner sep=0}, "\id", curve={height=-24pt}, from=5-1, to=5-3]
      \arrow[""{name=10, anchor=center, inner sep=0}, "\id"', curve={height=24pt}, from=5-1, to=5-3]
      \arrow[""{name=11, anchor=center, inner sep=0}, "\id"{description}, from=5-1, to=5-3]
      \arrow[""{name=12, anchor=center, inner sep=0}, draw=none, controls=+(80:1.5) and +(100:1.5), from=1-12, to=1-15]
      \arrow[""{name=13, anchor=center, inner sep=0}, draw=none, controls=+(100:-1.5) and +(80:-1.5), from=1-12, to=1-15]
      \arrow[""{name=14, anchor=center, inner sep=0}, draw=none, controls=+(80:1.5) and +(100:1.5), from=1-15, to=1-18]
      \arrow[""{name=15, anchor=center, inner sep=0}, draw=none, controls=+(100:-1.5) and +(80:-1.5), from=1-15, to=1-18]
      \arrow[""{name=16, anchor=center, inner sep=0}, draw=none, controls=+(80:1.5) and +(100:1.5), from=5-12, to=5-15]
      \arrow[""{name=17, anchor=center, inner sep=0}, draw=none, controls=+(100:-1.5) and +(80:-1.5), from=5-12, to=5-15]
      \arrow[""{name=18, anchor=center, inner sep=0}, draw=none, controls=+(80:1.5) and +(100:1.5), from=5-15, to=5-18]
      \arrow[""{name=19, anchor=center, inner sep=0}, draw=none, controls=+(100:-1.5) and +(80:-1.5), from=5-15, to=5-18]
      \arrow["\alpha"', color={rgb,255:red,0;green,24;blue,204}, shorten <=3pt, shorten >=5pt, Rightarrow, from=1, to=2]
      \arrow["\beta"', color={rgb,255:red,204;green,0;blue,14}, shorten <=5pt, shorten >=3pt, Rightarrow, from=2, to=0]
      \arrow["\beta"', color={rgb,255:red,204;green,0;blue,14}, shorten <=3pt, shorten >=5pt, Rightarrow, from=10, to=11]
      \arrow["\alpha"', color={rgb,255:red,0;green,24;blue,204}, shorten <=5pt, shorten >=3pt, Rightarrow, from=11, to=9]
      \arrow["\usebox{\ehalpha}"{description,inner sep = 0,xshift = -1.2pt}, shorten <=3pt, shorten >=3pt, Rightarrow, from=4, to=5]
      \arrow["\usebox{\ehbeta}"{description,inner sep = 0,xshift = -1.2pt}, shorten <=3pt, shorten >=3pt, Rightarrow, from=5, to=3]
      \arrow["\usebox{\ehbeta}"{description,inner sep = 0,xshift = -1.2pt}, shorten <=3pt, shorten >=3pt, Rightarrow, from=7, to=8]
      \arrow["\usebox{\ehalpha}"{description,inner sep = 0,xshift = -1.2pt}, shorten <=3pt, shorten >=3pt, Rightarrow, from=8, to=6]
      \arrow["\usebox{\ehlefttop}"{description,inner sep = 0,xshift = -1.3pt, yshift = 0.2pt}, shorten <=3pt, shorten >=3pt, Rightarrow, from=13, to=12]
      \arrow["\usebox{\ehrighttop}"{description,inner sep = 0,xshift = -1.3pt,yshift = 0.2pt}, shorten <=3pt, shorten >=3pt, Rightarrow, from=15, to=14]
      \arrow["\usebox{\ehleftbot}"{description,inner sep = 0,xshift = -1.3pt}, shorten <=3pt, shorten >=3pt, Rightarrow, from=17, to=16]
      \arrow["\usebox{\ehrightbot}"{description,inner sep = 0,xshift = -1.3pt}, shorten <=3pt, shorten >=3pt, Rightarrow, from=19, to=18]
      \arrow[controls=+(90:1.8) and +(90:1.8), from=1-5, to=1-10]
      \arrow[controls=+(90:-1.8) and +(90:-1.8), from=1-5, to=1-10]
      \arrow[controls=+(90:1.8) and +(90:1.8), from=5-5, to=5-10]
      \arrow[controls=+(90:-1.8) and +(90:-1.8), from=5-5, to=5-10]
      \arrow[controls=+(80:1.5) and +(100:1.5), from=1-12, to=1-15]
      \arrow[controls=+(100:-1.5) and +(80:-1.5), from=1-12, to=1-15]
      \arrow[controls=+(80:1.5) and +(100:1.5), from=1-15, to=1-18]
      \arrow[controls=+(100:-1.5) and +(80:-1.5), from=1-15, to=1-18]
      \arrow[controls=+(80:1.5) and +(100:1.5), from=5-12, to=5-15]
      \arrow[controls=+(100:-1.5) and +(80:-1.5), from=5-12, to=5-15]
      \arrow[controls=+(80:1.5) and +(100:1.5), from=5-15, to=5-18]
      \arrow[controls=+(100:-1.5) and +(80:-1.5), from=5-15, to=5-18]
    \end{tikzcd}
  \]
  \caption{The Eckmann-Hilton argument}
  \label{fig:eh}
\end{figure}

\subsection{Pasting diagrams}
\label{sec:pasting-diagrams}

The definition of \(\infty\)-categories given in the previous section is close in spirit to the the ordinary definitions of 1-categories and clearly demonstrates the different families of axioms present. However, we will see in \cref{sec:weak}, that these sort of definitions do not scale well to our eventual setting of weak higher categories.

There is a special class of (finite) globular sets known as \emph{pasting diagrams} (sometimes known as pasting schemes). The elements of the free strict \(\infty\)-category on a globular set \(G\) can instead be represented by a pasting diagram and a map from this pasting diagram into \(G\). To do this, it must be possible to obtain a canonical composite from each pasting diagram.

Informally, we can define a \(n\)-dimensional pasting diagram to be a finite globular set which admits a unique full composite of dimension \(n\), where a full composite of a globular set \(G\) is an element of the free \(\infty\)-category over \(G\) which uses all the maximal elements. This functions as the primary intuition on the role of pasting diagrams.

Pasting diagrams were used directly by \citeauthor{batanin1998monoidal}~\cite{batanin1998monoidal} to give a defintion of weak \(\infty\)-categories, and will be pivotal in \cref{sec:weak} to define the variety of higher categories that \Catt is based on. A more indepth discussion of pasting diagrams, representations of free strict \(\infty\)-categories using them, and their use in the definition of weak higher categories can be found in \citetitle{leinster2004higher}~\cite{leinster2004higher}.

Before giving a more formal definition of pasting diagrams, we explore some examples and non-examples. In contrast to \citeauthor{leinster2004higher}, we consider pasting diagrams as a full subcategory of globular sets, rather than a separate category with a function sending each pasting diagram to a globular set.

The disc contexts introduced in \cref{ex:disc} are all examples of pasting diagrams. The unique ``composite'' of these globular sets is just given by their maximal element, noting that we allow a singular cell in our informal definition of composite. The uniqueness of this is trivial as the only possible operations we could apply are compositions with units, which gives the same cell under the laws of an \(\infty\)-category.

The diagrams used to graphically represent our composition operations (of which we recall three below) are also pasting diagrams.

\[
  \begin{tikzcd}
    x & y & z
    \arrow["f", from=1-1, to=1-2]
    \arrow["g", from=1-2, to=1-3]
  \end{tikzcd}
  \qquad
  \begin{tikzcd}
    x && y
    \arrow[""{name=0, anchor=center, inner sep=0}, "f"', curve={height=24pt}, from=1-1, to=1-3]
    \arrow[""{name=1, anchor=center, inner sep=0}, "h", curve={height=-24pt}, from=1-1, to=1-3]
    \arrow[""{name=2, anchor=center, inner sep=0}, "g"{description}, from=1-1, to=1-3]
    \arrow["\alpha", shorten <=3pt, shorten >=3pt, Rightarrow, from=0, to=2]
    \arrow["\beta", shorten <=3pt, shorten >=3pt, Rightarrow, from=2, to=1]
  \end{tikzcd}
  \qquad
    \begin{tikzcd}
    x & y & z
    \arrow[""{name=0, anchor=center, inner sep=0}, "g", curve={height=-18pt}, from=1-1, to=1-2]
    \arrow[""{name=1, anchor=center, inner sep=0}, "f"', curve={height=18pt}, from=1-1, to=1-2]
    \arrow[""{name=2, anchor=center, inner sep=0}, "i", curve={height=-18pt}, from=1-2, to=1-3]
    \arrow[""{name=3, anchor=center, inner sep=0}, "h"', curve={height=18pt}, from=1-2, to=1-3]
    \arrow["\alpha", shorten <=5pt, shorten >=5pt, Rightarrow, from=1, to=0]
    \arrow["\beta", shorten <=5pt, shorten >=5pt, Rightarrow, from=3, to=2]
  \end{tikzcd}
\]

The composite of these diagrams is just the composite of the two maximal cells with the appropriate codimension.

We can also consider composites which are not binary composites of two cells of equal dimension. For example the following globular set is a pasting diagram:

\[
  \begin{tikzcd}
    x & y & z
    \arrow[""{name=0, anchor=center, inner sep=0}, "g", curve={height=-18pt}, from=1-1, to=1-2]
    \arrow[""{name=1, anchor=center, inner sep=0}, "f"', curve={height=18pt}, from=1-1, to=1-2]
    \arrow["h", from=1-2, to=1-3]
    \arrow["\alpha", shorten <=5pt, shorten >=5pt, Rightarrow, from=1, to=0]
  \end{tikzcd}
\]
with a composite given by \(\alpha *_0 \id(h)\). This operation is fairly common (in fact we have already seen it in \cref{prop:eh}) and is known as \emph{whiskering}. In this case we would say that the composite is given by the right whiskering of \(\alpha\) with \(h\).

The 1-dimensional pasting diagrams are all given by chains of 1-cells of the form:
\[x_0 \overset{f_0}\to x_1 \overset{f_1}\to x_2 \overset{f_2}\to \cdots \overset{f_n}\to x_{n+1}\]
There are multiple ways to form a composite over these diagrams by repeated binary composition, however these all have the same result due to associativity.

Lastly we look at the diagram, where all the \(0\)-cells and \(1\)-cells are assumed to be distinct:

\[
  \begin{tikzcd}[column sep = large]
    \bullet & \bullet & \bullet
    \arrow[""{name=0, anchor=center, inner sep=0}, curve={height=-30pt}, from=1-1, to=1-2]
    \arrow[""{name=1, anchor=center, inner sep=0}, curve={height=30pt}, from=1-1, to=1-2]
    \arrow[""{name=2, anchor=center, inner sep=0}, from=1-1, to=1-2]
    \arrow[""{name=3, anchor=center, inner sep=0}, curve={height=-30pt}, from=1-2, to=1-3]
    \arrow[""{name=4, anchor=center, inner sep=0}, curve={height=30pt}, from=1-2, to=1-3]
    \arrow[""{name=5, anchor=center, inner sep=0}, from=1-2, to=1-3]
    \arrow["\alpha", shorten <=4pt, shorten >=4pt, Rightarrow, from=1, to=2]
    \arrow["\beta", shorten <=4pt, shorten >=4pt, Rightarrow, from=2, to=0]
    \arrow["\gamma", shorten <=4pt, shorten >=4pt, Rightarrow, from=4, to=5]
    \arrow["\delta", shorten <=4pt, shorten >=4pt, Rightarrow, from=5, to=3]
  \end{tikzcd}
\]

We get a composite given by \((\alpha *_1 \beta) *_0 (\gamma *_1 \delta)\). The uniqueness of this composite is due to the interchange law.

Non-examples of pasting diagrams roughly fall into two groups: those that do not admit a composite, and those that admit many distinct composites. The following three globular sets fail to admit a composite (the last is drawn in a box to emphasise that \(z\) is part of the same globular set as \(x\), \(y\), \(f\), \(g\), and \(\alpha\)):

\[
  \begin{tikzcd}[column sep=large, row sep = small]
    & y \\
    x \\
    & z
    \arrow["f", pos=0.6, from=2-1, to=1-2]
    \arrow["g"', pos=0.6, from=2-1, to=3-2]
  \end{tikzcd}
  \qquad
  \begin{tikzcd}[column sep=large]
    x & y
    \arrow["f", curve={height=-12pt}, from=1-1, to=1-2]
    \arrow["g"', curve={height=12pt}, from=1-1, to=1-2]
  \end{tikzcd}
  \qquad
  \fbox{\begin{tikzcd}[column sep=scriptsize, ampersand replacement = \&]
    x \&\& y \& z
    \arrow[""{name=0, anchor=center, inner sep=0}, "f", curve={height=-18pt}, from=1-1, to=1-3]
    \arrow[""{name=1, anchor=center, inner sep=0}, "g"', curve={height=18pt}, from=1-1, to=1-3]
    \arrow["\alpha", shorten <=5pt, shorten >=5pt, Rightarrow, from=1, to=0]
  \end{tikzcd}}
\]
The globular set with a single \(0\)-cell \(x\), and a single \(1\)-cell \(f : x \to x\) has too many composites: \(f\) and \(f *_0 f\) need not be equal in an infinity category.

To describe the free \(\infty\)-category in terms of pasting diagrams we need to be able to extract a composite from a pasting diagram, and construct a pasting diagram from an arbitrary composite. Each pasting diagram having a unique composite solves the former issue.

To be able to construct a pasting diagram from a composite, we wish to equip our set of pasting diagrams itself with the structure of an \(\infty\)-category. We therefore need our pasting diagrams to have a notion of boundary and a notion of composition. A natural candidate for composition is given by colimits, as \(\mathbf{Glob}\) has all colimits due to being a presheaf category, and so it is sufficient for our class of pasting diagrams to be closed under these specific colimits. In fact, it is sufficient to contain a class of colimits known as \emph{globular sums}.

\begin{definition}
  A globular category is a category \(\mathcal{C}\), equipped with a disc functor \(D : \mathbf{G} \to \mathcal{C}\), specifying certain objects as discs in the category. A \emph{globular sum} is a colimit of a diagram of the form:
  \[
    \begin{tikzcd}[column sep = tiny, row sep = tiny]
      {D(i_0)} && {D(i_1)} && {D(i_2)} && {D(i_n)} && {D(i_{n+1})} \\
      &&&&& \cdots \\
      & {D(j_0)} && {D(j_1)} &&&& {D(j_n)}
      \arrow["{f_0}", from=3-2, to=1-1]
      \arrow["{g_0}"', from=3-2, to=1-3]
      \arrow["{f_n}", from=3-8, to=1-7]
      \arrow["{g_n}"', from=3-8, to=1-9]
      \arrow["{f_1}", from=3-4, to=1-3]
      \arrow["{g_1}"', from=3-4, to=1-5]
    \end{tikzcd}
  \]
  Where all morphisms \(f_i\) are a composite of source maps (\(D(\mathbf{s}_n)\) for some \(n\)) and the morphisms \(g_i\) are a composite of target maps (\(D(\mathbf{t}_n)\) for some \(n\)). Given that the maps \(f_i\) and \(g_i\) are uniquely determined, we may write such a globular sum as:

  \[ D(i_0) \amalg_{D(j_0)} D(i_1) \amalg_{D(j_1)} D(i_2) \cdots D(i_n) \amalg_{D(j_n)} D(i_{n+ 1})\]

  A \emph{globular extension} is a globular category where all globular sums exist, and a morphism of globular extensions is a functor of the underlying categories commuting with the disc functors and preserving globular sums.
\end{definition}

We can finally give our first definition of a pasting diagram.

\begin{definition}
  The category \(\mathbf{Glob}\) is a globular category with functor \(\mathbf{G} \to \mathbf{Glob}\) given by the Yoneda embedding. The category of \emph{pasting diagrams}, \(\mathbf{Pd}\), is the full subcategory containing the globular sets which are globular sums.
  The boundary of an \((n+1)\)-dimensional pasting diagram is given by replacing each instance of \(D^{n+1}\) by \(D^n\) in its globular sum representation. There are two canonical maps including the boundary into the original pasting diagram, whose images give the source and target of the pasting diagram.
\end{definition}

The category of pasting diagrams clearly forms a globular category, with the functor \(\mathbf{G} \to \mathbf{Pd}\) sending \(n\) to \(D^n\). It is a globular extension and is in fact the universal globular extension; it is initial in the category of globular extensions~\cite{Ara}.

We finish this section with one larger example.

\begin{example}
  The following depicts a \(2\)-dimensional pasting diagram.
  \[
    \begin{tikzcd}
      x & y & z & w
      \arrow[""{name=0, anchor=center, inner sep=0}, "g", curve={height=-18pt}, from=1-1, to=1-2]
      \arrow[""{name=1, anchor=center, inner sep=0}, "f"', curve={height=18pt}, from=1-1, to=1-2]
      \arrow["h"', from=1-2, to=1-3]
      \arrow[""{name=2, anchor=center, inner sep=0}, "k", curve={height=-24pt}, from=1-3, to=1-4]
      \arrow[""{name=3, anchor=center, inner sep=0}, "i"', curve={height=24pt}, from=1-3, to=1-4]
      \arrow[""{name=4, anchor=center, inner sep=0}, "j"{description}, from=1-3, to=1-4]
      \arrow["\alpha", shorten <=5pt, shorten >=5pt, Rightarrow, from=1, to=0]
      \arrow["\beta", shorten <=3pt, shorten >=3pt, Rightarrow, from=3, to=4]
      \arrow["\gamma", shorten <=3pt, shorten >=3pt, Rightarrow, from=4, to=2]
    \end{tikzcd}
  \]
  which has the following globular sum decomposition:
  % https://q.uiver.app/#q=WzAsMTMsWzAsMCwieCJdLFsyLDAsInkiXSxbOCwwLCJ6Il0sWzEwLDAsInciXSxbMywxLCJ5Il0sWzQsMCwieSJdLFs2LDAsInoiXSxbNywxLCJ6Il0sWzksMF0sWzEwLDEsInoiXSxbMTIsMSwidyJdLFsxMiwwLCJ6Il0sWzE0LDAsInciXSxbMCwxLCJnIiwwLHsiY3VydmUiOi0zfV0sWzAsMSwiZiIsMix7ImN1cnZlIjozfV0sWzIsMywiaSIsMix7ImN1cnZlIjo0fV0sWzIsMywiaiIsMV0sWzUsNiwiaCIsMl0sWzQsMSwiIiwyLHsic3R5bGUiOnsiYm9keSI6eyJuYW1lIjoiZGFzaGVkIn19fV0sWzQsNSwiIiwxLHsic3R5bGUiOnsiYm9keSI6eyJuYW1lIjoiZGFzaGVkIn19fV0sWzksMTAsImoiLDFdLFsxMSwxMiwiaiIsMV0sWzExLDEyLCJrIiwxLHsiY3VydmUiOi00fV0sWzcsNiwiIiwwLHsic3R5bGUiOnsiYm9keSI6eyJuYW1lIjoiZGFzaGVkIn19fV0sWzcsMiwiIiwwLHsic3R5bGUiOnsiYm9keSI6eyJuYW1lIjoiZGFzaGVkIn19fV0sWzE0LDEzLCJcXGFscGhhIiwwLHsic2hvcnRlbiI6eyJzb3VyY2UiOjIwLCJ0YXJnZXQiOjIwfX1dLFsxNSwxNiwiXFxiZXRhIiwwLHsic2hvcnRlbiI6eyJzb3VyY2UiOjIwLCJ0YXJnZXQiOjIwfX1dLFsyMSwyMiwiXFxnYW1tYSIsMCx7InNob3J0ZW4iOnsic291cmNlIjoyMCwidGFyZ2V0IjoyMH19XSxbMjAsMywiIiwxLHsic2hvcnRlbiI6eyJzb3VyY2UiOjIwfSwibGV2ZWwiOjEsInN0eWxlIjp7ImJvZHkiOnsibmFtZSI6ImRhc2hlZCJ9fX1dLFsyMCwxMSwiIiwxLHsic2hvcnRlbiI6eyJzb3VyY2UiOjIwfSwibGV2ZWwiOjEsInN0eWxlIjp7ImJvZHkiOnsibmFtZSI6ImRhc2hlZCJ9fX1dXQ==
  \[
    \begin{tikzcd}[column sep=small, row sep = small]
      x && y && y && z && z & {} & w && z && w \\
      &&& y &&&& z &&& z && w
      \arrow[""{name=0, anchor=center, inner sep=0}, "g", curve={height=-18pt}, from=1-1, to=1-3]
      \arrow[""{name=1, anchor=center, inner sep=0}, "f"', curve={height=18pt}, from=1-1, to=1-3]
      \arrow[""{name=2, anchor=center, inner sep=0}, "i"', curve={height=24pt}, from=1-9, to=1-11]
      \arrow[""{name=3, anchor=center, inner sep=0}, "j"{description}, from=1-9, to=1-11]
      \arrow["h"', from=1-5, to=1-7]
      \arrow[dashed, from=2-4, to=1-3]
      \arrow[dashed, from=2-4, to=1-5]
      \arrow[""{name=4, anchor=center, inner sep=0}, "j"{description}, from=2-11, to=2-13]
      \arrow[""{name=5, anchor=center, inner sep=0}, "j"{description}, from=1-13, to=1-15]
      \arrow[""{name=6, anchor=center, inner sep=0}, "k"{description}, curve={height=-24pt}, from=1-13, to=1-15]
      \arrow[dashed, from=2-8, to=1-7]
      \arrow[dashed, from=2-8, to=1-9]
      \arrow["\alpha", shorten <=5pt, shorten >=5pt, Rightarrow, from=1, to=0]
      \arrow["\beta", shorten <=3pt, shorten >=3pt, Rightarrow, from=2, to=3]
      \arrow["\gamma", shorten <=3pt, shorten >=3pt, Rightarrow, from=5, to=6]
      \arrow[shorten <=6pt, dashed, from=4, to=1-11]
      \arrow[shorten <=6pt, dashed, from=4, to=1-13]
    \end{tikzcd}
  \]
  The source and target of the diagram are given by:
  \[
    \begin{tikzcd}
      x & y & z & w
      \arrow["g", curve={height=-18pt}, from=1-1, to=1-2]
      \arrow["h", from=1-2, to=1-3]
      \arrow["k", curve={height=-24pt}, from=1-3, to=1-4]
    \end{tikzcd}
    \qquad\text{and}\qquad
    \begin{tikzcd}
      x & y & z & w
      \arrow["f"', curve={height=18pt}, from=1-1, to=1-2]
      \arrow["h", from=1-2, to=1-3]
      \arrow["i"', curve={height=24pt}, from=1-3, to=1-4]
    \end{tikzcd}
  \]
  which are isomorphic pasting diagrams.
\end{example}

\subsection{Weak higher categories}
\label{sec:weak}

The \(\infty\)-categories we have defined so far have all been strict \(\infty\)-categories, meaning that the laws are required to hold up to equality. In ordinary \(1\)-category theory, isomorphism is usually preferred over equality for comparing objects. Similarly, when we have access to higher dimensional arrows, it follows that that we can also consider isomorphisms between morphisms, and therefore consider laws such as associativity up to isomorphism instead of equality.

Topological spaces provide one of the primary examples for where it is useful to consider weak laws. Given a topological space \(X\), we can define a globular set of paths and homotopies. Let the \(0\)-cells be given by points \(x\) of the topological space, let morphisms from \(x\) to \(y\) be given as paths \(I \to X\) (where \(I\) is the topological interval \([0,1]\)) which send \(0\) to \(x\) and \(1\) to \(y\), and let higher cells be given by homotopies. The natural composition of two paths \(p\) and \(q\) is the following path:
\[
  (p * q)(i) =
  \begin{cases*}
    p(2i)&when \(i < 0.5\)\\
    q(2i-1)&when \(i \geq 0.5\)
  \end{cases*}
\]
which effectively lines up the paths end to end. Given \(3\) paths \(p\), \(q\), and \(r\), the compositions \((p * q) * r\) and \(p * (q * r)\) are not identical but are equal up to homotopy, meaning the two compositions are isomorphic. Therefore in this case the composition \(p * q\) does not form a strict \(\infty\)-category structure, but rather a weak structure.

\paragraph{Weak 2-categories} We start our exploration of weak higher categories by considering the lower dimension case of bicategories (weak \(2\)-categories). Here, interchange must still be given by a strict equality, as there are no non-trivial \(3\)-cells in a \(2\)-category. However, associativity and unitality can be given by isomorphisms known as associators and unitors:
\begin{align*}
  \alpha_{f,g,h} &: (f *_0 g) *_0 h \to f *_0 (g *_0 h)\\
  \lambda_f &: \id(x) *_0 f \to f\\
  \rho_f &: f *_0 \id(y) \to f
\end{align*}
for \(f : x \to y\), \(g : y \to z\), and \(h : z \to w\).

\begin{example}
  \label{ex:spans}
  All strict 2-categories are also bicategories. The bicategory of spans is an example of a bicategory which is not strict. Starting with a category \(\mathcal{C}\) equipped with chosen pullbacks, we define the bicategory of spans over \(\mathcal{C}\) to be:
  \begin{itemize}
  \item Objects are the same as \(\mathcal{C}\)
  \item Morphisms \(A\) to \(B\) are spans \(A \leftarrow C \to B\).
  \item A 2-morphism from \(A \leftarrow C \to B\) to \(A \leftarrow C' \to B\) is a morphism \(C \to C'\) such that the following diagram commutes:
    \[
      \begin{tikzcd}[row sep = small]
	& C \\
	A && B \\
	& {C'}
	\arrow[from=1-2, to=3-2]
	\arrow[from=3-2, to=2-1]
	\arrow[from=1-2, to=2-1]
	\arrow[from=1-2, to=2-3]
	\arrow[from=3-2, to=2-3]
      \end{tikzcd}
    \]
  \item Compositions and identities of 2-morphisms is given by composition and identities of the underlying morphisms in \(\mathcal{C}\).
  \item The identity on an object \(A\) is the span \(A \leftarrow A \to A\).
  \item Given spans \(A \leftarrow D \to B\) and \(B \leftarrow E \to C\), their composite is given by the pullback:
    \[
      \begin{tikzcd}[row sep=small]
	&& {D \times_B E} \\
	& D && E \\
	A && B && C
	\arrow[from=2-2, to=3-1]
	\arrow[from=2-2, to=3-3]
	\arrow[from=2-4, to=3-3]
	\arrow[from=2-4, to=3-5]
	\arrow[from=1-3, to=2-2]
	\arrow[from=1-3, to=2-4]
	\arrow["\lrcorner"{anchor=center, pos=0.125, rotate=-45}, draw=none, from=1-3, to=3-3]
      \end{tikzcd}
    \]
  \item Associators and unitors are given by the universal property of the pullback.
  \end{itemize}
\end{example}

In general, there could be many possible isomorphisms between \((f * g) * h\) and \(f * (g * h)\), and we require that the chosen morphisms satisfy certain compatibility properties. The first is that each of the associator, left unitor, and right unitor should be a natural isomorphism. The second is a property known as \emph{coherence}, saying that any two parallel morphisms built purely from naturality moves, associators, and unitors must be equal.

For bicategories it is sufficient to give two coherence laws: the triangle equality and pentagon equality. The triangle equality identifies two ways of cancelling the identity in the composite \(f * \id * g\), giving a compatibility between the left and right unitors. It is given by the following commutative diagram:

% https://q.uiver.app/#q=WzAsMyxbMCwwLCIoZiBcXHN0YXIgXFxpZCkgXFxzdGFyIGciXSxbMiwwLCJmIFxcc3RhciAoXFxpZCBcXHN0YXIgZykiXSxbMSwxLCJmIFxcc3RhciBnIl0sWzAsMSwiXFxhbHBoYV97ZixcXGlkLGd9Il0sWzAsMiwiXFxyaG9fZiBcXHN0YXJfMCBcXGlkKGcpIiwyXSxbMSwyLCJcXGlkKGYpXFxzdGFyXzBcXGxhbWJkYV9nIl1d
\[
  \begin{tikzcd}
    {(f * \id) * g} && {f * (\id * g)} \\
    & {f * g}
    \arrow["{\alpha_{f,\id,g}}", from=1-1, to=1-3]
    \arrow["{\rho_f *_0 \id(g)}"', from=1-1, to=2-2]
    \arrow["{\id(f)*_0\lambda_g}", from=1-3, to=2-2]
  \end{tikzcd}
\]

The pentagon equation identifies two ways of associating \(((f * g) * h) * k\) to \(f * (g * (h * k))\). It is given by the diagram below:
% https://q.uiver.app/#q=WzAsNSxbMSwzLCIoZiBcXHN0YXIgKGcgXFxzdGFyIGgpKSBcXHN0YXIgayJdLFswLDEsIigoZiBcXHN0YXIgZykgXFxzdGFyIGgpIFxcc3RhciBrIl0sWzIsMCwiKGYgXFxzdGFyIGcpIFxcc3RhciAoaCBcXHN0YXIgaykiXSxbNCwxLCJmIFxcc3RhciAoZyBcXHN0YXIgKGggXFxzdGFyIGspKSJdLFszLDMsImYgXFxzdGFyICgoZyBcXHN0YXIgaCkgXFxzdGFyIGspIl0sWzEsMiwiXFxhbHBoYV97ZiBcXHN0YXIgZyxoLGt9Il0sWzIsMywiXFxhbHBoYV97ZixnLGhcXHN0YXIga30iXSxbMSwwLCJcXGFscGhhX3tmLGcsaH0gXFxzdGFyXzAgXFxpZChrKSIsMl0sWzAsNCwiXFxhbHBoYV97ZixnXFxzdGFyIGgsa30iLDJdLFs0LDMsIlxcaWQoZilcXHN0YXJfMCBcXGFscGhhX3tnLGgsa30iLDJdXQ==
\[
  \begin{tikzcd}[column sep = -1.5em]
    && {(f * g) * (h * k)} \\
    {((f * g) * h) * k} &&&& {f * (g * (h * k))} \\
    \\
    & {(f * (g * h)) * k} && {f * ((g * h) * k)}
    \arrow["{\alpha_{f * g,h,k}}", from=2-1, to=1-3]
    \arrow["{\alpha_{f,g,h* k}}", from=1-3, to=2-5]
    \arrow["{\alpha_{f,g,h} *_0 \id(k)}"', from=2-1, to=4-2]
    \arrow["{\alpha_{f,g* h,k}}"', from=4-2, to=4-4]
    \arrow["{\id(f)*_0 \alpha_{g,h,k}}"', from=4-4, to=2-5]
  \end{tikzcd}
\]

Surprisingly, these two equations are enough to give full coherence. For the example of spans from \cref{ex:spans}, these two equations follow from the uniqueness of the universal morphism.

\paragraph{Weak \(\infty\)-categories} To move from weak \(2\)-categories to weak \(3\)-categories, new coherence cells for interchangers are added to replace the interchanger equalities, and new equalities must be added to specify the interaction between the interchangers and other coherence morphisms. Furthermore, the triangle and pentagon equation from \(2\)-categories will become an isomorphisms in a weak \(3\)-category, causing more coherence equations to be added.

As we move up in dimension, the number of coherence morphisms and equalities required increases exponentially. Whereas a bicategory has 11 operations (1-identity, 2-identity, 1-composition, vertical composition, horizontal composition, left unitor (and inverse), right unitor (and inverse), and associator (and inverse)), where as a fully weak tricategory already has around 51 operations~\cite{gurski2006algebraic}\footnote{The number here is obtained by unwrapping various subdefinitions and should be treated as approximate.}. Comparisons between the size of partially weak definitions can be found in \cite{bar2017data}.

Because of this complexity, we look for more uniform ways to represent the operations and axioms of an \(\infty\)-category. In this thesis, we will work with the type theory \Catt, which is based on a definition of \(\infty\)-categories due to \citeauthor{maltsiniotis2010grothendieck}~\cite{maltsiniotis2010grothendieck}, which is itself based on a definition of \(\infty\)-groupoid by \citeauthor{PursuingStacks}~\cite{PursuingStacks}. We will sketch the ideas behind these definitions here, and give a definition of \Catt in \cref{sec:type-theory-catt}.

The key insight behind Grothendieck's definition is that pasting diagrams should be weakly contractible, instead of containing a unique composite. Whereas in a strict \(\infty\)-category, each pasting diagram effectively has 1 composite, in a weak \(\infty\)-category there can be many operations over a pasting diagram.

These operations are assembled into a globular extension called a \emph{coherator}. A weak \(\infty\)-groupoid is then a presheaf on this coherator for which the opposite functor preserves globular sums (alternatively, the dual notion of globular product could be defined, and such a presheaf could be asked to preserve globular products). The objects of a coherator are given by pasting diagrams, with \(D^n\) being sent to the \(n\)-cells of the category and other pasting diagrams being sent to composable sets of cells (as determined by the preservation of globular sums).

Operations over a pasting diagram \(P\) in the coherator are given by morphisms \(D^n \to P\). When we take a presheaf over this, we obtain a function that takes an \(P\)-shaped collection of cells to a single \(n\)-cell. Operations can be precomposed with source and target maps \(D^{n-1} \to D^n\) to get the source and target of an operation. To build the coherator, we start by taking the category of pasting diagrams. The ``operations'' of this category consist solely of the inclusions of discs into pasting diagrams, and correspond to picking a single element from the pasting diagram. Other operations are then built using the following guiding principle.

\begin{principle-groupoid}
  Let \(f\) and \(g\) be two parallel operations over a pasting diagram \(P\). Then there is an operation \(h\) over \(P\) with source \(f\) and target \(g\).
\end{principle-groupoid}

We define a pair of operations \(f,g : D^n \to X\) to be \emph{parallel} if \(n = 0\) or \(n > 0\) and \(f \circ \mathbf{s}_{n-1} = g \circ \mathbf{s}_{n-1}\) and \(f \circ \mathbf{t}_{n-1} = g \circ \mathbf{t}_{n-1}\). A \emph{lift} for such a pair of parallel operations is an operation \(h : D^{n+1} \to X\) such that \(h \circ \mathbf{s}_{n} = f\) and \(h \circ \mathbf{t}_n = g\). Closing under the principle then amounts to inductively adding lifts for all parallel operations, while ensuring that the category remains a globular extension.

We start with some basic operations: Consider the pasting diagram \(A\):

\[
  \begin{tikzcd}
    x & y & z
    \arrow["a", from=1-1, to=1-2]
    \arrow["b", from=1-2, to=1-3]
  \end{tikzcd}
\]

where \(A = D^1 \amalg D^1\). Our rule now tells us that since \(x\) and \(z\) are elements of \(A\), that there should be an operation returning a cell with source \(x\) and target \(z\), namely the composition of \(a\) and \(b\). In the language of coherators, there are operations \(f, g : D^0 \to A\), where \(f\) includes into the source of the first disc of \(A\), and \(g\) includes into the target of the second disc of \(A\). These are trivially parallel, and so there exists a lift \(h : D^1 \to A\), giving 1-composition. Similarly, if we take the pasting diagram with a single \(0\)-cell \(x\) and no other cells, then applying our rule with \(f,g\) both being the operation returning the element \(x\) produces an operation with source and target \(x\), the identity on \(x\).

We can generate more complicated operations with this principle, consider pasting diagram \(B\):
\[
  \begin{tikzcd}
    x & y & z & w
    \arrow["f", from=1-1, to=1-2]
    \arrow["g", from=1-2, to=1-3]
    \arrow["h", from=1-3, to=1-4]
  \end{tikzcd}
\]
We already know the coherator contains 1-composition, and using composition and the universal property of globular sums, we can generate operations realising the compound composites \((f * g) * h\) and \(f * (g * h)\). The principle then gives us an operation returning the \(2\)-cell \((f * g) * h \to f * (g * h)\), which is of course our associator. This one principle allows us to generate all the structure we need, as well as structure that is arguably unnecessary, such as ternary compositions that did not appear in the definition of bicategory.

Unfortunately, as we have already mentioned, Grothendieck's definition is for \(\infty\)-groupoids, where everything is invertible, instead of \(\infty\)-categories in full generality, as we want to study in this thesis. This can be seen by taking the pasting diagram \(C\):
\[
  \begin{tikzcd}
    x & y
    \arrow["f", from=1-1, to=1-2]
  \end{tikzcd}
\]
and applying the rule with \(f\) returning \(y\) and \(g\) returning \(x\), giving an operation that returns a \(1\)-cell \(f^{-1} : y \to x\), the inverse of \(f\). The rule as we have stated it is too powerful.

Maltsiniotis' definition provides a solution to this problem by giving a more refined version of the principle. Whereas Grothendieck's definition treats all operations as coherences, Maltsiniotis' definition splits operations into two classes: compositions and equivalences. Both classes are obtained by restricting the classes of parallel operations that admit lifts.

We begin by defining what it means for an operation to be algebraic:
\begin{definition}
  Let \(\mathcal{C}\) be a globular extension for which the canonical functor \(P : \mathbf{Pd} \to \mathcal{C}\) is faithful and the identity on objects. Then an operation \(f : D^n \to X\) in \(\mathcal{C}\) is \emph{algebraic} if whenever \(f = P(g) \circ f'\), \(g = \id\).
\end{definition}
Intuitively, an operation is algebraic when it does not factor through any proper inclusion. Algebraicity is equivalent to requiring that an operation makes use of all the (locally maximal) elements of the pasting diagram.

Equivalences contain the various invertible laws of our \(\infty\)-categories such as associators, unitors, identities, and interchangers. For two operations \(f,g : D^n \to X\) to admit a lift under the rule for equivalences, they must both be algebraic. This gives the following rule:

\begin{principle-category}[Equivalences]
  Let \(f\) and \(g\) be two parallel operations over a pasting diagram \(P\). If both \(f\) and \(g\) use all locally maximal variables of \(f\), then there is an operation over \(P\) with source \(f\) and target \(g\).
\end{principle-category}

Clearly any operations generated by this principle are invertible, as the extra condition imposed is symmetric. For compositions we introduce the following asymmetric principle, recalling that pasting diagrams are equipped with source and target inclusions, and letting \(\partial^-(P)\) and \(\partial^+(P)\) be the images of these inclusions:

\begin{principle-category}[Composites]
  Let \(f\) and \(g\) are parallel operations over a (non-singleton) pasting diagram \(P\) such that \(f\) uses all locally maximal cells of \(\partial^-(P)\) and no cells outside of \(\partial^-(P)\) and \(g\) uses all locally maximal cells of \(\partial^+(P)\) and no cells outside of \(\partial^+(P)\). Then there is an operation over \(P\) with source \(f\) and target \(g\).
\end{principle-category}

The condition required to form a composite can be expressed by the operation \(f : D^n \to P\) factoring into an algebraic map composed with the source inclusion into \(P\), and similar for \(g\) with the target inclusion. It can be easily checked that the inverse operation given above does not satisfy the criteria for being an equivalence or composite.

As with Grothendieck's definition, a coherator can be made by closing the globular extension of pasting diagrams under these restricted principles, and then weak \(\infty\)-categories can be defined to be presheaves on this coherator such that the opposite functor preserves globular sums.

\begin{remark}
  We have claimed that a coherator can be formed by closing under adding lifts to parallel operations, though this is not precise and there are actually multiple ways of performing this closure that lead to different coherators. For example, one could add the lift for 1-composition twice, to get two distinct 1-composition operations, as long as one also added a lift between these now parallel operations. Grothendieck gives a general schema for producing coherators, and conjectures that any two coherators give rise to equivalent models of \(\infty\)-categories.
\end{remark}

We now turn our attention back to the proof of Eckmann-Hilton from \cref{fig:eh}. Given a \(0\)-cell \(x\) and two scalars \(\alpha, \beta : \id(x) \to \id(x)\), we expect the Eckmann-Hilton argument to give us an isomorphism in a weak higher category, rather than the equality obtained in the strict case. In fact we immediately see that equalities 2, 3, and 4 in the proof can be immediately replaced by isomorphisms (interchangers and unitors).

The first and last equalities however are more problematic, although at first we may believe that there should exist some horizontal unitor isomorphism, upon closer inspection the two compositions do not even have the same boundary and so are not parallel. The composition \(\alpha *_1 \beta\) has source and target \(\id(x)\), whereas the source of \(\alpha *_0 \id(\id(x))\) is \(\id(x) *_0 \id(x)\).

To recover the proof in a weak setting, the intermediate composites must be composed with unitors so that they all have source and target \(\id(x)\). To give equivalences for the first and last step, these unitors must be moved around with naturality moves, and at a critical point the isomorphism \(\lambda_{\id(x)} \simeq \rho_{\id(x)}\) is required. Multiple full proofs of Eckmann-Hilton will be given in \cref{sec:rehydration}. The proof of Eckmann-Hilton is vastly simpler in strict case, mainly due to the presence of the equation \(\id(x) *_0 \id(x) = \id(x)\).
%  It is natural to ask whether it is necessary to work with weak higher categories at all, given the extra complexity.

% For bicategories, it turns out that the answer is no. Every bicategory is biequivalent to a strict 2-category~\cite[Theorem 1.4]{gordon1995coherence}, meaning that to prove any equation holds in a bicategory, it suffices to prove that the same equation holds in a strict 2-category. This allows the more general notion of bicategory to be used without incurring extra proof burden.

% For more than 2-dimensions, this full strictification is no longer possible.\todo{This should all likely go in the introduction}

\subsection{Computads}
\label{sec:computads}

A free group is generated by a set, and a free category is generated by a directed graph, and so it is a natural question what the generating data for a free higher category is. We have already seen that a free higher category can be generated by a globular set, but free \(\infty\)-categories can also be generated by data that does not form a globular set.

Consider the minimum data needed to to state the Eckmann-Hilton principle~(\cref{prop:eh}). We require a single \(0\)-cell \(x\), and two \(2\)-cells \(\alpha, \beta : \id(x) \to \id(x)\). This data does not form a globular set as, for example, the source of the \(2\)-cell \(\alpha\) is not in the generating data, but is rather an operation applied to the data. We could try to remedy this by adding a new \(1\)-cell \(f\) to the data to represent \(\id(x)\), but then the connection between \(\id(x)\) and \(f\) would be lost and \(f\) and \(\id(x)\) would be distinct in any free \(\infty\)-category generated on this data.

The correct generating data for an \(\infty\)-category is a \emph{computad}. A version for 2-categories was introduced by \citeauthor{street1976limits}~\cite{street1976limits}, which allows a generating \(2\)-cell to have a composite or identity as its source or target. These were extended to strict \(\infty\)-categories by \citeauthor{burroni1993higher}~\cite{burroni1993higher} and weak \(\infty\)-categories by
\citeauthor{batanin1998computads}~\cite{batanin1998computads}, which allow the source and target of an \(n\)-cell to be any \((n-1)\)-cell of the free \(\infty\)-category generated by the lower dimensional data.

A modern approach to computads for weak \(\infty\)-categories is given by \citeauthor{dean2022computads}~\cite{dean2022computads}, which avoids much of the complexity of globular operads, relying only on (mutual) structural induction. This definition of a computad is much closer in style (and is inspired by) the type theory \Catt which we review in \cref{sec:type-theory-catt}.

\section{The type theory \Catt}
\label{sec:type-theory-catt}

In this section we give an overview of the dependent type theory \Catt~\cite{finster2017type}. \Catt serves as a definition of weak \(\infty\)-categories, by defining a weak \(\infty\)-category to be a model of the type theory (e.g. using categories with families~\cite{MR1474535}). In \cref{cha:gener-pres-catt}, we give a more general and comprehensive presentation of \Catt, allowing the addition of equality relations to the type theory, preempting \cref{cha:cattstrict}. In contrast this section presents the version of \Catt closer to the one found in the literature, and compares its various constructions to the ideas introduced in \cref{sec:weak}.

\subsection{Syntax of \Catt}
\label{sec:syntax-catt}

\Catt has 4 classes of syntax: contexts, terms, types, and substitutions.
\begin{itemize}
\item Contexts contain a list of variables with an associated type. We can consider contexts as finite computads, the generating data for a weak \(\infty\)-category (see \cref{sec:computads}). It is alternatively valid to consider contexts in \Catt as finitely generated \(\infty\)-categories. The set of contexts contains all globular sets (and hence all pasting diagrams).
\item Terms over a context \(\Gamma\) correspond to the operations from \cref{sec:weak}. Terms can either be a variable, which corresponds to the operations which pick a single cell out of a globular set, or those generated by the unique constructor \(\mathsf{coh}\), which correspond to the operations generated by lifting. A term over a context \(\Gamma\) can also be seen as a element of the free \(\infty\)-category generated from \(\Gamma\).
\item Types over a context \(\Gamma\) consist of a collection of terms over the same context, and contain the boundary information for a term. Types either take the form of the constructor \(*\), the type of \(0\)-cells (which have no boundary data), or an arrow type \(\arr s A t\), where \(s\) and \(t\) are terms giving the source and target of the boundary and the type \(A\) gives lower dimensional boundary information\footnote{This can be viewed as a directed version of the equality type \(s =_A t\) from Martin-L\"of type theory}.
\item Substitutions from a context \(\Gamma\) to a context \(\Delta\) are a mapping from variables of \(\Gamma\) to terms of \(\Delta\). These play the role of functors between the \(\infty\)-categories generated by \(\Gamma\) and \(\Delta\) and are also syntactically crucial for forming compound composites in the theory.
\end{itemize}

\begin{figure}[h]
  \centering
    \begin{tabular}{Sc Sc}
    {
    \begin{prooftree}
      \hypo{\phantom{\Term}} \infer1{\emptyset : \Ctx}
    \end{prooftree}
    }
    &
      {
      \begin{prooftree}
        \hypo{\Gamma : \Ctx} \hypo{A : \Type_\Gamma}
        \infer2{\Gamma, (x : A) : \Ctx}
      \end{prooftree}}
    \\
    {
    \begin{prooftree}
      \hypo{\phantom{\Term}} \infer1{\langle \rangle : \emptyset \to \Gamma}
    \end{prooftree}
    }
    & {
      \begin{prooftree}
        \hypo{\sigma : \Delta \to \Gamma} \hypo{t : \Term_\Gamma} \hypo{A : \Type_\Delta}
        \infer3{\langle \sigma , t \rangle : \Delta, (x : A) \to \Gamma}
      \end{prooftree}
      }
    \\
    {
    \begin{prooftree}
      \hypo{\phantom{\Type}} \infer1{\star : \Type_\Gamma}
    \end{prooftree}
    }
    & {
      \begin{prooftree}
        \hypo{A : \Type_\Gamma} \hypo{s : \Term_\Gamma} \hypo{t : \Term_\Gamma}
        \infer3{\arr s A t : \Type_\Gamma}
      \end{prooftree}
      }
    \\
    {
    \begin{prooftree}
      \hypo{x \in \Var(\Gamma)\vphantom{\Type}} \infer1{x : \Term_\Gamma}
    \end{prooftree}
    }
    & {
      \begin{prooftree}
        \hypo{\Delta : \Ctx} \hypo{A : \Type_\Delta} \hypo{\sigma : \Delta \to \Gamma}
        \infer3{\Coh \Delta A \sigma : \Term_\Gamma}
      \end{prooftree}
      }

    \end{tabular}

    \vspace{-5pt}
  \caption{Syntax constructions in \Catt.}
  \label{fig:syntax}
\end{figure}

The rules for constructing each piece of syntax are given in \cref{fig:syntax}. To simplify the notation, we may avoid writing substitutions in a fully nested fashion, writing \(\langle \sigma , s , t \rangle\) instead of \(\langle \langle \sigma, s \rangle, t \rangle\), or \(\langle s \rangle\) instead of \(\langle \langle \rangle, s \rangle\). We may also omit the subscript in the arrow type. As opposed to the original paper on \Catt, we fibre terms, types, and substitutions over contexts, allowing us to avoid any problems with substitution only extending to a partial operation on terms. We write \(\Ctx\) for the set of contexts, \(\Term_\Gamma\) for the set of terms in a context \(\Gamma\), \(\Type_\Gamma\) for the set of types in a context \(\Gamma\), and write \(\sigma : \Delta \to \Gamma\) when \(\sigma\) is a substitution taking variables of \(\Delta\) to terms of \(\Gamma\). In the literature, substitutions are often written as going in the opposite direction. We emphasise here that the direction of our substitution morphisms agrees with the direction of the function from variables to terms, the direction of the induced functor between the \(\infty\)-categories freely generated from the domain and codomain contexts, and the direction of arrows in a Grothendieck coherator.

We write \(\equiv\) for \emph{syntactic equality}, up to renaming of variables and \(\alpha\)-equivalence. The various pieces of syntax will be considered as equal up to this relation, which can be achieved by using a de Brujin index representation of the syntax as we present in \cref{cha:gener-pres-catt} for the formalisation. However, we continue to use named variables in the prose of the thesis to aid readability, assuming that all variables in a context are always distinct. We contrast this with the equality symbol, \(=\), which will represent the equality derived from extra equality rules we have placed on \Catt in \cref{sec:catt-with-equality}, and will be referred to as \emph{definitional equality}.

The action of a substitution \(\sigma : \Delta \to \Gamma\) can be extended from variables to all terms \(t \in \Term_\Delta\), types \(A \in \Type_\Delta\), and substitutions \(\tau : \Theta \to \Delta\) by mutual recursion:
\begin{align*}
  x \sub \sigma &= t&\text{if }(x \mapsto t) \in \sigma\\
  \Coh \Theta A \tau \sub \sigma &= \Coh \Theta A {\tau \bullet \sigma}\\
  \star \sub \sigma &= \star\\
  \arr s A t \sub \sigma &= \arr {s \sub \sigma} {A \sub \sigma} {t \sub \sigma}\\
  \langle \rangle \bullet \sigma &= \langle \rangle\\
  \langle \tau , t \rangle \bullet \sigma &= \langle \tau \bullet \sigma , t \sub \sigma \rangle
\end{align*}

For every context \(\Gamma\), there is an identity substitution \(\id_\Gamma\), which sends every variable to itself, which along with composition of substitutions above gives a category of contexts and substitutions.

The coherence constructor \(\Coh \Delta A \sigma\) allows us to construct lifts between parallel operations over pasting diagrams. The context \(\Delta\) plays the role of the pasting diagram. The type \(A\) will always be of the form \(\arr s B t\), and the terms \(s\) and \(t\) play the role of the parallel operation (with the type \(\arr s B t\) being well typed ensuring that \(s\) and \(t\) are parallel). The substitution \(\sigma : \Delta \to \Gamma\) holds the data of a set of arguments to the coherence, allowing compound composites/operations to be formed and taking the role of composition of morphisms in the coherator.

We next define the free variables of each piece of syntax. These will be used to encode the condition of an operation being algebraic from the theory of non-invertible coherators. Let \(\Var(\Gamma)\) denote the variables of \(\Gamma\). For a term \(t \in \Term_\Gamma\), a type \(A \in \Type_\Gamma\) and a substitution \(\sigma : \Delta \to \Gamma\) we define their free variables \(\FV(t), \FV(A), \FV(\sigma) \subseteq \Var(\Gamma)\) by mutual recursion.
\begin{align*}
  \FV(x) &= \{x\} &\text{if \(x\) is a variable}\\
  \FV(\Coh \Delta A \sigma) &= \FV(\sigma)\\
  \FV(\star) &= \{\}\\
  \FV(\arr s A t) &= \FV(s) \cup \FV(A) \cup \FV(t)\\
  \FV(\langle \rangle) &= \{\}\\
  \FV(\langle \sigma , t \rangle) &= \FV(\sigma) \cup \FV(t)
\end{align*}

The free variables of a term is often the wrong notion to use for testing algebraicity. For example in the context \(D^1\), the term \(d_1\) has free variables \(\{d_1\}\), whereas the unary composite of \(d_1\), \(\Coh {D_1} {\arr {d_0^-} \star {d_0^+}} {\id_{D^1}}\), has free variables \(\{d_0^-,d_0^+,d_1\}\). To remedy this, the original paper considers \(\FV(t) \cup \FV(A)\), for a term \(t\) of type \(A\). In this thesis we instead define the support of each piece of syntax, a purely syntactic construction.

\begin{definition}
  Fix a context \(\Gamma\). The subset \(V \subseteq \Var(\Gamma)\) is \emph{downwards closed} if for all \((x : A) \in \Gamma\) we have:
  \[x \in V \implies \FV(A) \subseteq V\]
  The downwards closure of a set \(V\) in a context \(\Gamma\), \(\DC_\Gamma(V)\) can be defined by induction on the context:
  \begin{align*}
    \DC_\emptyset(\emptyset) &= \emptyset\\
    \DC_{\Gamma, x : A}(V) &=
                               \begin{cases*}
                                 \DC_\Gamma(V)&if \(x \not\in V\)\\
                                 \{x\} \cup \DC_\Gamma(V \cup \FV(A))&if \(x \in V\)\\
                               \end{cases*}
  \end{align*}
  The support of a term, type, or substitution is then defined as the downwards closure of its free variables:
  \[ \Supp(t) = \DC_\Gamma(\FV(t))\qquad \Supp(A) = \DC_\Gamma(\FV(A))\qquad \Supp(\sigma) = \DC_\Gamma(\FV(\sigma)) \]
  for terms \(t \in \Term_\Gamma\), types \(A \in \Type_\Gamma\), and substitutions \(\sigma : \Delta \to \Gamma\).
\end{definition}

We will see later\todo{Cross ref} that for well-typed terms \(t\) of typed \(A\) that the support of \(t\) is equal to \(\FV(t) \cup \FV(A)\) and that \(\Supp(A) = \FV(A)\) for well-formed types. Modifying \Catt to use support therefore does not change the theory.

We lastly define the \emph{dimension} of types, contexts, and terms. For types this is defined recursively:
\[ \dim(\star) = 0 \qquad \dim(\arr s A t) = 1 + \dim(A) \]
For contexts we define \(\dim(\Gamma)\) to be the maximum of the dimension of each type in \(\Gamma\). For coherences \(\Coh \Gamma A \sigma\), the dimension is given by \(\dim(A)\), and for variables the dimension is given by the dimension of the associatiated type in the context.

\subsection{Ps-contexts}
\label{sec:ps-contexts}

We need to be able to describe pasting diagrams within the theory \Catt. As contexts model globular sets it is natural to treat pasting diagrams as a subset of contexts and will build pasting diagrams by iteratively attaching discs to a context. This is done by introducing the judgements:

\[ \Delta \vdash_{\mathsf{ps}} x : A \qquad \text{and}\qquad \Delta \vdash_{\mathsf{ps}} \]

If the first judgement holds, then \(\Delta\) is a pasting diagram for which a disc can be attached to the variable \(x\), called a \emph{dangling variable}, which has type \(A\). The contexts \(\Delta\) for which the second judgement holds are fully formed pasting diagrams, which we call \emph{Ps-contexts} (short for pasting scheme contexts). The rules for these judgements are given in \cref{fig:ps-context}.

We note that these rules do not just specify which globular sets are pasting diagrams, but they also specify an ordering on the elements of the pasting diagram, ensuring that there is a unique Ps-context for each pasting diagram. For example, the following judgement holds:
\begin{equation}
  \label[judgement]{judg:ps}
  (x : \star), (y : \star), (f : \arr x \star y), (z: \star), (g : \arr y \star z) \vdash_{\mathsf{ps}}
\end{equation}
However, the context:
\[(y : \star), (z : \star), (g : \arr y \star z), (x : \star), (f : \arr x \star y)\]
represents the same globular set but is not a Ps-context.

\begin{figure}[h]
  \centering
  \begin{mathpar}
    \inferrule{ }{(x : \star) \vdash_{\mathsf{ps}} x : \star}{(\textsc{pss})}
    \and
    \inferrule{\Gamma \vdash_{\mathsf{ps}} x : A}{\Gamma, (y : A), (f : \arr x A y)}{(\textsc{pse})}
    \and
    \inferrule{\Gamma \vdash_{\mathsf{ps}} x : \arr s A t}{\Gamma \vdash_{\mathsf{ps}} t : A}{(\textsc{psd})}
    \and
    \inferrule{\Gamma \vdash_{\mathsf{ps}} x : \star}{\Gamma \vdash_{\mathsf{ps}}}{(\textsc{ps})}
  \end{mathpar}
  \caption{Rules for Ps-contexts}
  \label{fig:ps-context}
\end{figure}

\begin{example}
  \Cref{judg:ps} is given by the following derivation:
  \[\begin{prooftree}
    \hypo{ }
    \infer1[(\textsc{pss})]{(x : \star) \vdash_{\mathsf{ps}} x : \star}
    \infer1[(\textsc{pse})]{(x : \star), (y : \star), (f : \arr x \star y) \vdash_{\mathsf{ps}} f : \arr x \star y}
    \infer1[(\textsc{psd})]{(x : \star), (y : \star), (f : \arr x \star y) \vdash_{\mathsf{ps}} y : \star}
    \infer1[(\textsc{pse})]{(x : \star), (y : \star), (f : \arr x \star y), (z : \star), (g : \arr y \star z) \vdash_{\mathsf{ps}} g : \arr x \star y}
    \infer1[(\textsc{psd})]{(x : \star), (y : \star), (f : \arr x \star y), (z : \star), (g : \arr y \star z) \vdash_{\mathsf{ps}} z : \star}
    \infer1[(\textsc{ps})]{(x : \star), (y : \star), (f : \arr x \star y), (z : \star), (g : \arr y \star z) \vdash_{\mathsf{ps}}}
  \end{prooftree}\]
The applications of (\textsc{pse}) allow new variables to be added to the context, by adding a fresh variable, and attaching a variable from the dangling variable to the new fresh variable. The rule (\textsc{psd}) encodes that if we can attach a variable to \(f : x \to y\), then we can also attach a variable to \(y\). Finally, the rule (\textsc{ps}) forces as many (\textsc{psd}) rules to be applied as possible before completing the derivation, ensuring that derivations of Ps-contexts are unique.
\end{example}

We now state the following theorem, which follows immediately from \cite[Theorem~53]{benjamin2021globular}.

\begin{theorem}
  The set of Ps-contexts is in bijection with the set of pasting diagrams.
\end{theorem}

In order to use Ps-contexts as our notion of pasting diagram, we need to be able to identify the source and target variables of each Ps-context. This will be done by specifying the dimension \(i\) source and target of each pasting context.

More precisely, for each Ps-context \(\Gamma\) and \(i \in \mathbb{N}\), we define a Ps-context we define subcontexts:
\[ \inc i - \Gamma : \bound i \Gamma \to \Gamma \qquad \text{and}\qquad \inc i + \Gamma : \bound i \Gamma \to \Gamma\]
Intuitively, the context \(\bound i \Gamma\) can be constructed by removing any variables of dimension greater than \(i\) from \(\Gamma\), and quotienting the dimension \(i\) variables by the (symmetric transitive closure of the) relation \(x \sim y\) if there exists an \(f : x \to y\). The inclusions then send this quotiented variable to the variable appearing first in the equivalence class for the source inclusion, and the variable appearing last in the class for the target inclusion.

These contexts and substitutions can be defined by recursion on the context \(\Gamma\):
\begin{align*}
  \bound i {(x : \star)} &= {(x : \star)}\\
  \bound i {\Gamma, (y : A), (f : \arr x A y)} &=
                                                  \begin{cases*}
                                                    \bound i \Gamma&if \(i \leq \dim(A)\)\\
                                                    \bound i \Gamma, (y : A), (f : \arr x A y)&otherwise
                                                  \end{cases*}\\
  \inc i \epsilon {(x : \star)} &= \langle x \rangle\\
  \inc i \epsilon {\Gamma, (y : A) , (f : \arr x A y)} &=
                                                           \begin{cases*}
                                                             \mathrlap{\inc i \epsilon \Gamma}{\phantom{\bound i \Gamma, (y : A), (f : \arr x A y)}}&if \(i < \dim(A)\)\\
                                                             \inc i - \Gamma&if \(i = \dim(A)\) and \(\epsilon = -\)\\
                                                             \replace(\inc i + \Gamma, y)&if \(i = \dim(A)\) and \(\epsilon = +\)\\
                                                             \langle \inc i \epsilon \Gamma, y, f \rangle &otherwise
                                                           \end{cases*}
\end{align*}
where \(\epsilon \in \{-,+\}\) and \(\replace(\langle \sigma, s \rangle, t) = \langle \sigma, t \rangle\). As it will be common to take the boundary of \(\Gamma\) at the dimension below the dimension of \(\Gamma\) itself, we write
\[\inc {} \epsilon \Gamma = \inc {\dim(\Gamma) - 1} \epsilon \Gamma\]
when \(\dim(\Gamma)\) is not zero.

In the original \Catt paper, these inclusion substitutions are not given and instead the source and target variables are given directly as subcontexts. It can be easily checked that the free variables of the inclusions are equal to the subcontexts, and that the free variable sets of these inclusions are downwards closed. It is known, e.g. from \cite[Lemma~55]{benjamin2021globular}, that these constructions agree with the constructions of the source and target pasting diagrams in \cref{sec:pasting-diagrams}.

\subsection{Typing for \Catt}
\label{sec:typing-catt}

We now have all the prerequisites in place to state the typing rules for \Catt. These take the form of 4 judgements (not including the judgements for Ps-contexts introduced in \cref{sec:ps-contexts}):
\begin{alignat*}{2}
  &\Gamma \vdash&\qquad&\text{\(\Gamma \in \Ctx\) is a well-formed context.}\\
  &\Gamma \vdash A&&\text{\(A \in \Type_\Gamma\) is a well-formed type in context \(\Gamma\).}\\
  &\Gamma \vdash t : A &&\text{\(t \in \Term_\Gamma\) is a well-formed term of type \(A \in \Type_\Gamma\).}\\
  &\Gamma \vdash \sigma : \Delta &&\text{\(\sigma : \Delta \to \Gamma\) is a well-formed substitution.}
\end{alignat*}

The typing rules for these judgements are then given in \cref{fig:catt-typing}. As most of these are standard we draw attention to a couple of the key rules. The rule for arrow types ensures that both the source and target of the arrow themselves have the same type, namely the one given in the subscript of the arrow. This effectively ensures the globular nature of the type theory, as given a term \(f : \arr s {\arr x A y} t\), both the source of the source and source of the target are \(x\), and both the target of the source and target of the target are \(y\).

\begin{figure}[h]
  \centering
  \begin{mathpar}
    \inferrule{ }{\emptyset \vdash}
    \and
    \inferrule{\Gamma \vdash\\ \Gamma \vdash A}{\Gamma, (x : A) \vdash}
    \and
    \inferrule{ }{\Gamma \vdash \star}
    \and
    \inferrule{\Gamma \vdash s : A \\ \Gamma \vdash A \\ \Gamma \vdash t : A}{\Gamma \vdash \arr s A t}
    \\
    \inferrule{ }{\Gamma \vdash \langle\rangle : \emptyset}
    \and
    \inferrule{\Gamma \vdash \sigma : \Delta\\ \Gamma \vdash t : A\sub\sigma}{\Gamma \vdash \langle \sigma , t \rangle : \Delta, (x : A)}
    \and
    \inferrule{(x : A) \in \Gamma}{\Gamma \vdash x : A}
    \and
    \inferrule{\Delta \vdash_{\mathsf{ps}}\\ \Delta \vdash \arr s A t \\ \Gamma \vdash \sigma : \Delta\\\dim(\Delta) \neq 0\\\supp(s) = \supp(\inc {} - \Delta)\\\supp(t) = \supp(\inc {} + \Delta)}{\Gamma \vdash \Coh \Delta {\arr s A t} \sigma : \arr {s \sub \sigma} {A \sub \sigma} {t \sub \sigma}}
    \and
    \inferrule{\Delta \vdash_{\mathsf{ps}}\\ \Delta \vdash \arr s A t \\ \Gamma \vdash \sigma : \Delta\\\supp(s) = \supp(t) = \Var(\Delta)}{\Gamma \vdash \Coh \Delta {\arr s A t} \sigma : \arr {s \sub \sigma} {A \sub \sigma} {t \sub \sigma}}
  \end{mathpar}
  \caption{Typing rules for \Catt}
  \label{fig:catt-typing}
\end{figure}

There are two rules given for typing coherence, corresponding to the two guiding principles for categories from \cref{sec:weak}. The first rule allows composites to be typed and the second allows equivalences to be typed. In both, the Ps-context \(\Delta\) corresponds to the pasting diagram \(P\), the terms \(s\) and \(t\) correspond to the operations \(f\) and \(g\) over \(P\) (with the judgement \(\Delta \vdash \arr s A t\) enforcing that they are parallel), and the conditions involving support give the remaining side conditions.

By a straightforward mutual induction we can prove that application of substitution to terms, types, and other substitutions preserves typing. Therefore, the \emph{syntactic category} of \Catt can be formed, which contains well-formed contexts as objects and well-typed substitutions between these contexts as morphisms, which by abuse of notation we also call \Catt. There is a full subcategory \(\Catt^{\mathsf{ps}}\), which only contains the contexts which are Ps-contexts.

\begin{theorem}
  The category \(\Catt^{\mathsf{ps}}\) is a coherator for \(\infty\)-categories.
\end{theorem}
\begin{proof}
  Follows from \cite[Theorem~73]{benjamin2021globular}, noting that the opposite convention for substitution is used in that paper.
\end{proof}

Thus, we immediately get that a presheaf over \(\Catt^{\mathsf{ps}}\) which preserves globular products is an \(\infty\)-category (using the Maltsiniotis definition). Further, presheafs of this form are equivalent to type-theoretic models of \Catt by \cite[Theorem~88]{benjamin2021globular}, meaning type-theoretic models of \Catt are \(\infty\)-categories.

\subsection{Basic constructions}
\label{sec:basic-constructions}

We now introduce some examples of basic categorical operations in order to give some early examples. Suppose we have terms \(a : \arr s \star t\) and \(b : \arr t \star u\) in some context \(\Gamma\). Then the Ps-context
\[ \Delta = (x : \star), (y : \star), (f : \arr x \star y), (z : \star), (g : \arr y \star z) \]
from \cref{judg:ps} can be used to form the 1-composite:
\[ a *_0 b = \Coh \Delta {\arr x \star z} {\langle s, t, a, u, b \rangle}\]
It is often not necessary to give all the terms in a substitution, especially when the substitution is from a pasting diagram (or more generally a globular set). In these cases it is sufficient to give terms for the \emph{locally maximal} variables of the context, those that do not appear as the source or target of another variable. For \(\Delta\), the locally maximal variables are \(f\) and \(g\), and so it suffices to give the substitution above as \(\langle a , b \rangle\), with the rest of the terms being inferable.

The disc contexts \(D^n\) can be formed in \Catt as the analogue of the disc globular sets given in \cref{ex:disc} and satisfy the property that a substitution from a disc context \(D^n\) contains the same data as a term and \(n\)-dimensional type. Given a term \(t\) of type \(A\) in context \(\Gamma\), we write this substitution \(\{A,t\} : D^{\dim(A)} \to \Gamma\). All disc contexts are Ps-contexts.

Using these, the identity can be formed on a term \(t\) of type \(A\) in \(\Gamma\):
\[\id(A,t) = \Coh {D^n} {\arr {d_n} {} {d_n}} {\{A, t\}}\]
where \(\dim(A) = n\), which is typed using the rule for equivalences. The structure of this term changes for different values of \(n\), and we will relate these different terms in \cref{sec:suspension}. As before, the non-locally maximal elements of a substitution
can be inferred, and so we may write \(\id(t)\) or \(\{t\}\) when the type \(A\) is inferable\footnote{In \Catt, all types are inferable, though later it may be necessary to specify the exact type we are using up to syntactic equality.}.

\paragraph{Standard coherences}
The composite and identity above form part of a more general collection of coherences, which we call \emph{standard coherences}.

\begin{definition}
  Given a pasting diagram \(\Delta\), we mutually define for all \(n\) the \emph{standard coherence} \(\mathcal{C}_\Delta^n\), the \emph{standard term} \(\mathcal{T}_\Delta^n\), and the \emph{standard type} \(\mathcal{U}_\Delta^n\):
  \begin{alignat*}{2}
    &\mathcal{C}_\Delta^n &&= \Coh \Delta {\mathcal{U}_\Delta^n} {\id_\Delta}\\
    &\mathcal{T}_\Delta^n &&=
                           \begin{cases}
                             d^n &\text{when \(\Delta\) is the disc \(D^n\)}\\
                             \mathcal{C}_\Delta^n &\text{otherwise}
                           \end{cases}\\
    &\mathcal{U}_\Delta^0 &&= \star\\
    &\mathcal{U}_\Delta^{n+1} &&= \arr {\mathcal{T}_{\bound n \Delta}^n \sub {\inc n - \Delta}} {\mathcal{U}_\Delta^n} {\mathcal{T}_{\bound n \Delta}^n \sub {\inc n + \Delta}}
  \end{alignat*}
  The standard type takes the standard term over each boundary of \(\Delta\), includes these all back into \(\Delta\) and assembles them into a type. When \(n = \dim(\Delta)\) we will refer to the standard coherence as the \emph{standard composite}.
\end{definition}

Intuitively, the standard coherence \(\mathcal{C}_\Delta^n\) is the canonical composite in dimension \(n\) of the pasting diagram \(\Delta\). To give this a type is needed to form the coherence, for which the standard type \(\mathcal{U}_\Delta^n\) is used. The standard term \(\mathcal{T}_\Delta^n\) is used as a variant of the standard coherence which special cases disc contexts. This avoids the standard type containing unary composites and allows standard composites (of non disc-contexts) to be normal forms of the reduction schemes that will be described in \cref{cha:cattstrict}.

It is immediate that the composite \(a *_0 b\) is given by \(\mathcal{C}_\Delta^1\sub{\langle a , b \rangle}\) and the identity on a term \(t\) of dimension \(n\) is given by \(\mathcal{C}_{D^n}^{n+1}\sub{\{t\}}\). This construction can be used to generate all the composites in the definition of a strict \(\infty\)-category. For example the vertical composite of \(2\)-cells is the standard composite over the context given by the diagram:
\[
  \begin{tikzcd}
    x && y
    \arrow[""{name=0, anchor=center, inner sep=0}, "f"', curve={height=24pt}, from=1-1, to=1-3]
    \arrow[""{name=1, anchor=center, inner sep=0}, "h", curve={height=-24pt}, from=1-1, to=1-3]
    \arrow[""{name=2, anchor=center, inner sep=0}, "g"{description}, from=1-1, to=1-3]
    \arrow["\alpha", shorten <=3pt, shorten >=3pt, Rightarrow, from=0, to=2]
    \arrow["\beta", shorten <=3pt, shorten >=3pt, Rightarrow, from=2, to=1]
  \end{tikzcd}
\]
and the horizontal composite of \(2\)-cells is the standard composite over:
\[
  \begin{tikzcd}
    x & y & z
    \arrow[""{name=0, anchor=center, inner sep=0}, "g", curve={height=-18pt}, from=1-1, to=1-2]
    \arrow[""{name=1, anchor=center, inner sep=0}, "f"', curve={height=18pt}, from=1-1, to=1-2]
    \arrow[""{name=2, anchor=center, inner sep=0}, "i", curve={height=-18pt}, from=1-2, to=1-3]
    \arrow[""{name=3, anchor=center, inner sep=0}, "h"', curve={height=18pt}, from=1-2, to=1-3]
    \arrow["\alpha", shorten <=5pt, shorten >=5pt, Rightarrow, from=1, to=0]
    \arrow["\beta", shorten <=5pt, shorten >=5pt, Rightarrow, from=3, to=2]
  \end{tikzcd}
\]
Noting that the standard type over the above diagram has source \(f * h\) and target \(g * i\), themselves being standard compositions demonstrating the mutual recursive behaviour of these constructions.

\begin{remark}
  Above we gave two Ps-contexts by drawing a diagram of the globular set that they represent. Ps-contexts fix the order that variables occur in and as such the mapping from Ps-contexts to globular sets is injective. The use of diagrams to define Ps-contexts is therefore unambiguous.
\end{remark}

\paragraph{Further examples}
The substitution component of a coherence allows operations to be combined into compound operations. Consider the (Ps-)context given by the following diagram:
\[\Gamma =
  \begin{tikzcd}
    s & t & u & v
    \arrow["a", from=1-1, to=1-2]
    \arrow["b", from=1-2, to=1-3]
    \arrow["c", from=1-3, to=1-4]
  \end{tikzcd}
\]
There are (at least) 3 ways to compose together the elements of this context. We could take the unbiased ternary composite \(a * b * c = \mathcal{C}_\Gamma^1\sub{\langle a, b, c\rangle}\), but could also construct either biased composite:
\begin{align*}
  (a * b) * c &= \mathcal{C}_\Delta^1\sub{\langle \mathcal{C}_\Delta^1\sub{\langle a,b\rangle}, c\rangle}\\
  a * (b * c) &= \mathcal{C}_\Delta^1\sub{\langle a, \mathcal{C}_\Delta^1\sub{\langle b, c\rangle}\rangle}\\
\end{align*}
Using the equivalence typing rule, we can relate these biased composite with the following term:
\[ \alpha_{a,b,c} = \Coh \Gamma {\arr {(a * b) * c} {} {a * (b * c)}} {\id_\Gamma}\]
which is the associator. Similarly for a term \(f : \arr x \star y\), unitors can be form over the disc context \(D^1\) using the equivalence rule:
\begin{align*}
  \lambda_f &= \Coh {D^1} {\arr {\id(d_0^-) * d_1} {} {d_1}} {\{f\}}\\
  \rho_f &= \Coh {D^1}  {\arr {d_1 * \id(d_0^-)} {} {d_1}} {\{f\}}
\end{align*}
The remainder of the operations for a 2-category can be defined similarly, as each displays the equivalence of two terms built over a pasting diagram. We observe that both the unitors and associator (as well as any coherence typed with the equivalence rule) are trivially invertible.

\subsection{Suspension}
\label{sec:suspension}

To end this section, we describe the meta-operation of \emph{suspension}, as described by \citeauthor{benjamin2020type}~\cite{benjamin2020type}. Suspension takes any piece of syntax as input and produces one with a dimension one higher. It can be used as an aid to defining operations in \Catt, but will also form a key part of the formal development of the constructions described in \cref{sec:operations-catt}.

Suspension is inspired by the identically named operation on topological spaces. Given a topological space \(X\), its suspension \(\Sigma X\) is formed by quotienting the space \(X \times [0,1]\) by the relation that identifies all points of the form \((x,0)\) for \(x \in X\) and identifies points \((x,1)\) for \(x \in X\).

The suspension on a space \(X\) can be alternatively viewed as the space containing two distinguished points \(N\) and \(S\), and a path from \(N\) to \(S\) for each point \(x \in X\). The names \(N\) and \(S\) stand for north and south, as the suspension of a circle can be visualised as a globe, with \(N\) and \(S\) being the north and south pole and each of the paths between them being a meridian.

A similar operation can be applied to globular sets. Given a globular set \(G\), its suspension \(\Sigma G\) is obtained by shifting the dimension of every \(n\)-cell up by one (making it into an \((n+1)\)-cell), adding two new \(0\)-cells \(N\) and \(S\), and letting the source of every \(1\)-cell be \(N\) and the target be \(S\). The globularity conditions for this construction can be quickly verified.

This construction extends to all computads~\cite{benjamin2024duamity}, and can be defined in \Catt by mutually defining the operation on contexts, types, terms, and substitutions.

\begin{definition}
  For a contexts \(\Gamma \in \Ctx\), types \(A \in \Type_\Gamma\), terms \(t \in \Term_\Gamma\), and substitutions \(\sigma : \Delta \to \Gamma\), we define their \emph{suspensions} \(\Sigma(\Gamma) \in \Ctx\), \(\Sigma(A) \in \Type_{\Sigma(\Gamma)}\), \(\Sigma(t)\in \Term_{\Sigma(\Gamma)}\), and \(\Sigma(\sigma) : \Sigma(\Delta) \to \Sigma(\Gamma)\) by mutual recursion.
  \begin{align*}
    \Sigma (\emptyset) &= (N : \star), (S : \star)
    &\Sigma (\Gamma, (x : A)) &= \Sigma \Gamma, (x : \Sigma A)\\
    \Sigma (\star) &= \arr N \star S
    &\Sigma (\arr s A t) &= \arr {\Sigma s} {\Sigma A} {\Sigma t}\\
    \Sigma(\langle \rangle) &= \langle N, S \rangle
    &\Sigma(\langle \sigma, x \rangle) &= \langle \Sigma(\sigma), \Sigma(t) \rangle\\
    \Sigma (x) &= x
    &\Sigma (\Coh \Delta A \sigma) &= \Coh {\Sigma(\Delta)} {\Sigma(A)} {\Sigma(\sigma)}
  \end{align*}
where \(x\) is a variable of \(\Gamma\).
\end{definition}

The dimension shift of suspension is driven by the cases for types, especially the case for the base type \(\star\), which returns a type of dimension \(1\), namely \(\arr N \star S\), using the two new variables \(N\) and \(S\). We note the suspension of any Ps-context is also a Ps-context, and in general the suspension of any piece of well-formed \Catt syntax can be well-typed. These results are given in \cite[Section~3.2]{benjamin2020type}, but will be proved in \cref{sec:ruleset} in more generality.

We can now investigate the action of suspension on the operations we have already defined. Take the context:
\[ (x : \star), (y : \star), (f : \arr x \star y), (z : \star), (g : \arr y \star z) \]
used in \cref{sec:basic-constructions} to generate 1-composition. Applying suspension to this context gives:
\[
  \begin{tikzcd}
    N && S
    \arrow[""{name=0, anchor=center, inner sep=0}, "x"', curve={height=24pt}, from=1-1, to=1-3]
    \arrow[""{name=1, anchor=center, inner sep=0}, "z", curve={height=-24pt}, from=1-1, to=1-3]
    \arrow[""{name=2, anchor=center, inner sep=0}, "y"{description}, from=1-1, to=1-3]
    \arrow["f", shorten <=3pt, shorten >=3pt, Rightarrow, from=0, to=2]
    \arrow["g", shorten <=3pt, shorten >=3pt, Rightarrow, from=2, to=1]
  \end{tikzcd}
\]
the context used to generate vertical 2-composition. Furthermore, applying suspension directly to 1-composition operation forms the vertical 2-composition operation.

The suspension of each disc context \(D^n\) is (up to \(\alpha\)-renaming) \(D^{n+1}\). It can be checked that applying suspension to the identity operation for \(n\)-dimensional terms returns the identity operation for \((n+1)\)-dimensional terms. Repeating this logic, all identity operations can be obtained as iterated suspensions of the identity for \(0\)-cells. The following more general result about standard coherences holds:

\begin{proposition}
  The following syntactic equalities hold:
  \[\Sigma(\mathcal{C}_\Delta^n) = \mathcal{C}_{\Sigma(\Delta)}^{n+1}\qquad
    \Sigma(\mathcal{T}_\Delta^n) = \mathcal{T}_{\Sigma(\Delta)}^{n+1}\qquad
    \Sigma(\mathcal{U}_\Delta^n) = \mathcal{U}_{\Sigma(\Delta)}^{n+1}\]
  for all Ps-contexts \(\Delta\) and \(n \in \mathbb{N}\).
\end{proposition}

The proof of these results is delayed to \cref{sec:operations-catt}, where we will have more tools for dealing with theses constructions.



\chapter{A formalised presentation of \Catt with equality}
\label{cha:gener-pres-catt}

The main purpose of this chapter will be to define the family of type theories \Cattr, which extend the base type theory \Catt with a specified set \(\mathcal{R}\) of equality rules. These equality rules equate various terms of the theory, which unifies the corresponding operations in the models of these theories, allowing us to generate type theories that model semistrict categories in \cref{cha:cattstrict}, categories where some but not all structure is strictified.

This chapter will also introduce the Agda\todo{citation} formalisation which accompanies this thesis, which compiles with Agda v2.6.4 and standard library v2.0. The formalisation implements the syntax and typing judgements of \Cattr, and contains proofs of most results in this chapter and \cref{sec:operations-catt}. By formalising \Cattr, instead of the more specific type theories \Cattsu and \Cattsua introduced in \cref{sec:cattsu,sec:cattsua}, the formalisation of many results can be applied to both type theories. This also allows these results to be applied to any future type theories that fit into this family.

\section{Extended substitution}
\label{sec:extend-subst}

\Cattr uses the same syntax as \Catt with one exception. In \Cattr we make a natural generalisation to substitutions, which will allow more operations to be defined for working with the suspension operation introduced in \cref{sec:suspension}. Unfortunately, the full utility of this generalisation will not be realised until \cref{sec:structured-terms}, but we choose to introduce it here as it forms a core part of the syntax, and requires very little modification to the rules of the type theory.

We recall that the suspension operation \(\Sigma\) acts on contexts, substitutions, types, and terms. Given a substitution \(\sigma : \Delta \to \Gamma\), its substitution \(\Sigma(\sigma)\) has domain \(\Sigma(\Delta)\) and codomain \(\Sigma(\Gamma)\). When we define trees and tree labellings in \cref{sec:operations-catt}, which will be used to define the insertion operation in \cref{sec:insertion}, we will need to be able to define substitutions from suspended contexts to arbitrary contexts. More generally, we would like to be able to describe substitutions of the form:
\[ \Sigma^n(\Delta) \to \Gamma\]
where \(\Sigma^n(\Delta)\) is the operation that applies suspension \(n\) times to \(\Delta\).

Consider the data contained in a substitution \(\tau : \Sigma(\Delta) \to \Gamma\). There are two terms \(N \sub \tau\) and \(S \sub \tau\) of type \(\star\), and then a term for each variable of \(\Delta\). Temporarily ignoring the typing conditions for substitutions, we see that the data is equivalent to a substitution from \(\Delta\) to \(\Gamma\) and two additional terms.

If we now consider a substitution \(\tau : \Sigma(\Sigma(\Delta)) \to \Gamma\), we notice that there is a term in \(\Gamma\) for each variable of \(\Delta\), as well as two terms \(s = N \sub \tau\) and \(t = S \sub \tau\) for the outer suspension and terms \(u = N' \sub \tau\) and \(v = S' \sub \tau\) for the inner suspension. As before, the terms \(s\) and \(t\) should have type \(\star\), but the terms \(u\) and \(v\) should have type \(\arr s \star t\). We note that this is the exact condition needed for \(\arr u {\arr s \star t} v\) to be a well-formed type. This motivates the notion of an \emph{extended substitution}, which is obtained by equipping a substitution with a type.

We have not yet determined the typing conditions required on the substitution part of these extended substitutions. We return to the example of a substitution \(\tau : \Sigma^2(\Delta) \to \Gamma\), and suppose that \(\Delta\) has a variable \(x\) of type \(\star\). In \(\Sigma^2(\Delta)\), \(x\) has the type \(\arr {N'} {\arr N \star S} {S'}\), and so \(x\) should be sent to a term of type \(\arr u {\arr s \star t} v\), the type portion of the extended substitution. In a substitution \(\sigma : \Delta \to \Gamma\), \(x\) would be sent to a term of type \(\star \sub \sigma\), which suggests that \(\star \sub \sigma\) should be redefined to send \(\star\) to the type part of the extended substitution.

This one change to the application of substitution to types is sufficient to form the generalisation to substitutions that was required. An extended substitutions \(\sigma : \Delta \to \Gamma\) then has the following intuition: The substitution part specifies where each variable in \(\Delta\) should be sent, and the type part specifies where the base type \(\star\) should be sent. The other cases for the application of substitution extend this to all terms, types, and (extended) substitutions as before. The extended substitution \(\sigma\) then represents a standard substitution \(\Sigma^n(\Delta)\) to \(\Gamma\), where \(n\) is the dimension of the type part of \(\sigma\). Hence, a regular substitution can be recovered as an extended substitution with type part \(\star\).

We modify the syntax of \Catt as follows, and will refer to these extended substitutions simply as substitutions, as extended substitutions are a direct generalisation of substitutions, and the notion of substitution is still recoverable by setting the type part to \(\star\):
\begin{itemize}
\item Substitutions will now be fibred over a type of their codomain context, which we will write \(\sigma : \arr \Delta A \Gamma\) where \(A \in \Type_\Gamma\). We note that this allows us to specify that \(\sigma\) is a regular substitutions by writing \(\sigma : \arr \Delta \star \Gamma\).
\item The constructor \(\langle\rangle\) is removed, and is replaced by the constructor \(\langle A \rangle : \arr \emptyset A \Gamma\), where \(A \in \Type_\Gamma\). Adding a term to a substitution preserves the type of the substiution. As before we may write a substitution \(\langle \langle \langle A \rangle, s \rangle, t \rangle\) as \(\langle A , s, t\rangle\). We let \(\FV(\langle A \rangle) = \FV(A)\).
\item An operation \(\ty(\sigma)\) is introduced that returns the type portion of a substitution. For \(\sigma : \arr \Delta A \Gamma\), we have \(\ty(\sigma) = A\).
\item Coherences \(\Coh \Delta A \sigma \in \Term_\Gamma\) are restricted so that \(\sigma\) is a regular substitution. In other words \(\ty(\sigma)\) must be \(\star\) for \(\sigma\) to appear in a substitution. While this condition could be dropped, it is convenient to keep the same operations as \Catt.
\end{itemize}

To witness the equivalence of extended substitutions \(\Delta \to \Gamma\) and regular substitutions \(\Sigma^n(\Delta) \to \Gamma\), we introduce new operations.

\begin{definition}
  For a substitution \(\sigma : \arr {\Delta} {\arr s A t} \Gamma\), we define its \emph{unrestriction}:
  \[\unrestrict\sigma : \arr {\Sigma(\Delta)} A \Gamma\]
  by induction on the length of \(\Delta\):
  \begin{align*}
    \unrestrict \langle \arr s A t \rangle &= \langle A, s, t \rangle\\
    \unrestrict \langle \sigma' , u \rangle &= \langle \unrestrict \sigma' , u \rangle
  \end{align*}
  The unrestrict operation simply moves two terms from the type part of the substitution into the main body of the substitution.
\end{definition}

To define the second operation, we need to first specify the changes to application of substitution:
\begin{itemize}
\item The composition of substitutions takes substitutions \(\sigma : \arr \Theta A \Delta\) and \(\tau : \arr \Delta B \Gamma\) to a substitution \(\sigma \bullet \tau : \arr \Theta {A \sub \tau} \Gamma\).
\item For a substitution \(\sigma : \arr \Delta A \Gamma\), we define \(\star \sub{\sigma} = A\).
\item As the substitution in a coherence must have type \(\star\), we define the application of an extended substitution \(\tau : \arr \Delta {\arr s A t} \Gamma\) to a coherence as:
  \[ \Coh \Theta A \sigma \sub \tau = \Coh {\Sigma(\Theta)} {\Sigma(A)} {\Sigma(\sigma)} \sub {\unrestrict \tau}\]
  The case for applying a regular substitution to a coherence remains unchanged.
\end{itemize}

We can now define an inverse to the unrestriction operation.

\begin{definition}
  For a substitution \(\sigma : \arr {\Sigma(\Delta)} A \Gamma\), its \emph{restriction}
  \[ \restrict \sigma : \arr \Delta {\arr {N \sub \sigma} A {S \sub \sigma}} \Gamma \]
  is defined by induction on the length of \(\Delta\):
  \begin{align*}
    \restrict \langle A, s, t \rangle &= \langle \arr s A t \rangle\\
    \restrict \langle \sigma', u \rangle &= \langle \restrict \sigma', u \rangle
  \end{align*}
  Inversely to the unrestrict operation, the restrict operation moves two terms into the type part of the substitution.
\end{definition}

As restriction and unrestriction cancel eachother, the suspension of the substitution \(\sigma : \arr \Delta \star \Gamma\) can be factored into \((\unrestrict \circ (\restrict \circ \Sigma)) (\sigma)\). We observe that the second part of this composition, \(\restrict \circ \Sigma\), is the operation that simply applies the suspension to each term in the substitution as well as the type of the substitution. This motivates the final definition of this section.

\begin{definition}
  Let the \emph{restricted suspension} of a substitution \(\sigma : \arr \Delta A \Gamma\) be a substitution
  \[\Sigma'(\sigma) : \arr \Delta {\Sigma(A)} {\Sigma(\Gamma)}\]
  defined inductively by the equations:
  \begin{align*}
    \Sigma'(\langle A \rangle) &= \langle \Sigma(A)\rangle \\
    \Sigma'(\langle \sigma' , t \rangle) &= \langle \Sigma'(\sigma'), \Sigma(t) \rangle
  \end{align*}
  The suspension of a substitution \(\tau : \arr \Delta \star \Gamma\) can be defined by \(\Sigma(\tau) = \unrestrict\Sigma'(\tau)\).
\end{definition}
For the rest of the thesis and the formalisation, the suspension on a substitution is defined as the composition of unrestriction and restricted suspension.

\section{\Cattr: \Catt with equality}
\label{sec:catt-with-equality}

This section will define the type theory \Cattr, a variation of \Catt with specified equality rules. This section, in addition to the following sections in this chapter, will be used to motivate certain choices in the formalisation. All the preliminary definitions as well as syntax, typing, and equality rules are assembled in \cref{fig:cattr}.

\subsection{Syntax}
\label{sec:syntax}

The syntax of \Cattr will be identical to \Catt with the exceptions specified in \cref{sec:extend-subst}. This creates a dependence chain of needing to define the base syntax before suspension can be defined, and needing to define suspension before application of substitution can be defined. In the formalisation these are defined in the following files:
\begin{itemize}
\item The core syntax is defined in \module{Catt.Syntax.Base}.
\item Suspension is defined in \module{Catt.Suspension}.
\item Other syntactic operations are defined in \module{Catt.Syntax}, which re-exports the core syntax.
\end{itemize}
To avoid any issues with alpha equivalence, especially as we have terms that contain contexts, we work with de Brujin indices throughout the formalisation. This means that a context is simply a vector of types, a fixed length list, which we give a nicer syntax to. Variables are then simply bounded natural numbers, represented by the sets \(\mathsf{Fin}_n\), where \(\mathsf{Fin}_n\) is the set \(\{0,\dots,n-1\}\). Given a context \(A , B , C\), the variables over this context are simply \(\mathsf{var\ 0}\), which has type \(C\), \(\mathsf{var\ 1}\), which has type \(B\), and \(\mathsf{var\ 2}\), with type \(A\). We note that \(3\) is not in \(\mathsf{Fin}_3\), and so \(\mathsf{var\ 3}\) is not a term of this context. Hence, we do not need to deal with unknown variables when applying substitutions. We will still make use of variable names in this text to aid readability, and will ignore any potential problems that could arise from this, knowing that the results are formalised in a setting where they do not appear.

The formalisation also differs from the presentation in the texts by the way that the various notions of syntax are fibred. We fibre contexts by a natural number representing their length, and then fibre terms, types, and substitutions over these lengths instead of fibring them over the contexts. We then get the following 4 syntactic classes defined as mutually inductive families, where \(\mathcal{U}\) is a type universe:
\[ \func{Catt.Syntax.Base}{94}{\Ctx} : \mathbb{N} \to \mathcal{U} \quad \func{Catt.Syntax.Base}{113}\Type : \mathbb{N} \to \mathcal{U} \quad \func{Catt.Syntax.Base}{131}\Term : \mathbb{N} \to \mathcal{U} \quad \func{Catt.Syntax.Base}{149}\Sub : (n\ m : \mathbb{N}) \to \Type_m \to \mathcal{U}\]
This decision was made purely for convenience, by fibring over natural numbers instead of contexts, we sometimes avoid the need for providing more explicit arguments to syntactic constructions. It comes with drawback that the context must be provided for certain operations, such as the support of a piece of syntax, or the dimension of a term.

One place an explicit argument can be avoided is when defining the weakening of a piece of syntax, an operation witnessing that for a piece of syntax living in a context \(\Gamma\), there is a copy living in \(\Gamma , A\) for any \(A\). These operations are defined in \module{Catt.Syntax} and take the following form, where we reuse the name \(\wk\) here as an abuse of notation:
\[ \func{Catt.Syntax}{117}{\wk} : \Term_{\Gamma} \to \Term_{\Gamma, A}\quad\func{Catt.Syntax}{143}{\wk} : \Type_{\Gamma} \to \Type_{\Gamma, A}\quad \func{Catt.Syntax}{169}{\wk} : (\arr \Gamma B \Delta) \to (\arr {\Gamma} {\wk(B)} {\Delta, A}) \]
If terms are fibred over contexts then this type \(A\) must often be specified, though with the fibring over context length this is no longer necessary. When using de Brujin indices, this operation is no longer the identity on terms, as each variable must be incremented due to the index in a variable counting from the end of the context. One might ask why de Brujin levels (which index from the start of the context) were not used instead, but this would not solve our problem as \(\mathsf{Fin}_n\) is not a sub type of \(\mathsf{Fin}_{n+1}\) in Agda. Furthermore, using de Brujin levels would cause the substitution application introduced in \cref{sec:syntax-catt} (and expanded in \cref{sec:extend-subst}) to compute poorly, due to the way substitutions are defined. The definition of weakening is given in \cref{fig:wk}.

Weakening can be used to give a short inductive definition of the identity substitution, a substitution \(\id_\Gamma : \Gamma \to \Gamma\) which sends every variable to itself. On the inductive case \(\id_{\Gamma, (x : A)}\), it clear that the variable \(x\) should be sent to \(x\), but the constructor for substitutions also requires a substitution \(\Gamma \to \Gamma, (x : A)\). This can be obtained by weakening a recursive call to the identity on \(\Gamma\). Similarly, an inclusion \(\Gamma \to \Gamma, (x : A)\) can be defined as \(\wk(\id_\Gamma)\), and applying this substitution is the same operation as weakening.

To begin proving syntactic properties of \Cattr, we need a notion of syntactic equality. This will be written \(\Gamma \equiv \Delta\) for contexts \(\Gamma\) and \(\Delta\), and similarly for terms \(s\) and \(t\), types \(A\) and \(B\), and substitutions \(\sigma\) and \(\tau\). It is given by alpha equivalence, and so we would hope that the formalisation could leverage the use of de Brujin indices to use the in-built equality type for syntactic equality. This is too restrictive however, there will be many times where we want to compare two terms of differing context length (in practice this context length will be propositionally equal, instead of definitionally equal).

Therefore, four syntactic equality relations are defined mutually inductively on the constructors of each piece of syntax in \module{Catt.Syntax.Properties}. These definitions can easily be heterogeneous, allowing two terms \(s : \Term_n\) and \(t : \Term_m\) to be compared. Unfortunately, using these comes at the cost of large amounts of boilerplate, as these inductively defined equalities do not come equipped with the J-rule, and so it must be manually proved that each operation respects syntactic equality. An example of such a function is \func{Catt.Syntax.Properties}{6102}{\textsf{wk-tm-\(\simeq\)}}, which states that the weakenings of two syntactically equal terms are syntactically equal.

\module{Catt.Syntax.Properties} contains many of the basic properties about the syntax of \Cattr, including:
\begin{itemize}
\item Syntactic equality is decidable.
\item Syntactic equality is propositional, there is at most one proof of \(s \equiv t\).
\item Functoriality of suspension.
\item Interaction of weakening with substitution application.
\end{itemize}\todo{Worth giving links?}
It also contains the following proposition.

\begin{proposition}
  \label{prop:categorical}
  Application of substitution is associative and unital with respect to the identity substitution. More precisely, given substitutions \(\sigma : \arr \Theta A \Delta\) and \(\tau : \arr \Delta B \Gamma\), the following equalities hold:
  \begin{mathpar}
    A \sub \sigma \sub \tau \equiv A \sub {\sigma \bullet \tau} \and A \sub \id_\Theta \equiv A\\
    t \sub \sigma \sub \tau \equiv t \sub {\sigma \bullet \tau} \and t \sub \id_\Theta \equiv t\\
    (\mu \bullet \sigma) \bullet \tau \equiv \mu \bullet (\sigma \bullet \tau) \and \mu \bullet \id_\Theta \equiv \mu \and \id_\Xi \bullet \mu \equiv \mu
  \end{mathpar}
  for types \(A \in \Type_\Theta\), terms \(t \in \Term_\Theta\), and substitutions \(\mu : \arr \Xi C \Theta\).
\end{proposition}

\begin{proof}
  The last equation is a simple induction on \(\mu\) (and the context \(\Xi\)). Both the unitality equations and associativity equations, as with the vast majority of syntactic proofs, are given by mutual induction on types, terms, and substitutions. The only difficult case is:
  \[ \Coh \Theta C \mu \sub \sigma \sub \tau \equiv t \sub {\sigma \bullet \tau} \]
  where the type part of \(\sigma: \arr \Theta A \Delta\) or \(\tau : \arr \Delta B \Gamma\) is not \(\star\). First suppose \(B = \arr s {B'} t\) but \(A = \star\):
  \begin{align*}
    \Coh \Theta C \mu \sub \sigma \sub \tau
    &\equiv \Coh \Theta C {\mu \bullet \sigma} \sub \tau\\
    &\equiv \Coh {\Sigma(\Theta)} {\Sigma(C)} {\Sigma(\mu \bullet \sigma)} \sub {\unrestrict \tau}\\
    &\equiv \Coh {\Sigma(\Theta)} {\Sigma(C)} {\Sigma(\mu) \bullet \Sigma(\sigma)} \sub {\unrestrict \tau}\\
    &\equiv \Coh {\Sigma(\Theta)} {\Sigma(C)} {\Sigma(\mu)} \sub {\Sigma(\sigma) \bullet \unrestrict \tau}\\
    &\equiv \Coh {\Sigma(\Theta)} {\Sigma(C)} {\Sigma(\mu)} \sub {\unrestrict (\sigma \bullet \tau)}\\
    &\equiv \Coh {\Theta} {C} {\mu} \sub {\sigma \bullet \tau}
  \end{align*}
  where the second to last line is given by property
  \[\unrestrict (\sigma \bullet \tau) \equiv \Sigma(\sigma) \bullet \unrestrict \tau\]
  which holds for all \(\sigma : \arr \Theta \star \Delta\) and is proven in \func{Catt.Syntax.Properties}{17858}{\textsf{\(\downarrow\)-comp}}, and the line before is given by the inductive hypothesis.

  If instead we had \(A = \arr s {A'} t\), then:
  \begin{align*}
    \Coh \Theta C \mu \sub \sigma \sub \tau
    &\equiv \Coh {\Sigma(\Theta)} {\Sigma(C)} {\Sigma(\mu)} \sub {\unrestrict \sigma} \sub \tau\\
    &\equiv \Coh {\Sigma(\Theta)} {\Sigma(C)} {\Sigma(\mu)} \sub {\unrestrict \sigma \bullet \tau}\\
    &\equiv \Coh {\Sigma(\Theta)} {\Sigma(C)} {\Sigma(\mu)} \sub {\unrestrict (\sigma \bullet \tau)}\\
    &\equiv \Coh \Theta C \mu \sub {\sigma \bullet \tau}
  \end{align*}
  where we use the inductive hypothesis after applying the equality
  \[ \unrestrict (\sigma \bullet \tau) \equiv \unrestrict \sigma \bullet \tau \]
  which holds for all \(\sigma : \arr \Theta {\arr s {A'} t} \Delta\) by \func{Catt.Syntax.Properties}{18741}{\textsf{\(\downarrow\)-comp-higher}}.
\end{proof}

This proposition proves that the syntax of \Cattr forms a category, which we will not name as we will work instead with the subcategory containing well-typed contexts and substitutions, introduced in the following sections.

\paragraph{Discs}
We finish our discussion of the syntax of \Cattr by giving formal definitions of disc and sphere contexts, some constructions on these and their properties. This will allow these to be used as examples in following sections, and preempts the use of discs in the first two equality rules that we will introduce, disc removal and endo-coherence removal.

We begin with the defintions of discs, spheres, and sphere types, which can be found in \module{Catt.Discs} as \func{Catt.Discs}{331}{Disc}, \func{Catt.Discs}{366}{Sphere}, and \func{Catt.Discs}{202}{sphere-type}. We write the sphere type as \(U^n\), which is intentionally close to the notation of the standard type \(\mathcal{U}_\Delta^n\), as it will turn out that these coincide.

\begin{definition}
  We mutually define the disc contexts \(D^n\), sphere contexts \(S^n\), and sphere type \(U^n \in \Type_{S^n}\).
  \begin{mathpar}
    D^n = S^n , (d_n^- : U^n) \and
    S^0 = \emptyset \and
    S^{n+1} = D^n , (d_n^+ : \wk(U^n)) \\
    U^0 = \star \and
    U^{n+1} = \arr {d_n^-} {\wk(\wk(U^{n+1}))} {d_n^+}
  \end{mathpar}
  We will sometimes refer to the last variable of \(D^n\) as \(d_n\) instead of \(d_n^-\), given that there is no \(d_n^+\) in the context.
\end{definition}

We also characterise the substitutions from a sphere or disc. These are given by \func{Catt.Discs}{586}{sub-from-sphere} and \func{Catt.Discs}{494}{sub-from-disc} in the formalisation.

\begin{definition}
  Let \(A : \Type_\Gamma\) be a type and suppose \(n = \dim(A)\). Define the substitution \(\{A\} : S^n \to \Gamma\) inductively by:
  \[ \{\star\} = \langle \rangle \qquad \{\arr s A t\} = \langle \{ A \}, s, t \rangle\]
  Further, given a term \(t : \Term_\Gamma\), define the substitution \(\{A,t\} : D^n \to \Gamma\) by \(\{A, t\} = \langle \{A\}, t \rangle\).
\end{definition}

In \module{Catt.Discs.Properties}, various facts about these constructions are proved which we list below.

\begin{lemma}
  \label{lem:disc-prop}
  The following hold:
  \begin{itemize}
  \item \(\dim(D^n) = \dim(U^n) = n\) and \(\dim(S^n) = \max(n - 1, 0)\).
  \item \(\Sigma(D^n) \equiv D^{n+1}\), \(\Sigma(S^n) \equiv S^{n+1}\), and \(\Sigma(U^n) \equiv U^{n+1}\).
  \item \(\{\wk(A)\} \equiv \wk(\{A\})\) and \(\{\wk(A), \wk(t)\} \equiv \wk(\{A,t\})\).
  \item \(\{\Sigma(A)\} \equiv \Sigma(\{A\})\) and \(\{\Sigma(A),\Sigma(t)\} \equiv \Sigma(\{A,t\})\).
  \item \(\{A \sub \sigma\} \equiv \{A\} \bullet \sigma\) and \(\{A \sub \sigma,t \sub \sigma\} \equiv \{A,t\}\bullet \sigma\).
  \item \(U^n \sub{\{A\}} \equiv A\) and hence \(\wk(U^n)\sub{\{A,t\}} \equiv A\).
  \item For \(\tau : S^n \to \Gamma\), \(\tau \equiv \{U^n \sub \tau\}\).
  \item For \(\tau : D^n \to \Gamma\), \(\tau \equiv \{\wk(U^n) \sub \tau, d_n \sub \tau\}\).
  \end{itemize}
  for all \(n \in \mathbb{N}\) and appropriate \(A\), \(t\), and \(\sigma\).
\end{lemma}

The last two statements finish the characterisation of substitutions from spheres and discs as all such substitutions are of the form \(\{A\}\) or \(\{A,t\}\) respectively.

In \module{Catt.Discs.Pasting}, it is shown that \(D^n\) is a ps-context for each \(n\). Therefore, as in \cref{sec:basic-constructions}, the identity on a term \(t\) of type \(A\) can be defined as:
\[ \id(A,t) = \Coh {D^n} {\arr {d_n} {\wk(U^n)} {d_n}} {\{A,t\}} \]
Many properties of identity terms can be easily derived from \cref{lem:disc-prop}.


\subsection{Typing and equality}
\label{sec:typing-equality}

The typing rules for \Cattr differ from those from \Catt in three key ways:
\begin{enumerate}
\item The fixed conditions on the support of the types in a coherence have been replaced by a set of operations \(\mathcal{O}\). Instead of having two typing rules for coherences, one for equivalences and one for composites, we simply have one typing rule and specify that a coherence \(\Coh \Delta {\arr s A t} \sigma\) can be well-typed when:
  \[ (\Delta, \supp(s), \supp(t)) \in \mathcal{O} \]
This will be further motivated and explained in \cref{sec:support}.
\item A definitional equality is added to the system, generated by a set of equality rules \(\mathcal{R}\) which specifies pairs of terms which should be equated. The equality take the form of three new judgements:
  \begin{alignat*}{2}
  &\Gamma \vdash A = B&\qquad&\text{\(A, B \in \Type_\Gamma\) are equal in context \(\Gamma\).}\\
  &\Gamma \vdash s = t &&\text{\(s, t \in \Term_\Gamma\) are equal in context \(\Gamma\).}\\
  &\Gamma \vdash \tau = \sigma &&\text{\(\tau : \Theta \to \Gamma\) and \(\sigma : \Delta \to \Gamma\) are equal.}
  \end{alignat*}
  These judgements are all mutually defined (and are in fact mutually defined with the typing judgements). By defining the equality generically over a list
\item The typing rules are adjusted to account for this definitional equality, via the addition of a conversion rule.
\end{enumerate}

The conversion rule is the only additional typing rule that must be added to \Cattr, and takes the following form:
\begin{mathpar}
  \inferrule {\Gamma \vdash s : A \and \Gamma \vdash A = B}{\Gamma \vdash s : B}\textsc{conv}
\end{mathpar}
allowing the type of any term to vary up to the definitional equality. This rule accounts for all of the semistrict behaviour in the theories we introduce in \cref{cha:cattstrict}.

By adding this rule, and allowing the type of a term to vary up to definitional equality instead of syntactic equality, we allow more terms in the theory to become composable. Suppose we have terms \(f : x \to y\) and \(g : y' \to z\). In \Catt, we would not be able to form the vertical composition of these terms, as \(y\) and \(y'\) are not the same. If we now suppose that \(\Gamma \vdash y = y'\), then it will follow that \(\Gamma \vdash x \to y = x \to y'\), and so using the conversion rule we get:
\begin{mathpar}
  \inferrule{\inferrule*{\Gamma \vdash f : x \to y \and \inferrule*{\Gamma \vdash y = y'}{\Gamma \vdash x \to y = x \to y'}}{\Gamma \vdash f : x \to y'} \and \Gamma \vdash g : y' \to z}{\Gamma \vdash f * g : x \to z}
\end{mathpar}
We remark that adding definitional equality does not simply quotient the terms of the theory, but also allows new terms to be well-typed as above.

The definitional equality judgements are given by the rules in \cref{fig:equality} and appear in the formalisation along side the typing rules in \module{Catt.Typing}. These are generated by the set of \emph{equality rules} \(\mathcal{R}\), which is a set of triples of the form \((\Gamma, s, t)\) where \(\Gamma\) is a context and \(s,t \in \Term_\Gamma\). The key inference rule for equality is then:
\begin{mathpar}
  \inferrule{\Gamma \vdash s : A \and (\Gamma,s,t) \in \mathcal{R}}{\Gamma \vdash s = t}\textsc{rule}
\end{mathpar}
which says that if a triple \((\Gamma, s, t)\) is in \(\mathcal{R}\), then \(\Gamma \vdash s = t\) if \(s\) is well-typed in \(\Gamma\). The typing prerequisite forces the definitions of equality and typing to be mutually defined, and ensures that we only apply our equality rules to well-behaved terms.

We note the asymmetry of this rule, in that only the left hand side is required to be well-typed. Every rule introduced in this thesis will take the form of some reduction from the left hand side to the right hand side, and we will be able to prove that typing for the right hand side follows from typing for the left hand side for every equality we consider. The converse may not hold in general, necessitating the condition on the left hand side. This is similar to \(\beta\)-reduction in the \(\lambda\)-calculus, where an untyped term can reduce to a simply typed term.

The remainder of the inference rules for equality simply close under each constructor, reflexivity, symmetry, and transitivity. It is only necessary to give symmetry and transitivity rules for terms, and a reflexivity rule for variables, with these properties following for the other judgements by simple induction.

\begin{lemma}
  The definitional equality relations on terms, types, and substitutions are equivalence relations, for any \(\mathcal{R}\).
\end{lemma}
\begin{proof}
  Proofs of these are found in \module{Catt.Typing.Properties.Base}.
\end{proof}

There is not much more that can be proved about the definitional equality at this point without knowing more about the rule set \(\mathcal{R}\). In \cref{sec:ruleset}, certain conditions will be imposed on the set of equality rules, that will allow further lemmas to be proved in large generality.

\paragraph{Disc removal}

We now give our first example of an equality rule, \emph{disc removal}. Disc removal removes unary composites, replacing them with the underlying term. We recall that for every \(n\), there exists the \(n\)-dimensional disc context \(D^n\), and that given a term \(t \in \Term_\Gamma\) and \(n\)-dimensional type \(A \in \Type_\Gamma\), there exists a substitution \(\{A,t\} : D^n \to \Gamma\). The unary composite of a term \(t\) of type \(A\) of dimension \(n\) is then the coherence:
\[\Coh {D^n} {\wk(U^n)} {\{A,t\}}\]
Disc removal equates this with the term \(t\), making the following rule inferable:
\begin{mathpar}
  \inferrule{\Gamma \vdash t : A \\ \Gamma \vdash A}{\Gamma \vdash \Coh {D^n} {\wk(U^n)} {\{A,t\}} = t}\textsc{dr}
\end{mathpar}
with the removal of the disc coherence giving the name to this equality rule.

Assembling disc removal into a rule set \(\mathcal{R}\) is simple, as it is possible to simply give a syntactic condition with no need to refer to typing.

\begin{definition}
  The disc removal rule set, \dr, is the set consisting of the triples:
  \[ (\Gamma, \Coh {D^n} {\wk(U^n)} {\{A,t\}}, t) \]
  for each \(n \in \mathbb{N}\), context \(\Gamma\), type \(A : \Type_\Gamma\), and term \(t : \Term_\Gamma\).

  A set of rules \(\mathcal{R}\) \emph{contains disc removal} if \(\dr \subseteq \mathcal{R}\). Further we say that \(\mathcal{R}\) \emph{has disc removal} if the rule \textsc{dr} holds in the generated theory.
\end{definition}

The inference rule \textsc{dr} follows the \textsc{rule} and typing properties about discs which will be given in \cref{sec:ruleset}.

We draw attention to the typing premise of \textsc{rule}. If we know that the unary composite of a term \(t\) is well typed, then it follows that \(t\) itself must have been well-typed, but we cannot infer that the term \(\Coh {D^n} {\wk(U^n)} {\{A,t\}}\) is well-typed from \(t\) being well-typed. In particular, the well-formedness of \(t\) does not constrain \(A\) at all without knowing that the given type \(A\) is the type of \(t\). We must therefore include an additional typing premise if we want to avoid well-typed and untyped terms being equated.

\begin{figure}[!t]
  \centering
  \fbox{\begin{subfigure}{0.45\textwidth}
      \vspace{0.4pt}
    \begin{mathpar}
      \inferrule{ }{\star : \Type_\Gamma}
      \and
      \inferrule{x \in \Var(\Gamma)} {x : \Term_\Gamma}
      \and
      \inferrule{A : \Type_\Gamma}{\langle A \rangle : \emptyset \to \Gamma}
      \and
      \inferrule{ }{\emptyset : \Ctx}
      \and
      \inferrule{\Gamma : \Ctx \\ A : \Type_\Gamma}{\Gamma, (x : A) : \Ctx}
      \and
      \inferrule{\sigma : \arr \Delta A \Gamma \\ t : \Term_\Gamma \\ B : \Type_\Delta}{\langle \sigma , t \rangle : \arr {\Delta, (x : B)} A \Gamma}
      \and
      \inferrule{A : \Type_\Gamma \\ s : \Term_\Gamma \\ t : \Term_\Gamma} {\arr s A t : \Type_\Gamma}
      \and
      \inferrule{\\\\\Delta : \Ctx \\ A : \Type_\Delta \\ \sigma : \arr \Delta \star \Gamma}{\Coh \Delta A \sigma : \Term_\Gamma}
    \end{mathpar}
    \caption{Syntax}
  \end{subfigure}}
  \hfill
  \fbox{\begin{subfigure}{0.50\textwidth}
    \begin{mathpar}
      \inferrule{ }{\emptyset \vdash}
      \and
      \inferrule{\Gamma \vdash\\ \Gamma \vdash A}{\Gamma, (x : A) \vdash}
      \and
      \inferrule{ }{\Gamma \vdash \star}
      \and
      \inferrule{\Gamma \vdash s : A \\ \Gamma \vdash A \\ \Gamma \vdash t : A}{\Gamma \vdash \arr s A t}
      \and
      \inferrule{\Gamma \vdash A}{\Gamma \vdash \langle A \rangle : \emptyset}
      \and
      \inferrule{\Gamma \vdash \sigma : \Delta\\ \Gamma \vdash t : A\sub\sigma}{\Gamma \vdash \langle \sigma , t \rangle : \Delta, (x : A)}
      \and
      \inferrule{(x : A) \in \Gamma}{\Gamma \vdash x : A}
      \and
      \inferrule{\Gamma \vdash t : A\\ \Gamma \vdash A = B}{\Gamma \vdash t : B}\textsc{conv}
      \and
      \inferrule{\Delta \vdash_{\mathsf{ps}}\\ \Delta \vdash \arr s A t \\ \Gamma \vdash \sigma : \Delta\\(\Delta, \Supp(s), \Supp(t)) \in \mathcal{O}}{\Gamma \vdash \Coh \Delta {\arr s A t} \sigma : \arr {s \sub \sigma} {A \sub \sigma} {t \sub \sigma}}
    \end{mathpar}
    \caption{Typing}
  \end{subfigure}}

\vspace{7pt}
  \fbox{\begin{subfigure}{0.9852\textwidth}
    \begin{mathpar}
      \inferrule{\Gamma \vdash s : A \\ (\Gamma, s, t) \in \mathcal{R}}{\Gamma \vdash s = t}\textsc{rule} \and
      \inferrule{x \in \Var(\Gamma)}{\Gamma \vdash x = x} \and
      \inferrule{\Gamma \vdash s = t}{\Gamma \vdash t = s} \and
      \inferrule{\Gamma \vdash s = t \\ \Gamma \vdash t = u}{\Gamma \vdash s = u} \and
      \inferrule{\Delta \vdash A = B \\ \Gamma \vdash \sigma = \tau}{\Gamma \vdash \Coh \Delta A \sigma = \Coh \Delta B \tau} \and
      \inferrule{ }{\Gamma \vdash \star = \star} \and
      \inferrule{\Gamma \vdash s = s' \\ \Gamma \vdash t = t' \\ \Gamma \vdash A = A'}{\Gamma \vdash \arr s A t = \arr {s'} {A'} {t'}}\and
      \inferrule{\Gamma \vdash A = B}{\Gamma \vdash \langle A \rangle = \langle B \rangle}\and
      \inferrule{\Gamma \vdash \sigma = \tau \\ \Gamma \vdash s = t}{\Gamma \vdash \langle \sigma, s \rangle = \langle \tau, t \rangle}
    \end{mathpar}
    \caption{Equality}
    \label{fig:equality}
  \end{subfigure}}

\vspace{7pt}
\fbox{\begin{subfigure}{0.45\textwidth}
    \vspace{1pt}
    \begin{mathpar}
    \inferrule{ }{(x : \star) \vdash_{\mathsf{ps}} x : \star}
    \and
    \inferrule{\Gamma \vdash_{\mathsf{ps}} x : A}{\Gamma, (y : A), (f : \arr x A y)}
    \and
    \inferrule{\Gamma \vdash_{\mathsf{ps}} x : \arr s A t}{\Gamma \vdash_{\mathsf{ps}} t : A}
    \and
    \inferrule{\Gamma \vdash_{\mathsf{ps}} x : \star}{\Gamma \vdash_{\mathsf{ps}}}
  \end{mathpar}
    \caption{Ps-contexts}
  \end{subfigure}}
  \hfill
  \fbox{\begin{subfigure}{0.5\textwidth}
      \vspace{6pt}
    \begin{mathpar}
      \FV(\star) = \{\}
      \and
      \FV(\langle A \rangle) = \FV(A)
      \\
      \FV(x) = \{x\} \text{ for }x \in \Var
      \\
      \FV(\Coh \Delta A \sigma) = \FV(\sigma)
      \\
      \FV(\arr s A t) = \FV(s) \cup \FV(A) \cup \FV(t)
      \\
      \FV(\langle \sigma , t \rangle) = \FV(\sigma) \cup \FV(t)
    \end{mathpar}
    \caption{Free variables}
  \end{subfigure}}
  \caption{\Cattr: syntax, typing, and operations (continued below)}
  \label{fig:cattr}
\end{figure}

\begin{figure}
  \ContinuedFloat
  \fbox{\begin{subfigure}{1\textwidth}
    \begin{align*}
      \DC_\emptyset(\emptyset) &= \emptyset\\
      \DC_{\Gamma, x : A}(V) &= \begin{cases*}
        \DC_\Gamma(V)&if \(x \not\in V\)\\
        \{x\} \cup \DC_\Gamma(V \setminus \{x\} \cup \FV(A))&if \(x \in V\)\\
      \end{cases*}\\
      \Supp(t) &= \DC_\Gamma(\FV(t))\text{ for }t \in \Term_\Gamma\\
      \Supp(A) &= \DC_\Gamma(\FV(A))\text{ for }A \in \Type_\Gamma\\
      \Supp(\sigma) &= \DC_\Gamma(\FV(\sigma))\text{ for }\sigma : \arr {\Delta} A \Gamma
    \end{align*}
    \caption{Support}
  \end{subfigure}}

\vspace{7pt}
  \fbox{\begin{subfigure}{\textwidth}
    \begin{align*}
      x \sub \sigma &= t\text{ if }(x \mapsto t) \in \sigma\\
      \Coh \Theta A \tau \sub \sigma &=
                                       \begin{cases*}
                                         \Coh \Theta A {\tau \bullet \sigma}&if \(\dim(\ty(\sigma)) = 0\)\\
                                         \Coh {\Sigma(\Theta)} {\Sigma(A)} {\Sigma(\tau)} \sub {\unrestrict\sigma}&otherwise
                                       \end{cases*}
      \\
      \star \sub \sigma &= \ty(\sigma)\\
      (\arr s A t) \sub \sigma &= \arr {s \sub \sigma} {A \sub \sigma} {t \sub \sigma}\\
      \langle A \rangle \bullet \sigma &= \langle A \sub \sigma \rangle\\
      \langle \tau , t \rangle \bullet \sigma &= \langle \tau \bullet \sigma , t \sub \sigma \rangle
    \end{align*}
    \caption{Substitution application}
  \end{subfigure}}

\vspace{7pt}
\fbox{\begin{subfigure}{0.475\textwidth}
      \begin{align*}
        \Sigma (\emptyset) &= (N : \star), (S : \star)\\
        \Sigma (\Gamma, (x : A)) &= \Sigma \Gamma, (x : \Sigma A)\\
        \Sigma (\star) &= \arr N \star S\\
        \Sigma (\arr s A t) &= \arr {\Sigma s} {\Sigma A} {\Sigma t}\\
        \Sigma (x) &= x\\
        \Sigma (\Coh \Delta A \sigma) &= \Coh {\Sigma(\Delta)} {\Sigma(A)} {\Sigma(\sigma)}\\
        \Sigma(\sigma) &= \unrestrict(\Sigma'(\sigma))\\[7.25pt]
        \Sigma'(\langle A \rangle) &= \langle \Sigma(A) \rangle\\
        \Sigma'(\langle \sigma, x \rangle) &= \langle \Sigma'(\sigma), \Sigma(t) \rangle\\
        \unrestrict\langle \arr s A t \rangle &= \langle A , s , t \rangle\\
        \unrestrict\langle \sigma, t \rangle &= \langle \unrestrict \sigma, t \rangle
      \end{align*}
    \caption{Suspension}
  \end{subfigure}}
\hfill
\begin{subfigure}{0.49\textwidth}
  \fbox{\begin{subfigure}{1\textwidth}
      \begin{align*}
        \wk(\star) &= \star\\
        \wk(\arr s A t) &= \arr {\wk(s)} {\wk(A)} {\wk(t)}\\
        \wk(x) &= x\\
        \wk(\Coh \Delta A \sigma) &= \Coh \Delta A {\wk(\sigma)}\\
        \wk(\langle A \rangle) &= \langle \wk(A) \rangle\\
        \wk(\langle \sigma, t \rangle) &= \langle \wk(\sigma), \wk(t) \rangle
      \end{align*}
      \caption{Weakening}
      \label{fig:wk}
    \end{subfigure}}

  \vspace{7pt}
  \fbox{\begin{subfigure}{1\textwidth}
      \begin{align*}
        \id_\emptyset &= \langle \star \rangle\\
        \id_{\Gamma, (x : A)} &= \langle \wk(\id_\Gamma), x \rangle
      \end{align*}
      \caption{Identity substitution}
    \end{subfigure}}
\end{subfigure}
\caption{\Cattr: syntax, typing, and operations}
\end{figure}

\section{The set of operations \texorpdfstring{\(\mathcal{O}\)}{O}}
\label{sec:support}

In \cref{sec:typing-equality}, we introduced a set of operations \(\mathcal{O}\), which allows us to vary the operations available in the theory, much like the set \(\mathcal{R}\) allows us to vary the equality rules of the theory. The set \(\mathcal{O}\) replaces the conditions on the support of the type contained in a coherence, and consists of a set of triples of a context \(\Delta\), along with two sets \(x,y \subseteq \Var(\Delta)\). A certain type \(\arr s A t : \Type_\Delta\) is permitted to appear in a coherence exactly when \((\Delta , \supp(s), \supp(t))\) is an element of \(\mathcal{O}\).

There are two key advantages to setting up the theory this way.
\begin{itemize}
\item A clear separation is introduced in the metatheory and formalisation between properties that are specific to the support conditions in \Catt and those that are independent of the specific support conditions present.
\item The results in the following sections can be proven generically for different variants of \Catt.
\end{itemize}
In particular, the main utility we extract in this thesis is the ability to define groupoidal versions of the various semistrict theories we define in \cref{cha:cattstrict}. By letting \(\mathcal{O}\) consists of all possible triples, the support condition is effectively removed, producing a version of \Catt closer to Grothendieck's definition of \(\infty\)-groupoid (see \cref{sec:weak}).

\subsection{Operation sets}
\label{sec:operation-sets}

As previously mentioned, an operation set \(\mathcal{O}\) consists of a collection of triples of a context \(\Delta\) and two subsets of the variables of \(\Delta\).

We call a subset of the variables of a context a \emph{variable set}. In the formalisation, these variable sets are given as a list of booleans, one boolean for each variable of the context. These are given in \module{Catt.Support}, which also contains many basic properties and constructions on them, including unions of these sets, subset relations, and the free variables of each piece of syntax. The variable sets of \(\Delta\) form a lattice with top element \(\Var(\Delta)\) and bottom element \(\emptyset\).

We recall the function \(\DC\) on these variable sets, given by \func{Catt.Support}{2590}{DC} in the formalisation, which produces the downwards closure of a variable set. This admits the following properties:

\begin{proposition}
  \(\DC\) is an idempotent join-semilattice homomorphism. It preserves binary joins (unions), subset inclusions, and preserves the top and bottom element of the lattice.
\end{proposition}

We further define the application of a substitution to a variable set below.

\begin{definition}
  Given a variable set \(V\) of \(\Delta\) and (standard) substitution \(\sigma : \Delta \to \Gamma\), we define the application of \(\sigma\) to \(V\), written \(V \sub \sigma\) to be a variable set of \(\Gamma\) given by:
  \begin{align*}
    V \sub {\langle \rangle} &= \emptyset\\
    V \sub {\langle \sigma , t \rangle} &=
                                          \begin{cases*}
                                            (V \setminus \{x\}) \sub \sigma \cup \FV(t)&if \(x \in V\)\\
                                            V \sub \sigma &otherwise
                                          \end{cases*}
  \end{align*}
  Where \(x\) is assumed to be the last variable of \(\Delta\) in the second case.
\end{definition}

We note that when representing variable sets as a list of booleans, these definitions are given by simple inductions on the length of the context. These constructions admit the following properties.

\begin{proposition}
  Let \(\Delta\) be a context. Then the function taking a variable set \(V\) of \(\Delta\) to \(V \sub \sigma\) is a join-semilattice homomorphism for any substitution \(\sigma : \Delta \to \Gamma\). Further, for a term \(t : \Term_\Delta\), a type \(A : \Type_\Delta\), or a substitution \(\tau : \arr \Theta A \Delta\), the following equalities hold:
  \begin{align*}
    \FV(t \sub \sigma) &= \FV(t) \sub \sigma \\
    \FV(A \sub \sigma) &= \FV(A) \sub \sigma \\
    \FV(\tau \bullet \sigma) &= \FV(\tau) \sub \sigma
  \end{align*}
  and hence \(\Var(\Delta) \sub \sigma = \FV(\id_\Delta) \sub \sigma = \FV(\id_\Delta \bullet \sigma) = \FV(\sigma)\). Finally, for any variable set \(V \subseteq \Var(\Theta)\) we have:
  \[ V \sub {\id_\Theta} = V \qquad V \sub {\tau \bullet \sigma} = V \sub \tau \sub \sigma \]
  for \(\tau : \Theta \to \Delta\) and \(\sigma : \Delta \to \Gamma\).
\end{proposition}
\begin{proof}
  All proofs proceed by induction on the length of the context \(\Delta\) and are given in \module{Catt.Support.Properties}.
\end{proof}

An operation set is then an element of:
\[ \Sigma_{\Delta : \Ctx} \mathcal{P}(\Var(\Delta)) \times \mathcal{P}(\Var(\Delta)) \]
In the formalisation this is defined in \module{Catt.Ops} to be a function from a context and two variable sets of that context to a universe.

\begin{remark}
  The definition of an operation set in the formalisation deviates from the presentation given here, as the version in the formalisation is proof relevant. The proof relevant definition allows us to give any type as the type of witnesses that a certain triple appears in \(\mathcal{O}\), including a type containing many distinct witnesses.

  If we wished to recover a definition closer to the classical set-based definition, we could enforce that this function has a universe of propositions as its codomain, instead of a universe of types, and use propositional truncations to define various versions of \(\mathcal{O}\). This is however unnecessary for any of the proofs appearing in this thesis, hence the choice of the proof relevant definition for simplicity. A similar observation will apply to the definition of equality rule sets introduced in \cref{sec:ruleset}.
\end{remark}

We can now introduce our first operation set, the operation set for groupoidal operations, which imposes no support conditions and allows all operations.

\begin{definition}
  We define the \emph{groupoidal operation set} \(\Group\) as:
  \[ \Group = \{ (\Delta, U, V) \mid \Delta : \Ctx, U \subseteq \Var(\Delta), V \subseteq \Var(\Delta) \} \]
  We will refer to \Cattr with the operation set \(\Group\) as \emph{groupoidal \Cattr} or \emph{groupoidal \Catt} (when \(\mathcal{R} = \emptyset\)).
\end{definition}

To recover the standard definition of \Catt, we must define the boundary sets of a pasting diagram. In \cref{sec:typing-catt}, these are given as the free variables of the boundary inclusion substitutions of pasting diagrams. Here we will instead give a direct definition of the variable sets corresponding to the free variables of the substitutions, delaying the definition of boundary inclusions of pasting diagrams until \cref{sec:trees}.

\begin{definition}
  Let \(\Delta\) be a ps-context. Define the \(n\)-boundary variable sets \(\bdry n -  \Delta\) and \(\bdry n + \Delta\) by induction on \(\Delta\):
\begin{align*}
  \bdry i \epsilon {(x : \star)} &= \{ x \}\\
  \bdry i \epsilon {\Gamma, (y : A) , (f : \arr x A y)} &=
                                                           \begin{cases*}
                                                             \bdry i \epsilon \Gamma&if \(i < \dim(A)\)\\
                                                             \bdry i - \Gamma&if \(i = \dim(A)\) and \(\epsilon = -\)\\
                                                             (\bdry i + \Gamma \cup \{ y \}) \setminus \{x\}&if \(i = \dim(A)\) and \(\epsilon = +\)\\
                                                             \bdry i \epsilon \Gamma \cup \{ y , f \}&otherwise
                                                           \end{cases*}
\end{align*}
These boundary sets appear in the formalisation as \func{Catt.Support}{1257}{pd-bd-supp}.
\end{definition}

The following lemma is immediate:

\begin{lemma}
  \label{lem:bdry-full}
  If \(n \geq \dim(\Delta)\), then \(\bdry n \epsilon \Delta = \Var(\Delta)\).
\end{lemma}
\begin{proof}
  A simple induction on the definition. A formalised proof appears as \func{Catt.Support.Properties}{21113}{pd-bd-supp-full}.
\end{proof}

With this definition we can introduce the regular operation set, which recovers the regular support conditions used in the definition of \Catt.

\begin{definition}
  The \emph{regular operation set} \Reg is defined to be:
  \[ \Reg = \{ (\Delta, \Var(\Delta), \Var(\Delta)) \mid \Delta \vdash_{\mathsf{ps}} \} \cup \{ (\Delta, \bdry {\dim(\Delta)-1} - \Delta, \bdry {\dim(\Delta)-1} + \Delta) \mid \Delta \vdash_{\mathsf{ps}} \} \]
  The first component allows equivalences to be well-typed, and the second gives the support condition for composites.
\end{definition}

The regular operation set has more standard presentation.

\begin{proposition}
  \label{prop:std-op}
  Define the set \Std of standard operations be defined as:
  \[ \Std = \{ (\Delta, \bdry n - \Delta, \bdry n + \Delta) \mid \Delta \vdash_{\mathsf{ps}} , n \geq \dim(\Delta) - 1 \} \]
  Then \(\Std = \Reg\).
\end{proposition}
\begin{proof}
  Suppose \((\Delta, U, V) \in \Reg\). If \(U = \bdry {\dim(\Delta) - 1} - \Delta\) and \(V = \bdry {\dim(\Delta) - 1} + \Delta\), then \((\Delta , U ,V)\) is trivially in \Std by letting \(n = \dim(\Delta) - 1\). If instead \(U = V = \Var(\Delta)\), then \((\Delta, U , V) \in \Std\) by letting \(n = \dim(\Delta)\) and applying \cref{lem:bdry-full}.

  Conversely, assume \((\Delta, U, V) \in \Std\). Then there is \(n \geq \dim(\Delta) - 1\) with \(U = \bdry n - \Delta\) and \(V = \bdry n + \Delta\). If \(n = \dim(\Delta) - 1\) then \((\Delta, U ,V)\) is trivially in \(\Reg\), and otherwise by \cref{lem:bdry-full} we have \(U = V = \Var(\Delta)\), and so \((\Delta,U,V)\) is again an element of \Reg. Hence \(\Reg = \Std\).
\end{proof}

This more uniform is sometimes easier to work with, and will be used to prove properties of \Reg in \cref{sec:operation-properties}.

\begin{remark}
  By letting \(\mathcal{O} = \emptyset\), we recover the type theory \textsf{GSeTT}~\cite{benjamin2021globular}, a type theory for globular sets.
\end{remark}

It would be possible to generalise the notion of operation set presented here by instead letting the set \(\mathcal{O}\) consist of triples \((\Delta, s,t)\) where \(s\) and \(t\) are terms over \(\Delta\) instead of variable sets over \(\Delta\). This would allow more control over which operations were allowed in the theory. As an example, we would be able to restrict the class of composites to contain only the standard composites, or even further restrict it to binary composites.

This is however unnecessary to present the regular and groupoidal versions of \Cattr. By only allowing the set of available operations to be specified up to the support of the contained terms, it is possible to show that a coherence being an operation is closed under equality by proving that equality preserves the support of a term.

\subsection{Operation properties}
\label{sec:operation-properties}

Currently, our set of operations is completely unconstrained, and we will be limited in the constructions that can be made in \Cattr. We therefore constrain these sets in two ways. The first enforces that our set of operations is closed under suspension, for which we need to be able to suspend variable sets. This is defined in the formalisation as \func{Catt.Suspension.Support}{504}{susp-vs}.

\begin{definition}
  Let \(\Delta\) be a context. The suspension of a variable set \(V\) over \(\Delta\) is defined to be:
  \[ \Sigma(V) = \{ N , S \} \cup V \]
  where \(\Sigma(V)\), the suspension of \(V\) is a variable set over \(\Sigma(\Delta)\).
\end{definition}

We can then define our first property on operation sets.

\begin{definition}
  An operation set \(\mathcal{O}\) is \emph{suspendable} if:
  \[ (\Delta, U, V) \in \mathcal{O} \implies (\Sigma(\Delta), \Sigma(U), \Sigma(V)) \in \mathcal{O} \]
  For \(\Delta : \Ctx\) and \(U, V \subseteq \Var(\Delta)\).
\end{definition}

The groupoidal operation set is trivially suspendable. To show that the regular operation set is suspendable, we prove the following proposition.

\begin{proposition}
  Let \(\Delta\) be a ps-context. Then:
  \[\Sigma(\bdry n \epsilon \Delta) = \bdry {n + 1} {\epsilon} {\Sigma(\Delta)}\]
  for \(n \in \mathbb{N}\) and \(\epsilon \in \{-,+\}\).
\end{proposition}
\begin{proof}
  We proceed by induction on \(\Delta\). First suppose \(\Delta = (x : \star)\). We then have:
  \[ \Sigma(\bdry n \epsilon {(x : \star)}) = \Sigma(\{x\}) = \{N,S,x\} = \bdry {n + 1} {\epsilon} {\Sigma((x: \star))} \]
  Now suppose that \(\Delta = \Delta', (y : A), (f : \arr x A y)\). We split into cases on \(n\), \(\dim(A)\), and \(\epsilon\):
  \begin{itemize}
  \item If \(n < \dim(A)\) then
    \begin{align*}
      \Sigma(\bdry n \epsilon \Delta) &= \Sigma(\bdry n \epsilon {\Delta'})\\
                                      &=  \bdry {n + 1} {\epsilon} {\Sigma(\Delta')} &\text{by inductive hypothesis}\\
                                      &= \bdry {n + 1} {\epsilon} {\Sigma(\Delta)} &\text{as }n + 1 < \dim(\Sigma(A))\\
      \intertext{
      \item If \(n = \dim(A)\) and \(\epsilon = -\) then the proof is similar to the preceding case.
      \item If \(n = \dim(A)\) and \(\epsilon = +\) then:
      }
      \Sigma(\bdry n + \Delta) &= \Sigma((\bdry n + {\Delta'} \cup \{y\}) \setminus \{x\})\\
                               &= (\Sigma(\bdry n + {\Delta'}) \cup \{y\}) \setminus \{x\} \\
                               &= (\bdry {n+1} + {\Sigma(\Delta')} \cup \{y\}) \setminus \{x\} &\text{by inductive hypothesis}\\
                               &= \bdry {n+1} + {\Sigma(\Delta)} &\text{as }n + 1 = \dim(\Sigma(A))\\
      \intertext{\item If \(n > \dim(A)\) then}
      \Sigma(\bdry n \epsilon \Delta) &= \Sigma((\bdry n \epsilon {\Delta'} \cup \{y,f\})\\
                                      &= \Sigma(\bdry n + {\Delta'}) \cup \{y,f\} \\
                                      &= \bdry {n+1} + {\Sigma(\Delta')} \cup \{y, f\} &\text{by inductive hypothesis}\\
                                      &= \bdry {n+1} + {\Sigma(\Delta)} &\text{as }n + 1 > \dim(\Sigma(A))
    \end{align*}
  \end{itemize}
  Hence, the desired equality holds in all cases.
\end{proof}

\begin{corollary}
  The regular operation set is suspendable.
\end{corollary}
\begin{proof}
  By \cref{prop:std-op}, it suffices to show that the standard operation set is suspendable, which is clear from the above proposition.
\end{proof}

The second restriction we put on operation sets is that there are enough operations to create the standard coherences presented in \cref{sec:basic-constructions}.

\begin{definition}
  An operation set \(\mathcal{O}\) \emph{contains the standard operations} if \(\Std \subseteq \mathcal{O}\).
\end{definition}

The groupoidal operation set clearly contains the standard operations, and the regular operation set does due to \cref{prop:std-op}. The empty operation set does not contain the standard operations.

\subsection{Invertible generators}
\label{sec:invertibility}

\todo[inline]{Ideas about invertibility here?}

\todo[inline]{New type generator}

\todo[inline]{Limitation of this generator}

\todo[inline]{Some variations on support schemes}

\todo[inline]{Explain results you would want to prove}
\todo[inline]{Pasting contexts vs Contractible contexts}

\section{The set of equality rules \texorpdfstring{\(\mathcal{R}\)}{R}}
\label{sec:ruleset}

\todo[inline]{Form of the equality rules in formalisation}

\todo[inline]{Inclusions of rules}

\todo[inline]{Anything well typed in Catt in well typed}

\todo[inline]{Equality rules currently allow arbitrary things to be identified}

\todo[inline]{We want to be able to prove properties about these theories in generality}

\todo[inline]{Put certain closure properties on the set of rules}

\subsection{Tame theories}
\label{sec:tame-theories}

\paragraph{Lifting condition}

\todo[inline]{Can well type discs/identity}

\paragraph{Suspension condition}

\todo[inline]{Mention need for operation suspension}

\paragraph{Substitution condition}

\todo[inline]{Combination of substitution and suspension}

\todo[inline]{Substitution condition implies lifting}

\subsection{Further conditions}
\label{sec:further-conditions}

\todo[inline]{Most constructions can be done in a tame theory}

\todo[inline]{Introduce extra conditions to help prove metatheoretic properties}

\paragraph{Support condition}

\todo[inline]{Give definition}

\todo[inline]{Pinpoint use for support/downwards closure}

\todo[inline]{Use disc removal to introduce problem}

\todo[inline]{Give proof strategy}

\paragraph{Conversion condition}

\todo[inline]{Need conversion and support for full conversion}

\todo[inline]{Highlight the need for the typing judgement}

\subsection{Endo-coherence removal}
\label{sec:ecr}


\chapter{Constructions in \Catt}
\label{sec:operations-catt}

\todo[inline]{Overview of chapter}
\todo[inline]{Work in a tame theory}
\todo[inline]{Formalisation is sometimes more specific}
\todo[inline]{Introduce pruning and insertion}
\todo[inline]{Pruning used for cattsu and removes identities}
\todo[inline]{Pruning performs more radical modifications to the head term}
\todo[inline]{Insertion flattens the structure of terms, moving data from locally maximal arguments into the head term}
\todo[inline]{Compare this with associativity}
\todo[inline]{Insertion can be viewed as a generalisation of pruning}
\todo[inline]{Point to end of chapter}
\todo[inline]{Insertion again more radically changes the head term}
\todo[inline]{Is best understood as an operation on trees}
\todo[inline]{Expression morphisms between these tree contexts is requires many constructions, we introduce structured terms to aid computations involving these}
\todo[inline]{Finally we introduce the insertion construction, and give properties of this, including universal property}

\section{Pruning}
\label{sec:pruning}

\todo[inline]{High level explanation of pruning}

\todo[inline]{Recap locally maximal argument}

\todo[inline]{Want to remove a locally maximal argument which is an identity}

\todo[inline]{Introduce constituent parts}

\subsection{Dyck Words}

\todo[inline]{Need to modify the structure of the pasting diagram}
\todo[inline]{Easier to use a more explicit representation of pasting diagrams}
\todo[inline]{Very similar to ps-contexts but allows easier induction}
\todo[inline]{Properties of Dyck words}

\subsection{The pruning construction}

\todo[inline]{Explicitly give constructions}

\todo[inline]{Give pruning set}
\todo[inline]{Give pruning property}

\subsection{Properties of pruning}

\todo[inline]{Give main typing properties}
\todo[inline]{Give any confluence properties here}

\section{Trees}
\label{sec:trees}

\subsection{Wedge sums}
\label{sec:wedge-sums}

\todo[inline]{Start with topological intuition}

\todo[inline]{Universal property}

\todo[inline]{Give Catt definition}

\todo[inline]{Basic properties}

\todo[inline]{Preserves pasting diagrams}

\subsection{Tree contexts}
\label{sec:tree-contexts}

\todo[inline]{Singleton contexts, wedge sums, and suspensions preserve ps-context}

\todo[inline]{Use this to interpret trees into ps-contexts}

\todo[inline]{Give some examples}

\todo[inline]{Mapping back from ps-context}

\todo[inline]{Paths in trees}

\todo[inline]{Tree support}

\todo[inline]{Tree boundary}

\todo[inline]{Introduce labellings}

\todo[inline]{indexed by paths}

\todo[inline]{Need for extended substitutions}

\todo[inline]{Typing for labellings}

\todo[inline]{Tree inclusions}

\section{Structured terms}
\label{sec:structured-terms}

\todo[inline]{Labellings do not nicely compose}

\todo[inline]{Example one: Paths}

\todo[inline]{Example two: suspension}

\todo[inline]{Introduce structured term}

\todo[inline]{How to convert to terms}

\todo[inline]{Preliminary lemmas}

\subsection{Standard coherences}
\label{sec:standard-coherences}

\todo[inline]{Recall definition from start}

\todo[inline]{Can now define these as a structured term}

\todo[inline]{Use proposition to give an alternative definition}

\todo[inline]{Discs as structured terms}

\todo[inline]{Standard label}

\subsection{Typing and equality}
\label{sec:typing-struct-terms}

\todo[inline]{Inherit typing from terms}

\todo[inline]{point to alternative label typing}

\todo[inline]{Support for structured terms}

\todo[inline]{Disc removal and endocoherence removal for standard terms}

\section{Insertion}
\label{sec:insertion}

\todo[inline]{Motivation for insertion}
\todo[inline]{Wish to move inner composite into outer composite}

\todo[inline]{Explore action on trees}

\todo[inline]{Define branches}

\todo[inline]{Insertion only possible when trunk height more than branch height}

\todo[inline]{Give components of insertion}
\todo[inline]{Use paper for a lot of this}

\todo[inline]{Give insertion construction}

\subsection{Universal property of insertion}
\label{sec:univ-prop-insert}

\todo[inline]{Build lemmas towards universal property}

\todo[inline]{Give intuitive reasoning}

\subsection{The insertion rule}
\label{sec:insertion-rule}

\todo[inline]{Give equality rule}
\todo[inline]{Prove properties}

\subsection{Further properties}
\label{sec:further-properties}

\todo[inline]{Confluence properties for insertion}
\todo[inline]{End with standard coherences being preserved}



\chapter{Semistrict versions of \Catt}
\label{cha:cattstrict}

\section{\Cattsu}
\label{sec:cattsu}

\todo[inline]{Include disc trivialisation}

\section{\Cattsua}
\label{sec:cattsua}

\section{Towards normalisation by evaluation}
\label{sec:towards-nbe}

\todo[inline]{Explain implementation in depth}

\section{Rehydration}
\label{sec:rehydration}

\todo[inline]{Explain original motivation}

\todo[inline]{Explain connection to equivalence}

\todo[inline]{core problem with rehydration}

\subsection{Rehydration by dimension}
\label{sec:rehydr-dimens}

\subsection{Rehydration by cylinders}
\label{sec:rehydr-cylind}

\section{Further theories}
\label{sec:further-theories}

\todo[inline]{Generalised insertion}

\todo[inline]{Endo-coherence removal variation?}

\todo[inline]{Missing equation from grey categories}

\todo[inline]{Interchange and generalised pasting diagrams}






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% References:
%%

\printbibliography

\end{document}
